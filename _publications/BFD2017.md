---
type: "article"
title: "Effective Extensible Programming: Unleashing Julia on GPUs"
authors:
- Tim Besard
- Christophe Foket
- Bjorn De Sutter
year: "2017"
pages: "1--14"
arxiv: 1712.03112
packages:
  CUDAnative.jl: https://github.com/JuliaGPU/CUDAnative.jl
  CUDAdrv.jl: https://github.com/JuliaGPU/CUDAdrv.jl
  LLVM.jl: https://github.com/maleadt/LLVM.jl
---
GPUs and other accelerators are popular devices for accelerating
compute-intensive, parallelizable applications. However, programming these
devices is a difficult task. Writing efficient device code is challenging, and
is typically done in a low-level programming language. High-level languages are
rarely supported, or do not integrate with the rest of the high-level language
ecosystem. To overcome this, we propose compiler infrastructure to efficiently
add support for new hardware or environments to an existing programming
language.

We evaluate our approach by adding support for NVIDIA GPUs to the Julia
programming language. By integrating with the existing compiler, we
significantly lower the cost to implement and maintain the new compiler, and
facilitate reuse of existing application code. Moreover, use of the high-level
Julia programming language enables new and dynamic approaches for GPU
programming. This greatly improves programmer productivity, while maintaining
application performance similar to that of the official NVIDIA CUDA toolkit.