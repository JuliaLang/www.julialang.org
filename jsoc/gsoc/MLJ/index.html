<!doctype html> <html lang=en > <meta charset=utf-8 > <meta name=viewport  content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv=x-ua-compatible  content="ie=edge"> <meta name=author  content="Jeff Bezanson, Stefan Karpinski, Viral Shah, Alan Edelman, et al."> <meta name=description  content="The official website for the Julia Language. Julia is a language that is fast, dynamic, easy to use, and open source. Click here to learn more."> <meta name=robots  content="max-image-preview:large"> <meta name="twitter:site:id" content=1237720952 > <meta name=google-site-verification  content=9VDSjBtchQj6PQYIVwugTPY7pVCfLYgvkXiRHjc_Bzw  /> <link rel=icon  href="/assets/infra/julia.ico"> <link rel=stylesheet  href="/libs/highlight/github.min.css"> <link rel=stylesheet  href="/libs/bootstrap/bootstrap.min.css"> <link rel=stylesheet  href="/css/app.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/fonts.css"> <link href="https://fonts.googleapis.com/css?family=Roboto:400,400i,500,500i,700,700i" rel=stylesheet > <link href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel=stylesheet > <script async defer src="/libs/buttons.js"></script> <script type="application/javascript"> var doNotTrack = false; if (!doNotTrack) { window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga('create', 'UA-28835595-1', 'auto'); ga('send', 'pageview'); } </script> <script async src='https://www.google-analytics.com/analytics.js'></script> <title>GSOC projects</title> <style> .container ul li p {margin-bottom: 0;} </style> <meta property="og:title" content="GSOC projects"> <meta property="og:description" content=""> <meta property="og:image" content="/assets/images/julia-open-graph.png"> <div class="container py-3 py-lg-0"> <nav class="navbar navbar-expand-lg navbar-light bg-light" id=main-menu > <a class=navbar-brand  href="/"> <img src="/assets/infra/logo.svg" alt="JuliaLang Logo"> </a> <button class="navbar-toggler ml-auto hidden-sm-up float-xs-left" type=button  data-toggle=collapse  data-target="#navbarSupportedContent" aria-controls=navbarSupportedContent  aria-expanded=false  aria-label="Toggle navigation"> <span class=navbar-toggler-icon ></span> </button> <div class="collapse navbar-collapse" id=navbarSupportedContent > <ul class="navbar-nav mx-auto"> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/downloads/">Download</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://docs.julialang.org">Documentation</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/blog/">Blog</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/community/">Community</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/learning/">Learn</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/research/">Research</a> <li class="nav-item active flex-md-fill text-md-center"> <a class=nav-link  href="/jsoc/">JSoC</a> </ul> <span class=navbar-right > <a class=github-button  href="https://github.com/sponsors/julialang" data-icon=octicon-heart  data-size=large  aria-label="Sponsor @julialang on GitHub">Sponsor</a> </span> </div> </nav> </div> <br><br> <a href="https://github.com/JuliaLang/www.julialang.org/blob/master/jsoc/gsoc/MLJ.md" title="Edit this page on GitHub" class=edit-float > </a> <div class="container main"><h1 id=gsoc_projects ><a href="#gsoc_projects">GSOC projects</a></h1> <h1 id=2021_ideas ><a href="#2021_ideas">2021 Ideas</a></h1> <h1 id=titles_possible_mentors ><a href="#titles_possible_mentors">Titles &amp; possible mentors </a></h1> <ul> <li><p><a href="#Particle-swarm-optimization-of-machine-learning-models">Particle swarm optimization of machine learning models</a></p> <li><p><a href="#In-processing-methods-for-fairness-in-machine-learning">In-processing methods for fairness in machine learning</a></p> <li><p><a href="#Causal-and-counterfactual-methods-for-fairness-in-machine-learning">Causal and counterfactual methods for fairness in machine learning</a></p> <li><p><a href="#Time-series-forecasting-at-scale---speed-up-via-Julia">Time series forecasting at scale - speed up via Julia</a></p> <li><p><a href="#Interpretable-Machine-Learning-in-Julia">Interpretable Machine Learning in Julia</a></p> <li><p><a href="#Model-visualization-in-MLJ">Model visualization in MLJ</a></p> <li><p><a href="#Deeper-Bayes">Deeper integration with Bayseian methods and Bayesian Stacking</a></p> <li><p><a href="#MLJ-and-MLFlow-integration">MLJ and MLFlow integration</a></p> <li><p><a href="#Speed-demons-only-need-apply">Speed demons only need apply</a></p> </ul> <h1 id=mlj_projects_summer_of_code ><a href="#mlj_projects_summer_of_code">MLJ Projects – Summer of Code</a></h1> <p><a href="https://github.com/alan-turing-institute/MLJ.jl">MLJ</a> is a machine learning framework for Julia aiming to provide a convenient way to use and combine a multitude of tools and models available in the Julia ML/Stats ecosystem.</p> <p>MLJ is released under the MIT license and sponsored by the Alan Turing Institute.</p> <h2 id=particle_swarm_optimization_of_machine_learning_models ><a href="#particle_swarm_optimization_of_machine_learning_models">Particle swarm optimization of machine learning models</a></h2> <p>Bring particle swarm optimization to the MLJ machine learning platform to help users tune machine learning models. </p> <p><strong>Difficulty.</strong> Easy - moderate. </p> <h3 id=description ><a href="#description">Description</a></h3> <p>Imagine your search for the optimal machine learning model as the meandering flight of a bee through hyper-parameter space, looking for a new home for the queen. Parallelize your search, and you&#39;ve created a swarm of bees. Introduce communication between the bees about their success so far, and you introduce the possibility of the bees ultimately converging on good candidate for the best model.</p> <p>PSO &#40;particle swarm optimization&#41; is a large, promising, and active area of research, but also one that is used in real data science practice. The method is based on a very simple idea inspired by nature and makes essentially no assumptions about the nature of the cost function &#40;unlike other methods, such as gradient descent, which might require a handle on derivatives&#41;. The method is simple to implement, and applicable to a wide range of hyper-parameter optimization problems.</p> <p><strong>Mentors.</strong> <a href="https://ablaom.github.io">Anthony Blaom</a>, <a href="https://www.turing.ac.uk/people/programme-directors/sebastian-vollmer">Sebastian Vollmer</a></p> <h3 id=prerequisites ><a href="#prerequisites">Prerequisites</a></h3> <div class=tight-list ><ul> <li><p>Julia language fluency essential. </p> <li><p>Git-workflow familiarity strongly preferred. </p> <li><p>Some prior contact with optimization algorithms of some kind</p> <li><p>A passing familiarity with machine learning goals and workflow preferred</p> </ul></div> <h3 id=your_contribution ><a href="#your_contribution">Your contribution</a></h3> <p>The aim of this project is to implement one or more variants of PSO algorithm, for use in the MLJ machine learning platform, for the purpose of optimizing hyper-parameters. <em>Integration</em> with MLJ is crucial, so there will be opportunity to spend time familiarizing yourself with this popular tool. </p> <p>Specifically, you will:</p> <ul> <li><p>familiarize yourself with the training, evaluation and tuning of machine learning models in MLJ</p> <li><p>learn about the PSO algorithm and its variants, conducting a short survey of some of the literature and existing implementations in Julia and other languages, and preparing a short summary</p> <li><p>familiarize yourself intimately with the &#91;MLJ tuning</p> </ul> <p>API&#93;&#40;https://github.com/alan-turing-institute/MLJTuning.jl#how-do-i-implement-a-new-tuning-strategy&#41;</p> <ul> <li><p>implement a simple PSO variant, complete with testing and documentation</p> <li><p>experiment with the variant to learn more about its shortcomings and advantages, help recommend default parameter settings</p> <li><p>add variants, as time permits</p> </ul> <h3 id=references ><a href="#references">References</a></h3> <ul> <li><p><a href="https://en.wikipedia.org/wiki/Particle_swarm_optimization">Wiki entry on PSO</a></p> <li><p><a href="https://www.hindawi.com/journals/mpe/2015/931256/">Zhang et al. &#40;2015&#41;: A Comprehensive Survey on Particle Swarm Optimization Algorithm and Its Applications</a></p> <li><p><a href="https://link.springer.com/article/10.1007/s12065-019-00210-z">Elbes et al. &#40;2015&#41;: A survey on particle swarm optimization with emphasis on engineering and network applications</a></p> <li><p><a href="https://github.com/alan-turing-institute/MLJTuning.jl#how-do-i-implement-a-new-tuning-strategy">The MLJ tuning API</a></p> </ul> <h2 id=in-processing_methods_for_fairness_in_machine_learning ><a href="#in-processing_methods_for_fairness_in_machine_learning">In-processing methods for fairness in machine learning</a></h2> <p>Mentors: <a href="https://jiahao.github.io/">Jiahao Chen</a>, <a href="https://github.com/mschauer">Moritz Schauer</a>, and <a href="https://www.turing.ac.uk/people/programme-directors/sebastian-vollmer">Sebastian Vollmer</a></p> <p><a href="https://github.com/ashryaagr/Fairness.jl">Fairness.jl</a> is a package to audit and mitigate bias, using the MLJ machine learning framework and other tools. It has implementations of some preprocessing and postprocessing methods for improving fairness in classification models, but could use more implementations of other methods, especially inprocessing algorithms like adversarial debiasing.</p> <p><em>Difficulty</em> Hard.</p> <h3 id=prerequisites__2 ><a href="#prerequisites__2">Prerequisites</a></h3> <div class=tight-list ><ul> <li><p>Essential: working knowledge of the Julia language</p> <li><p>Strongly preferred: git workflow familiarity</p> <li><p>Desirable: Experience with flux and autodiff</p> </ul></div> <h3 id=description__2 ><a href="#description__2">Description</a></h3> <p>Machine learning models are developed to support and make high-impact decisions like who to hire or who to give a loan to. However, available training data can exhibit bias against race, age, gender, or other prohibited bases, reflecting a complex social and economic history of systemic injustic. For example, women in the United Kingdom, United States and other countries were only allowed to have their own bank accounts and lines of credit in the 1970s&#33; That means that training a credit decisioning model on historical data would encode implicit biases, that women are less credit-worthy because few of them had lines of credit in the past. Surely we would want to be fair and not hinder an applicant&#39;s ability to get a loan on the basis of their race, gender and age?</p> <p>So how can we fix data and models that are unfair? A common first reaction is to remove the race, gender and age attributes from the training data, and then say we are done. But as described in detail in the references, we cam have to consider if other features like one&#39;s name or address could encode such prohibited bases too. To mitigate bias and improve fairness in models, we can change the training data &#40;pre-processing&#41;, the way we define and train the model &#40;in-processing&#41;, and/or alter the predictions made &#40;post-processing&#41;. Some algorithms for the first and third approaches have already been implemented in Fairness.jl, which have the advantage of treating the ML model as a black box. However, our latest resarch <a href="https://arxiv.org/abs/2011.02407">&#40;arXiv:2011.02407&#41;</a> shows that pur black box methods have fundamental limitations in their ability to mitigate bias.</p> <h3 id=your_contribution__2 ><a href="#your_contribution__2">Your contribution</a></h3> <p>This project is to implement more bias mitigation algorithms and invent new ones too. We will focus on in-processing algorithms that alter the training process or alter ML model. Some specific stages are to:</p> <ol> <li><p>Use <a href="https://github.com/FluxML/Flux.jl">Flux.jl</a> or <a href="https://github.com/alan-turing-institute/MLJFlux.jl">MLJFlux.jl</a> to develop in-processing algorithms,</p> <li><p>Study research papers proposing in-processing algorithms and implement them, and</p> <li><p>Implement fairness algorithms and metrics for individual fairness as described in papers like <a href="https://arxiv.org/abs/2006.11439">arXiv:2006.11439</a>.</p> </ol> <h3 id=references__2 ><a href="#references__2">References</a></h3> <ol> <li><p>High-level overview: <a href="https://julialang.org/jsoc/gsoc/MLJ/">https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb</a></p> <li><p><a href="https://nextjournal.com/ashryaagr/fairness">https://nextjournal.com/ashryaagr/fairness</a> </p> <li><p>IBM’s AIF360 resources: <a href="https://aif360.mybluemix.net/">https://aif360.mybluemix.net/</a> </p> <p>AIF360 Inprocessing algorithms: Available <a href="https://aif360.readthedocs.io/en/latest/modules/algorithms.html#module-aif360.algorithms.inprocessing">here</a>.</p> <li><p><a href="https://dssg.github.io/fairness_tutorial/">https://dssg.github.io/fairness_tutorial/</a> </p> </ol> <h2 id=causal_and_counterfactual_methods_for_fairness_in_machine_learning ><a href="#causal_and_counterfactual_methods_for_fairness_in_machine_learning">Causal and counterfactual methods for fairness in machine learning</a></h2> <p>Mentors: <a href="https://jiahao.github.io/">Jiahao Chen</a>, <a href="https://github.com/mschauer">Moritz Schauer</a>, <a href="https://github.com/zenna">Zenna Tavares</a>, and <a href="https://www.turing.ac.uk/people/programme-directors/sebastian-vollmer">Sebastian Vollmer</a></p> <p><a href="https://github.com/ashryaagr/Fairness.jl">Fairness.jl</a> is a package to audit and mitigate bias, using the MLJ machine learning framework and other tools. This project is to implement algorithms for counterfactual &#40;&quot;what if&quot;&#41; reasoning and causal analysis to Fairness.jl and MLJ.jl, integrating and extending Julia packages for causal analysis.</p> <p><em>Difficulty</em> Hard.</p> <h3 id=prerequisites__3 ><a href="#prerequisites__3">Prerequisites</a></h3> <div class=tight-list ><ul> <li><p>Essential: working knowledge of the Julia language</p> <li><p>Strongly preferred: git workflow familiarity</p> <li><p>Desirable: Experience in causal inference</p> <li><p>Desirable: Experience with graphical models</p> </ul></div> <h3 id=description__3 ><a href="#description__3">Description</a></h3> <p>Machine learning models are developed to support and make high-impact decisions like who to hire or who to give a loan to. However, available training data can exhibit bias against race, age, gender, or other prohibited bases, reflecting a complex social and economic history of systemic injustic. For example, women in the United Kingdom, United States and other countries were only allowed to have their own bank accounts and lines of credit in the 1970s&#33; That means that training a credit decisioning model on historical data would encode implicit biases, that women are less credit-worthy because few of them had lines of credit in the past. Surely we would want to be fair and not hinder an applicant&#39;s ability to get a loan on the basis of their race, gender and age?</p> <p>So how can we fix unfairness in models? Arguably, we should first identify the underlying <em>causes</em> of bias, and only then can we actually remediate bias successfully. However, one major challenge is that a proper evaluation often requires data that we don&#39;t have. For this reason, we also need counterfactual analysis, to identify actions we can take that can mitigate fairness not just in our training data, but also in situations we haven&#39;t seen yet but could encounter in the future. Ideas for identifying and mitigating bias using such causal interventions have been proposed in papers such as <a href="https://causalai.net/r37.pdf">Equality of Opportunity in Classification: A Causal Approach</a> and the references below.</p> <h3 id=your_contribution__3 ><a href="#your_contribution__3">Your contribution</a></h3> <p>This project is to implement algorithms for counterfactual &#40;&quot;what if&quot;&#41; reasoning and causal analysis to Fairness.jl and MLJ.jl, integrating and extending Julia packages for causal analysis. Some specific stages are:</p> <div class=tight-list ><ol> <li><p>Implement interfaces in MLJ.jl for Julia packages for causal inference and probabilistic programming such as <a href="https://github.com/zenna/Omega.jl">Omega.jl</a> and CausalInference.jl&#93;&#40;https://github.com/mschauer/CausalInference.jl&#41;</p> <li><p>Implement and benchmark causal and counterfactual definitons for measuring unfairness</p> <li><p>Implement and benchmark causal and counterfactual approaches to mitigate bias</p> </ol></div> <h3 id=references__3 ><a href="#references__3">References</a></h3> <div class=tight-list ><ul> <li><p><a href="https://github.com/yongkaiwu/Causal-Fairness">Repository of Causal-Fairness links</a> </p> <li><p><a href="https://causalai.net/r37.pdf">Causal fairness for predictive models</a></p> <li><p><a href="https://papers.nips.cc/paper/2020/file/d0921d442ee91b896ad95059d13df618-Paper.pdf">High-level overview: Fair Multiple Decision Making Through Soft Interventions</a></p> <li><p><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16949/15911">Fairness in Decision-Making — The Causal Explanation Formula</a></p> <li><p><a href="https://causalml.readthedocs.io/en/latest/methodology.html#t-learner">CausalML tool from Uber</a></p> <li><p><a href="https://www2.slideshare.net/AmitSharma315/dowhy-an-endtoend-library-for-causal-inference">end-to-end causal</a></p> <li><p><a href="https://causalai.net/r37.pdf">Equality of Opportunity in Classification: A Causal Approach</a>.</p> </ul></div> <h2 id=time_series_forecasting_at_scale_-_speed_up_via_julia ><a href="#time_series_forecasting_at_scale_-_speed_up_via_julia">Time series forecasting at scale - speed up via Julia</a></h2> <p>Time series are ubiquitous - stocks, sensor reading, vital signs. This projects aims at adding time series forecasting to MLJ and perform benchmark comparisons to <a href="https://github.com/alan-turing-institute/sktime">sktime</a>, <a href="https://github.com/rtavenar/tslearn">tslearn</a>, <a href="https://github.com/uea-machine-learning/tsml/">tsml</a>&#41;.</p> <p><strong>Difficulty.</strong> Easy - moderate. </p> <h3 id=prerequisites__4 ><a href="#prerequisites__4">Prerequisites</a></h3> <ul> <li><p>Julia language fluency essential. </p> <li><p>Git-workflow essebtial </p> <li><p>Some prior contact with time series forecasting </p> <li><p>HPC in julia is a desirable</p> </ul> <h3 id=your_contribution__4 ><a href="#your_contribution__4">Your contribution</a></h3> <p>MLJ is so far focused on tabular data and time series classification. This project is to add support for time series data in a modular, composable way.</p> <p>Time series are everywhere in real-world applications and there has been an increase in interest in time series frameworks recently &#40;see e.g. <a href="https://github.com/alan-turing-institute/sktime">sktime</a>, <a href="https://github.com/rtavenar/tslearn">tslearn</a>, <a href="https://github.com/uea-machine-learning/tsml/">tsml</a>&#41;.</p> <p>But there are still very few principled time-series libraries out there, so you would be working on something that could be very useful for a large number of people. To find out more, check out this <a href="http://learningsys.org/neurips19/assets/papers/sktime_ml_systems_neurips2019.pdf">paper</a> on sktime.</p> <p><strong>Mentors</strong>: <a href="https://www.turing.ac.uk/people/programme-directors/sebastian-vollmer">Sebastian Vollmer</a>, <a href="https://github.com/mloning">Markus Löning</a> &#40;sktime developer&#41;.</p> <h3 id=references__4 ><a href="#references__4">References</a></h3> <ul> <li><p><a href="https://github.com/alan-turing-institute/sktime">sktime</a></p> <li><p><a href="https://github.com/rtavenar/tslearn">tslearn</a></p> <li><p><a href="https://github.com/uea-machine-learning/tsml/">tsml</a></p> <li><p><a href="http://learningsys.org/neurips19/assets/papers/sktime_ml_systems_neurips2019.pdf">sktime paper</a></p> </ul> <h2 id=interpretable_machine_learning_in_julia ><a href="#interpretable_machine_learning_in_julia">Interpretable Machine Learning in Julia</a></h2> <p>Interpreting and explaining black box interpretation crucial to estabilish trust and improve performance</p> <p><strong>Difficulty.</strong> Easy - moderate. </p> <h3 id=description__4 ><a href="#description__4">Description</a></h3> <p>It is important to have mechanisms in place to interpret the results of machine learning models. Identify the relevant factors of a decision or scoring of a model. </p> <p>This project will implement methods for model and feature interpretability.</p> <p><strong>Mentors.</strong> <a href="https://github.com/darenasc">Diego Arenas</a>, <a href="https://www.turing.ac.uk/people/programme-directors/sebastian-vollmer">Sebastian Vollmer</a>.</p> <h3 id=prerequisites__5 ><a href="#prerequisites__5">Prerequisites</a></h3> <ul> <li><p>Julia language fluency essential. </p> <li><p>Git-workflow familiarity strongly preferred. </p> <li><p>Some prior contact with explainable AI/ML methods is desirable.</p> <li><p>A passing familiarity with machine learning goals and workflow preferred</p> </ul> <h3 id=your_contribution__5 ><a href="#your_contribution__5">Your contribution</a></h3> <p>The aim of this project is to implement multiple variants implementation algorithms such as:</p> <ul> <li><p>Implement methods to show feature importance</p> <li><p>Partial dependence plots</p> <li><p>Tree surrogate</p> <li><p>LocalModel: Local Interpretable Model-agnostic Explanations</p> <li><p>Add Dataset loaders for standard interpretability datasetss. </p> <li><p>Add performance metrics for interpretability</p> <li><p>Add interpretability algorithms</p> <li><p>Glue code to SHAP package </p> </ul> <p>Specifically you will</p> <ul> <li><p>Familiarize yourself with MLJ</p> <li><p>Survey of some of the literature and existing implementations in Julia and other languages, and preparing a short summary</p> <li><p>Implement visualisations of explanations</p> <li><p>Implement use cases</p> <li><p>You will learn about the benefits and short comings of model interpretation and how to use them. </p> </ul> <h3 id=references__5 ><a href="#references__5">References</a></h3> <ul> <li><p><a href="https://christophm.github.io/interpretable-ml-book/">Interpretable Machine Learning - A Guide for Making Black Box Models Explainable by Christoph Molnalr</a></p> <li><p><a href="https://github.com/christophM/iml/">iml R package</a></p> <li><p></p> </ul> <p>Tutorials</p> <ul> <li><p><a href="https://dl.acm.org/doi/abs/10.1145/3351095.3375667">AI explainability 360: hands-on tutorial</a></p> <li><p><a href="https://mlr3book.mlr-org.com/iml.html">IML tutorial</a></p> </ul> <h2 id=model_visualization_in_mlj ><a href="#model_visualization_in_mlj">Model visualization in MLJ</a></h2> <p>Design and implement a data visualization module for MLJ.</p> <p><strong>Difficulty</strong>. Easy.</p> <h3 id=description__5 ><a href="#description__5">Description</a></h3> <p>Design and implement a data visualization module for MLJ to visualize numeric and categorical features &#40;histograms, boxplots, correlations, frequencies&#41;, intermediate results, and metrics generated by MLJ machines. </p> <p>Using a suitable Julia package for data visualization.</p> <p>The idea is to implement a similar resource to what <a href="https://github.com/mlr-org/mlr3viz">mlr3viz</a> does for <a href="https://mlr3.mlr-org.com">mlr3</a>.</p> <h3 id=prerequisites__6 ><a href="#prerequisites__6">Prerequisites</a></h3> <ul> <li><p>Julia language fluency essential.</p> <li><p>Git-workflow essential.</p> <li><p>Some prior work on data visualization is desirable</p> </ul> <h3 id=your_contribution__6 ><a href="#your_contribution__6">Your contribution</a></h3> <p>So far visualizing data or features in MLJ is an ad-hoc task. Defined by the user case by case. You will be implementing a standard way to visualize model performance, residuals, benchmarks and predictions for MLJ users.</p> <p>The structures and metrics will be given from the results of models or data sets used; your task will be to implement the right visualizations depending on the data type of the features.</p> <p>A relevant part of this project is to visualize the target variable against the rest of the features.</p> <p>You will enhance your visualisation skills as well as your ability to &quot;debug&quot; and understand models and their prediction visually.</p> <h3 id=references__6 ><a href="#references__6">References</a></h3> <ul> <li><p><a href="https://github.com/mlr-org/mlr3viz">mlr3viz</a></p> <li><p><a href="https://github.com/JuliaPlots/StatsPlots.jl">StatsPlots</a></p> </ul> <p><strong>Mentors</strong>: <a href="https://www.turing.ac.uk/people/programme-directors/sebastian-vollmer">Sebastian Vollmer</a>, <a href="https://github.com/darenasc">Diego Arenas</a>.</p> <h2 id=deeper_bayesian_intergration ><a href="#deeper_bayesian_intergration">Deeper Bayesian Intergration</a></h2> <p>Bayesian methods and probabilistic supervised learning provide uncertainty quantification. This project aims increasing integration to combine Bayeisan and non-Bayesian methods using Turing.</p> <h3 id=description__6 ><a href="#description__6">Description</a></h3> <p>As an initial step reproduce &#40;SOSSMLJ&#41;&#91;https://github.com/cscherrer/SossMLJ.jl&#93; in Turing. The bulk of the project is to implement methods that combine multiple predictive distributinons.</p> <h3 id=your_contributions ><a href="#your_contributions">Your contributions</a></h3> <ul> <li><p>Interface between Turing and MLJ</p> <li><p>Comparisons of ensambling, stacking of predictive distribution</p> <li><p>reproducible benchmarks across various settings.</p> </ul> <h3 id=references__7 ><a href="#references__7">References</a></h3> <p><a href="http://www.stat.columbia.edu/~gelman/research/published/stacking_paper_discussion_rejoinder.pdf">Bayesian Stacking</a> <a href="https://github.com/alan-turing-institute/skpro/blob/master/README.md">SKpro</a></p> <h3 id=difficulty_medium_to_hard ><a href="#difficulty_medium_to_hard">Difficulty: Medium to Hard</a></h3> <p><strong>Mentors</strong>: <a href="https://github.com/yebai">Hong Ge</a> <a href="https://www.turing.ac.uk/people/programme-directors/sebastian-vollmer">Sebastian Vollmer</a> </p> <h2 id=mlj_and_mlflow_integration ><a href="#mlj_and_mlflow_integration">MLJ and MLFlow integration</a></h2> <p>Integrate MLJ with <a href="https://mlflow.org">MLFlow</a>. </p> <p><strong>Difficulty.</strong> Easy. </p> <h3 id=description__7 ><a href="#description__7">Description</a></h3> <p>MLFlow is a flexible model management tool. The project consists of writing the necessary functions to integrate MLJ with <a href="https://mlflow.org/docs/latest/rest-api.html">MLFlow REST API</a> so models built using MLJ can keep track of its runs, evaluation metrics, parameters, and can be registered and monitored using MLFlow.</p> <h3 id=prerequisites__7 ><a href="#prerequisites__7">Prerequisites</a></h3> <ul> <li><p>Julia language fluency essential.</p> <li><p>Git-workflow familiarity strongly preferred.</p> </ul> <h3 id=your_contribution__7 ><a href="#your_contribution__7">Your contribution</a></h3> <ul> <li><p>Provide to MLJ users a way to keep track of their machine learning models using MLflow, as a local or remote server.</p> <li><p>Implement a reproducible way to store and load machine learning models.</p> <li><p>Implement functions wraping the REST API calls that makes possible the use of MLflow.</p> </ul> <h3 id=references__8 ><a href="#references__8">References</a></h3> <ul> <li><p><a href="https://mlflow.org">MLFlow</a> website.</p> <li><p><a href="https://mlflow.org/docs/latest/rest-api.html">MLFlow REST API</a>.</p> </ul> <h2 id=speed_demons_only_need_apply ><a href="#speed_demons_only_need_apply">Speed demons only need apply</a></h2> <p>Diagnose and exploit opportunities for speeding up common MLJ workflows.</p> <p><strong>Difficulty.</strong> Moderate. </p> <h3 id=description__8 ><a href="#description__8">Description</a></h3> <p>In addition to investigating a number of known performance bottlenecks, you will have some free reign in this to identify opportunities to speed up common MLJ workflows, as well as making better use of memory resources.</p> <h3 id=prerequisites__8 ><a href="#prerequisites__8">Prerequisites</a></h3> <ul> <li><p>Julia language fluency essential. </p> <li><p>Experience with multi-threading and multi-processor computing essential, preferably in Julia.</p> <li><p>Git-workflow familiarity strongly preferred. </p> <li><p>Familiarity with machine learning goals and workflow preferred</p> </ul> <h3 id=your_contribution__8 ><a href="#your_contribution__8">Your contribution</a></h3> <p>In this project you will:</p> <ul> <li><p>familiarize yourself with the training, evaluation and tuning of machine learning models in MLJ</p> <li><p>work towards addressing a number of known performance issues, including:</p> <li><p>limitations of the generic Tables.jl interface for interacting with tabular data which, in common cases &#40;DataFrames&#41;, has extra functionality that can be exploited</p> <li><p>rolling out new data front-end for models to avoid unnecessary copying of data</p> <li><p>in conjuction with your mentor, identify best design for introducing better sparse data support to MLJ models &#40;e.g., naive Bayes&#41; </p> <li><p>implement a multi-threading and/or multi-processor parallelism to the current learning networks scheduler</p> <li><p>benchmark and profile common workflows to identify opportunities for further code optimizations</p> <li><p>implement some of these optimizations</p> </ul> <h3 id=references__9 ><a href="#references__9">References</a></h3> <ul> <li><p><a href="https://github.com/alan-turing-institute/MLJ.jl/blob/dev/ROADMAP.md#scalability">MLJ Roadmap</a>. See, in particular &quot;Scalability&quot; section.</p> <li><p><a href="https://github.com/alan-turing-institute/MLJBase.jl/issues/309">Taking performance more seriously GitHub issue</a></p> <li><p><a href="https://alan-turing-institute.github.io/MLJ.jl/dev/adding_models_for_general_use/#Implementing-a-data-front-end-1">Data front end</a> for MLJ models.</p> </ul> <p><strong>Mentors.</strong> <a href="https://ablaom.github.io">Anthony Blaom</a></p> </div><br><br> <script src="/libs/highlight/highlight.pack.js"></script> <script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: ' '});</script> <footer class="container-fluid footer-copy"> <div class=container > <div class="row footrow"> <ul> <li><a href="/project">About</a> <li><a href="/about/help">Get Help</a> <li><a href="/blog/2019/02/julia-entities/">Governance</a> <li><a href="/research/#publications">Publications</a> <li><a href="/research/#sponsors">Sponsors</a> </ul> <ul> <li><a href="/downloads/">Downloads</a> <li><a href="/downloads/">All Releases</a> <li><a href="https://github.com/JuliaLang/julia">Source Code</a> <li><a href="/downloads/#current_stable_release">Current Stable Release</a> <li><a href="/downloads/#long_term_support_release">Longterm Support Release</a> <li><a href="https://status.julialang.org/">PkgServer Status</a> </ul> <ul> <li><a href="https://docs.julialang.org/en/v1/">Documentation</a> <li><a href="https://juliaacademy.com">JuliaAcademy</a> <li><a href="https://www.youtube.com/user/JuliaLanguage">YouTube</a> <li><a href="/learning/getting-started/">Getting Started</a> <li><a href="https://docs.julialang.org/en/v1/manual/faq/">FAQ</a> <li><a href="/learning/books">Books</a> </ul> <ul> <li><a href="/community/">Community</a> <li><a href="/community/standards/">Code of Conduct</a> <li><a href="/diversity/">Diversity</a> <li><a href="https://juliacon.org">JuliaCon</a> <li><a href="/community/#julia_user_and_developer_survey">User/Developer Survey</a> <li><a href="/shop/">Shop Merchandise</a> </ul> <ul> <li><a href="https://github.com/JuliaLang/julia/blob/master/CONTRIBUTING.md">Contributing</a> <li><a href="https://github.com/JuliaLang/julia/issues">Issue Tracker</a> <li><a href="https://github.com/JuliaLang/julia/security/policy">Report a Security Issue</a> <li><a href="https://github.com/issues?q=is%3Aopen+is%3Aissue+language%3AJulia+label%3A%22help+wanted%22">Help Wanted Issues</a> <li><a href="https://github.com/issues?q=is%3Aopen+is%3Aissue+language%3AJulia+label%3A%22good+first+issue%22+">Good First Issue</a> <li><a href="https://docs.julialang.org/en/v1/devdocs/reflection/">Dev Docs</a> </ul> </div> <div id=footer-bottom  class=row > <div class="col-md-10 py-2"> <p>Built with <a href="https://franklinjl.org">Franklin.jl</a> and the <a href="https://julialang.org">Julia Programming Language</a>. We thank <a href="https://www.fastly.com">Fastly</a> for their generous infrastructure support.</p> <p>©2021 JuliaLang.org <a href="https://github.com/JuliaLang/www.julialang.org/graphs/contributors">contributors</a>. The content on this website is made available under the <a href="https://github.com/JuliaLang/www.julialang.org/blob/master/LICENSE.md">MIT license</a>. </div> <div class="col-md-2 py-2"> <span class=float-sm-right > <a class=github-button  href="https://github.com/sponsors/julialang" data-icon=octicon-heart  data-size=large  aria-label="Sponsor @julialang on GitHub">Sponsor</a> </span> </div> </div> </div> </footer> <script src="/libs/jquery/jquery.min.js"></script> <script src="/libs/bootstrap/bootstrap.min.js"></script>