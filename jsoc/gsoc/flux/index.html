<!doctype html> <html lang=en > <meta charset=utf-8 > <meta name=viewport  content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv=x-ua-compatible  content="ie=edge"> <meta name=author  content="Jeff Bezanson, Stefan Karpinski, Viral Shah, Alan Edelman, et al."> <meta name=description  content="The official website for the Julia Language. Julia is a language that is fast, dynamic, easy to use, and open source. Click here to learn more."> <meta name=robots  content="max-image-preview:large"> <meta name="twitter:site:id" content=1237720952 > <meta name=google-site-verification  content=9VDSjBtchQj6PQYIVwugTPY7pVCfLYgvkXiRHjc_Bzw  /> <link rel=icon  href="/assets/infra/julia.ico"> <link rel=stylesheet  href="/libs/bootstrap/bootstrap.min.css"> <link rel=stylesheet  href="/css/app.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/fonts.css"> <link href="https://fonts.googleapis.com/css?family=Roboto:400,400i,500,500i,700,700i" rel=stylesheet > <link href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel=stylesheet > <script async defer src="/libs/buttons.js"></script> <script type="application/javascript"> var doNotTrack = false; if (!doNotTrack) { window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga('create', 'UA-28835595-1', 'auto'); ga('send', 'pageview'); } </script> <script async src='https://www.google-analytics.com/analytics.js'></script> <title>Machine Learning Projects - Summer of Code</title> <style> .container ul li p {margin-bottom: 0;} </style> <meta property="og:title" content="Machine Learning Projects - Summer of Code"> <meta property="og:description" content=""> <meta property="og:image" content="/assets/images/julia-open-graph.png"> <div class="container py-3 py-lg-0"> <nav class="navbar navbar-expand-lg navbar-light bg-light" id=main-menu > <a class=navbar-brand  href="/"> <img src="/assets/infra/logo.svg" alt="JuliaLang Logo"> </a> <button class="navbar-toggler ml-auto hidden-sm-up float-xs-left" type=button  data-toggle=collapse  data-target="#navbarSupportedContent" aria-controls=navbarSupportedContent  aria-expanded=false  aria-label="Toggle navigation"> <span class=navbar-toggler-icon ></span> </button> <div class="collapse navbar-collapse" id=navbarSupportedContent > <ul class="navbar-nav mx-auto"> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/downloads/">Download</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://docs.julialang.org">Documentation</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/blog/">Blog</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/community/">Community</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/learning/">Learn</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/research/">Research</a> <li class="nav-item active flex-md-fill text-md-center"> <a class=nav-link  href="/jsoc/">JSoC</a> </ul> <span class=navbar-right > <a class=github-button  href="https://github.com/sponsors/julialang" data-icon=octicon-heart  data-size=large  aria-label="Sponsor @julialang on GitHub">Sponsor</a> </span> </div> </nav> </div> <br><br> <a href="https://github.com/JuliaLang/www.julialang.org/blob/master/jsoc/gsoc/flux.md" title="Edit this page on GitHub" class=edit-float > </a> <div class="container main"><h1 id=machine_learning_projects_-_summer_of_code ><a href="#machine_learning_projects_-_summer_of_code">Machine Learning Projects - Summer of Code</a></h1> <h3 id=cuda_hacking ><a href="#cuda_hacking">CUDA Hacking</a></h3> <p>Are you a performance nut? Help us implement cutting-edge CUDA kernels in Julia for operations important across deep learning, scientific computing and more. We also need help developing our wrappers for machine learning, sparse matrices and more, as well as CI and infrastructure. Contact us to develop a project plan.</p> <p>Mentors: <a href="https://github.com/maleadt">Tim Besard</a>, <a href="https://github.com/DhairyaLGandhi">Dhairya Gandhi</a>.</p> <h3 id=reinforcement_learning_environments ><a href="#reinforcement_learning_environments">Reinforcement Learning Environments</a></h3> <p>Develop a series of reinforcement learning environments, in the spirit of the <a href="https://gym.openai.com">OpenAI Gym</a>. Although we have wrappers for the gym available, it is hard to install &#40;due to the Python dependency&#41; and, since it&#39;s written in Python and C code, we can&#39;t do more interesting things with it &#40;such as differentiate through the environments&#41;. A pure-Julia version that supports a similar API and visualisation options would be valuable to anyone doing RL with Flux.</p> <p>Mentors: <a href="https://github.com/DhairyaLGandhi/">Dhairya Gandhi</a>.</p> <h3 id=reinforcement_learning_algorithms ><a href="#reinforcement_learning_algorithms">Reinforcement Learning Algorithms</a></h3> <p>Recent advances in reinforcement learning led to many breakthroughs in artificial intelligence. Some of the latest deep reinforcement learning algorithms have been implemented in <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl">ReinforcementLearning.jl</a> with Flux. We&#39;d like to have more interesting and practical algorithms added to enrich the whole community, including but not limited to the following directions:</p> <ul> <li><p><strong>&#91;Easy&#93; Recurrent version of existing algorithms</strong>. Students with a basic understanding of Q-learning and recurrent neural networks are preferred. We&#39;d like to have a general implementation to easily extend existing algorithms to the sequential version.</p> <li><p><strong>&#91;Medium&#93; Offline reinforcement learning algorithms</strong>. A bunch of offline reinforcement learning algorithms are proposed in recent years, including <a href="https://arxiv.org/pdf/1910.01708.pdf">BCQ</a>, <a href="https://arxiv.org/abs/2006.15134">CRR</a>, <a href="https://arxiv.org/abs/2006.04779">CQL</a> and so on. The expected output is to have some typical offline reinforcement learning algorithms and experiments added into <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningZoo.jl">ReinforcementLearningZoo.jl</a>.</p> <li><p><strong>&#91;Medium&#93; Model-based reinforcement learning algorithms</strong>. Students interested in this topic may refer <a href="https://arxiv.org/abs/2006.16712">Model-based Reinforcement Learning: A Survey</a> and design some general interfaces to implement typical model based algorithms.</p> <li><p><strong>&#91;Medium&#93; Multi-agent reinforcement learning algorithms</strong>. Currently, we only have some CFR related algorithms implemented. We&#39;d like to have more implemented, including <a href="https://arxiv.org/abs/1706.02275v4">MADDPG</a>, <a href="https://arxiv.org/abs/1705.08926">COMA</a>, <a href="https://arxiv.org/abs/1603.01121">NFSP</a>, <a href="https://arxiv.org/abs/1711.00832">PSRO</a>.</p> <li><p><strong>&#91;Hard&#93; Distributed reinforcement learning framework</strong>. Inspired by <a href="https://arxiv.org/abs/2006.00979">Acme</a>, a similar design is proposed in <a href="https://github.com/JuliaReinforcementLearning/DistributedReinforcementLearning.jl">DistributedReinforcementLearning.jl</a>. However, it is still in a very early stage. Students interested in this direction are required to have a basic understanding of distributed computing in Julia. Ideally we&#39;d like to see some distributed reinforcement learning algorithms implemented under this framework, like <a href="https://openreview.net/forum?id&#61;r1lyTjAqYX&amp;utm_campaign&#61;RL&#37;20Weekly&amp;utm_medium&#61;email&amp;utm_source&#61;Revue&#37;20newsletter">R2D2</a>, <a href="https://arxiv.org/abs/1804.08617v1">D4PG</a>.</p> </ul> <h4 id=expected_outcomes ><a href="#expected_outcomes">Expected Outcomes</a></h4> <p>For each new algorithm, at least two experiments are expected to be added into <a href="https://github.com/JuliaReinforcementLearning/ReinforcementLearningZoo.jl">ReinforcementLearningZoo.jl</a>. A simple one to make sure it works on some toy games with CPU only and another more practical one to produce comparable results on the original paper with GPU enabled. Besides, a technical report on the implementation details and speed/performance comparison with other baselines is preferred.</p> <p>Mentors: <a href="https://github.com/findmyway">Jun Tian</a></p> <h3 id=nlp_tools_and_models ><a href="#nlp_tools_and_models">NLP Tools and Models </a></h3> <p><strong>Difficulty</strong>: Medium to Hard</p> <p>Build deep learning models for Natural Language Processing in Julia. <a href="https://github.com/juliatext/TextAnalysis.jl">TextAnalysis</a> and <a href="https://github.com/JuliaText/WordTokenizers.jl">WordTokenizers</a> contains the basic algorithms and data structures to work with textual data in Julia. On top of that base, we want to build modern deep learning models based on recent research. The following tasks can span multiple students and projects.</p> <p>It is important to note that we want practical, usable solutions to be created, not just research models. This implies that a large part of the effort will need to be in finding and using training data, and testing the models over a wide variety of domains. Pre-trained models must be available to users, who should be able to start using these without supplying their own training data.</p> <div class=tight-list ><ul> <li><p>Implement GPT/GPT-2 in Julia</p> <li><p>Implement <a href="https://arxiv.org/abs/1909.03186">extractive summarisation based on Transformers</a></p> <li><p>Implement practical models for</p> <ul> <li><p>Dependency Tree Parsing </p> <li><p>Morphological extractions </p> <li><p>Translations &#40;using Transformers&#41; </p> </ul> <li><p>Indic language support – validate and test all models for Indic languages</p> <ul> <li><p>ULMFiT models for Indic languages</p> </ul> <li><p>Chinese tokenisation and parsing</p> </ul></div> <p><strong>Mentors</strong>: <a href="https://github.com/aviks/">Avik Sengupta</a></p> <h3 id=automated_music_generation ><a href="#automated_music_generation">Automated music generation </a></h3> <p><strong>Difficulty</strong>: Hard</p> <p>Neural network based models can be used for music analysis and music generation &#40;composition&#41;. A suite of tools in Julia to enable research in this area would be useful. This is a large, complex project that is suited for someone with an interest in music and machine learning. This project will need a mechanism to read music files &#40;primarily MIDI&#41;, a way to synthesise sounds, and finally a model to learn composition. All of this is admittedly a lot of work, so the exact boundaries of the project can be flexible, but this can be an exciting project if you are interested in both music and machine learning.</p> <p><strong>Recommended Skills</strong>: Music notation, some basic music theory, MIDI format, Transformer and LSTM architectures</p> <p><strong>Resources</strong>: <a href="https://magenta.tensorflow.org/music-transformer">Music Transformer</a>, <a href="https://magenta.tensorflow.org/maestro-wave2midi2wave">Wave2MIDI2Wave</a>, <a href="https://github.com/JuliaMusic/MIDI.jl">MIDI.jl</a>, <a href="https://github.com/JuliaMusic/Mplay.jl">Mplay.jl</a></p> <p><strong>Mentors</strong>: <a href="https://github.com/aviks/">Avik Sengupta</a></p> <h2 id=fluxjl ><a href="#fluxjl">Flux.jl</a></h2> <p>Flux usually takes part in <a href="https://summerofcode.withgoogle.com">Google Summer of Code</a>, as part of the wider Julia organisation. We follow the same <a href="/jsoc/projects/">rules and application guidelines</a> as Julia, so please check there for more information on applying. Below are a set of ideas for potential projects &#40;though you are welcome to explore anything you are interested in&#41;.</p> <p>Flux projects are typically very competitive; we encourage you to get started early, as successful students typically have early PRs or working prototypes as part of the application. It is a good idea to simply start contributing via issue discussion and PRs and let a project grow from there; you can take a look at <a href="https://github.com/FluxML/Flux.jl/issues?q&#61;is&#37;3Aopen&#43;is&#37;3Aissue&#43;label&#37;3A&#37;22help&#43;wanted&#37;22">this list of issues</a> for some starter contributions.</p> <h3 id=port_ml_tutorials ><a href="#port_ml_tutorials">Port ML Tutorials</a></h3> <p>There are many high-quality open-source tutorials and learning materials available, for example from PyTorch and fast.ai. We&#39;d like to have Flux ports of these that we can add to the model zoo, and eventually publish to the Flux website.</p> <p>Mentors: <a href="https://github.com/DhairyaLGandhi/">Dhairya Gandhi</a>.</p> <h3 id=ferminets_generative_synthesis_for_automating_the_choice_of_neural_architectures ><a href="#ferminets_generative_synthesis_for_automating_the_choice_of_neural_architectures">FermiNets: Generative Synthesis for Automating the Choice of Neural Architectures</a></h3> <p>The application of machine learning requires an understanding a practictioner to optimize a neural architecture for a given problem, or does it? Recently techniques in automated machine learning, also known as AutoML, have dropped this requirement by allowing for good architectures to be found automatically. One such method is the <a href="https://arxiv.org/abs/1809.05989">FermiNet</a> which employs generative synthesis to give a neural architecture which respects certain operational requirements. The goal of this project is to implement the FermiNet in Flux to allow for automated sythesis of neural networks.</p> <p>Mentors: <a href="https://github.com/ChrisRackauckas">Chris Rackauckas</a> and <a href="https://github.com/DhairyaLGandhi/">Dhairya Gandhi</a>.</p> <h3 id=differentiable_rendering_hard ><a href="#differentiable_rendering_hard">Differentiable Rendering &#91;HARD&#93;</a></h3> <p>Expected Outcome: This is motivated to create SoftRasterizer/DiB-R based projects. We already have RayTracer.jl which is motivated by OpenDR. &#40;Of course, if someone wants to implement NERF - like models they are most welcome to submit a proposal&#41;. We would ideally target at least 2 of these models.</p> <p>Skills: GPU Programming, Deep Learning, &#40;deep&#41; familiarity with the literature, familiarity with defining &#40;a lot of&#41; Custom Adjoints</p> <p>Mentors: <a href="https://github.com/DhairyaLGandhi/">Dhairya Gandhi</a>, <a href="https://github.com/avik-pal">Avik Pal</a></p> <h3 id=core_development_medium ><a href="#core_development_medium">Core Development &#91;MEDIUM&#93;</a></h3> <p>Expected Outcomes:</p> <ul> <li><p>Some of the functions require custom adjoints for speedup</p> <li><p>Functions require GPU kernels. Some of these are of common interest to the community like – knn, etc.</p> <li><p>Benchmarking with Tensorflow Graphics and Pytorch3D. We already have the scripts for kaolin, need to extend that.</p> <li><p>Most of these problems are listed as issues in the main repo.</p> </ul> <p>Skills: GPU Programming, Deep Learning, familiarity with defining &#40;a lot of&#41; Custom Adjoints</p> <p>Mentors: <a href="https://github.com/DhairyaLGandhi/">Dhairya Gandhi</a></p> <h3 id=fastaijl_development ><a href="#fastaijl_development">FastAI.jl Development</a></h3> <p><strong>Difficulty:</strong> Medium</p> <p>In this project, you will assist the <a href="https://julialang.zulipchat.com/#narrow/stream/237432-ml-ecosystem-coordination">ML community team</a> with building FastAI.jl on top of the existing JuliaML &#43; FluxML ecosystem packages. The primary goal is to create an equivalent to <a href="https://docs.fast.ai">docs.fast.ai</a>. This will require building the APIs, documenting them, and creating the appropriate tutorials. Some familiarity with the following Julia packages is preferred, but it is not required:</p> <div class=tight-list ><ul> <li><p><a href="https://github.com/JuliaML/MLDataPattern.jl.git">MLDataPattern.jl</a></p> <li><p><a href="https://github.com/lorenzoh/FluxTraining.jl.git">FluxTraining.jl</a></p> <li><p><a href="https://github.com/lorenzoh/DataAugmentation.jl">DataAugmentation.jl</a></p> </ul></div> <p>A stretch goal can include extending FastAI.jl beyond its Python-equivalent by leveraging the flexibility in the underlying Julia packages. For example, creating and designing abstractions for distributed data parallel training.</p> <p><strong>Skills:</strong> Familiarity with deep learning pipelines, common practices, Flux.jl, and MLDataPattern.jl</p> <p><strong>Mentors:</strong> <a href="https://github.com/darsnack">Kyle Daruwalla</a></p> <h3 id=differentiable_computer_vision_hard ><a href="#differentiable_computer_vision_hard">Differentiable Computer Vision &#91;HARD&#93;</a></h3> <p>Expected Outcome:</p> <p>Create a library of utliity functions that can consume Julia&#39;s Imaging libraries to make them differentiable. With Zygote.jl, we have the platform to take a general purpose package and apply automatic differentiation to it. This project is motivated to use existing libraries that offer perform computer vision tasks, and augment them with AD to perform tasks such as homography regression.</p> <p>Skills: Familiarity with automatic differentiation, deep learning, and defining &#40;a lot of&#41; Custom Adjoints</p> <p>Mentors: <a href="https://github.com/DhairyaLGandhi/">Dhairya Gandhi</a></p> <h2 id=deep_learning_for_source_code_analysis ><a href="#deep_learning_for_source_code_analysis">Deep Learning for source code analysis </a></h2> <p><strong>Difficulty</strong>: Easy to Medium</p> <p>The use of deep learning tools to source code is an active area of research. With the runtime being able to easily introspect into Julia code &#40;for example, with a clean, accesible AST format&#41;, using theses techniques on Julia code would be a fruitful exercise. </p> <div class=tight-list ><ul> <li><p>Use of RNNs for syntax error correction: https://arxiv.org/abs/1603.06129</p> <li><p>Implement Code2Vec for Julia: https://arxiv.org/abs/1803.09473</p> </ul></div> <p><strong>Recommended Skills:</strong> Familiarity with compiler techniques as well as deep learning tools will be required. The &quot;domain expertise&quot; in this task is Julia programming, so it will need someone who has a reasonable experience of the Julia programming language. </p> <p><strong>Expected Outcome:</strong> Packages for each technique that is usable by general programmers. </p> <p><strong>Mentors</strong>: <a href="https://github.com/aviks/">Avik Sengupta</a></p> </div><br><br> <footer class="container-fluid footer-copy"> <div class=container > <div class="row footrow"> <ul> <li><a href="/project">About</a> <li><a href="/about/help">Get Help</a> <li><a href="/blog/2019/02/julia-entities/">Governance</a> <li><a href="/research/#publications">Publications</a> <li><a href="/research/#sponsors">Sponsors</a> </ul> <ul> <li><a href="/downloads/">Downloads</a> <li><a href="/downloads/">All Releases</a> <li><a href="https://github.com/JuliaLang/julia">Source Code</a> <li><a href="/downloads/#current_stable_release">Current Stable Release</a> <li><a href="/downloads/#long_term_support_release">Longterm Support Release</a> <li><a href="https://status.julialang.org/">PkgServer Status</a> </ul> <ul> <li><a href="https://docs.julialang.org/en/v1/">Documentation</a> <li><a href="https://juliaacademy.com">JuliaAcademy</a> <li><a href="https://www.youtube.com/user/JuliaLanguage">YouTube</a> <li><a href="/learning/getting-started/">Getting Started</a> <li><a href="https://docs.julialang.org/en/v1/manual/faq/">FAQ</a> <li><a href="/learning/books">Books</a> </ul> <ul> <li><a href="/community/">Community</a> <li><a href="/community/standards/">Code of Conduct</a> <li><a href="/diversity/">Diversity</a> <li><a href="https://juliacon.org">JuliaCon</a> <li><a href="/community/#julia_user_and_developer_survey">User/Developer Survey</a> <li><a href="/shop/">Shop Merchandise</a> </ul> <ul> <li><a href="https://github.com/JuliaLang/julia/blob/master/CONTRIBUTING.md">Contributing</a> <li><a href="https://github.com/JuliaLang/julia/issues">Issue Tracker</a> <li><a href="https://github.com/JuliaLang/julia/security/policy">Report a Security Issue</a> <li><a href="https://github.com/issues?q=is%3Aopen+is%3Aissue+language%3AJulia+label%3A%22help+wanted%22">Help Wanted Issues</a> <li><a href="https://github.com/issues?q=is%3Aopen+is%3Aissue+language%3AJulia+label%3A%22good+first+issue%22+">Good First Issue</a> <li><a href="https://docs.julialang.org/en/v1/devdocs/reflection/">Dev Docs</a> </ul> </div> <div id=footer-bottom  class=row > <div class="col-md-10 py-2"> <p>Built with <a href="https://franklinjl.org">Franklin.jl</a> and the <a href="https://julialang.org">Julia Programming Language</a>. We thank <a href="https://www.fastly.com">Fastly</a> for their generous infrastructure support.</p> <p>©2020 JuliaLang.org <a href="https://github.com/JuliaLang/www.julialang.org/graphs/contributors">contributors</a>. The content on this website is made available under the <a href="https://github.com/JuliaLang/www.julialang.org/blob/master/LICENSE.md">MIT license</a>. </div> <div class="col-md-2 py-2"> <span class=float-sm-right > <a class=github-button  href="https://github.com/sponsors/julialang" data-icon=octicon-heart  data-size=large  aria-label="Sponsor @julialang on GitHub">Sponsor</a> </span> </div> </div> </div> </footer> <script src="/libs/jquery/jquery.min.js"></script>