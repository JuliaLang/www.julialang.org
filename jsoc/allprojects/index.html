<!doctype html>
<html lang="en">
<head>
	<!-- parts for all pages -->
	<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="x-ua-compatible" content="ie=edge">
<meta name="author" content="Jeff Bezanson, Stefan Karpinski, Viral Shah, Alan Edelman, et al.">
<meta name="description" content="The official website for the Julia Language. Julia is a language that is fast, dynamic, easy to use, and open source. Click here to learn more.">
<meta name="robots" content="max-image-preview:large">
<meta name="twitter:site:id" content="1237720952"> <!-- @JuliaLanguage -->
<meta name="google-site-verification" content="9VDSjBtchQj6PQYIVwugTPY7pVCfLYgvkXiRHjc_Bzw" /> <!-- Google News Feed -->


	<link rel="icon" href="/assets/infra/julia.ico">

  <!-- Franklin stylesheets for generated pages -->
  
  

	<!-- NOTE: specific stylesheets -->
<link rel="stylesheet" href="/libs/bootstrap/bootstrap.min.css">
<link rel="stylesheet" href="/css/app.css">
<link rel="stylesheet" href="/css/franklin.css">
<link rel="stylesheet" href="/css/fonts.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:400,400i,500,500i,700,700i" rel="stylesheet">
<link href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
<script async defer src="/libs/buttons.js"></script>
<script src="/libs/clipboard.min.js"></script>
<script src="/libs/detectdark.js"></script>


<script defer data-domain="julialang.org" src="https://plausible.io/js/script.js"></script>

<!-- scripts for map rendering -->
<link rel="stylesheet" href="https://unpkg.com/leaflet@1.7.1/dist/leaflet.css"
integrity="sha512-xodZBNTC5n17Xt2atTPuE1HxjVMSvLVW9ocqUKLsCC5CXdbqCmblAshOMAS6/keqq/sMZMZ19scR4PsZChSR7A=="
crossorigin=""/>

<script src="https://unpkg.com/leaflet@1.7.1/dist/leaflet.js"
 integrity="sha512-XQoYMqMTK8LvdxXYG3nZ448hOEQiglfqkJs1NOQV44cWnUrBc8PkAOcXy20w0vlaXaVUearIOBhiXZ5V3ynxwA=="
 crossorigin=""></script>

<!-- https://github.com/Leaflet/Leaflet.markercluster -->
<script src="https://cdn.jsdelivr.net/npm/leaflet.markercluster@1.4.1/dist/leaflet.markercluster-src.min.js"></script>

<script src="https://kit.fontawesome.com/f030d443fe.js" crossorigin="anonymous"></script>


   <title>View all GSoC/JSoC Projects</title>   

  

  <!-- Specific style for blog pages (except the /blob/index) -->
  

  <!-- OGP Metadata -->
	<meta property="og:title" content="View all GSoC/JSoC Projects">
<meta property="og:description" content="">
<meta property="og:image" content="/assets/images/julia-open-graph.png">


</head>

<body>

<nav class="navbar navbar-expand-lg navbar-light bg-white">
  <div class="container">
      <a class="navbar-brand" href="/">
          <img src="/assets/infra/logo.svg" alt="JuliaLang Logo" height="40">
      </a>
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarContent" aria-controls="navbarContent" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarContent">
          <ul class="navbar-nav mx-auto mb-2 mb-lg-0">
              <li class="nav-item">
                  <a class="nav-link" href="/downloads/">Download</a>
              </li>
              <li class="nav-item">
                  <a class="nav-link" href="https://docs.julialang.org">Documentation</a>
              </li>
              <li class="nav-item">
                  <a class="nav-link" href="/learning/">Learn</a>
              </li>
              <li class="nav-item">
                  <a class="nav-link" href="/blog/">Blog</a>
              </li>
              <li class="nav-item">
                  <a class="nav-link" href="/community/">Community</a>
              </li>
              <li class="nav-item">
                  <a class="nav-link" href="/contribute/">Contribute</a>
              </li>
              <li class="nav-item">
                  <a class="nav-link" href="/jsoc/">JSoC</a>
              </li>
          </ul>
          <div class="navbar-action-buttons d-flex gap-4">
              <a class="btn btn-outline-dark btn-sm btn-star" href="https://github.com/JuliaLang/julia" target="_blank">⭐ Star</a>
              <a class="btn btn-danger btn-sm btn-sponsor" href="https://github.com/sponsors/julialang" target="_blank">❤️ Sponsor</a>
          </div>
      </div>
  </div>
</nav>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">

<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>

<br><br>




<a href="https://github.com/JuliaLang/www.julialang.org/blob/master/jsoc/allprojects.md" title="Edit this page on GitHub" class="edit-float">
</a>


<!-- Content appended here -->
<div class="container main"><h1 id="view_all_gsocjsoc_projects"><a href="#view_all_gsocjsoc_projects" class="header-anchor">View all GSoC/JSoC Projects</a></h1>
<p>This page is designed to improve discoverability of projects. You can, for example, search this page for specific keywords and find all of the relevant projects.</p>
<h2 id="clima_a_new_open-source_climate_model_running_on_gpus"><a href="#clima_a_new_open-source_climate_model_running_on_gpus" class="header-anchor">CliMA: A New Open-Source Climate Model Running on GPUs</a></h2>
<p>Climate models are complex codes that simulate Earth&#39;s climate system &#40;atmosphere, ocean, land, ice&#41;. These models demand immense computing power and present significant software engineering challenges, including managing massive datasets, ensuring numerical stability, optimizing performance, and coupling diverse components. The complexity and legacy nature of existing models hinder their ability to fully utilize modern computing infrastructure &#40;GPUs, machine learning, etc.&#41;. The Climate Modeling Alliance is developing CliMA, a new climate model built in Julia and designed from the outset to leverage GPU acceleration and modern software engineering practices to overcome the limitations of traditional climate models.</p>
<h4 id="climaexplorer_an_interactive_visualizer_of_climate_model_outputs"><a href="#climaexplorer_an_interactive_visualizer_of_climate_model_outputs" class="header-anchor"><code>ClimaExplorer</code>: An Interactive Visualizer of Climate Model Outputs</a></h4>
<p>Visualizing simulation output is crucial for both scientific understanding and outreach. This project involves developing <code>ClimaExplorer</code>, an interactive visualizer for the output of the CliMA Earth system model. <code>ClimaExplorer</code> will leverage the <a href="https://github.com/MakieOrg/Makie.jl">Makie</a> ecosystem and web technologies, providing a user-friendly interface for exploring complex climate data. This will enable researchers to more easily analyze and interpret simulation results, accelerating scientific discovery. Furthermore, the web-based component will facilitate broader dissemination of results to a wider audience.</p>
<p><strong>Desired Skills:</strong> Familiarity with front-end web development &#40;HTML, JavaScript, and CSS&#41;, Julia, and <a href="https://github.com/MakieOrg/Makie.jl">Makie</a>.</p>
<p><strong>Difficulty:</strong> Medium</p>
<p><strong>Duration</strong> 175 hours</p>
<p><strong>Expected Results:</strong> <code>ClimaExplorer</code>, a new module for interactive visualization of simulation output &#40;with tests and documentation&#41;.</p>
<p><strong>Mentor:</strong> <a href="https://github.com/sbozzolo">Gabriele Bozzola</a></p>
<p><strong>Contact:</strong> Feel free to ask questions via <a href="clima-software@caltech.edu">email</a> or <a href="https://join.slack.com/t/julialang/shared_invite/zt-2a5wdtotu-H52pQQTMDOa4NwsTSgQ_lQ">Julia Slack</a> &#40;DM to Gabriele Bozzola&#41;.</p>
<p><em>Interested in other aspects of climate modeling in Julia but not this particular project? Get in touch—we have many more projects&#33;</em></p>
<h2 id="compiler_projects_summer_of_code"><a href="#compiler_projects_summer_of_code" class="header-anchor">Compiler Projects – Summer of Code</a></h2>
<p>There are a number of compiler projects that are currently being worked on. Please contact Jameson Nash for additional details and let us know what specifically interests you about this area of contribution. That way, we can tailor your project to better suit your interests and skillset.</p>
<h3 id="better_debug_information_output_for_variables_175_hours"><a href="#better_debug_information_output_for_variables_175_hours" class="header-anchor">Better debug information output for variables &#40;175 hours&#41;</a></h3>
<p>We have part of the infrastructure in place for representing DWARF information for our variables, but only from limited places. We could do much better since there are numerous opportunities for improvement&#33;</p>
<ul>
<li><p><strong>Expected Outcomes</strong>: Ability to see more variable, argument, and object details in gdb<br /></p>
</li>
<li><p><strong>Recommended Skills</strong>: Most of these projects involve algorithms work, requiring a willingness and interest in seeing how to integrate with a large system.</p>
</li>
<li><p><strong>Difficulty</strong>: Medium</p>
</li>
<li><p><strong>Mentors</strong>: <a href="https://github.com/vtjnash">Jameson Nash</a>, <a href="https://github.com/gbaraldi">Gabriel Baraldi</a></p>
</li>
</ul>
<h3 id="improving_test_coverage_175_hours"><a href="#improving_test_coverage_175_hours" class="header-anchor">Improving test coverage &#40;175 hours&#41;</a></h3>
<p>Code coverage reports very good coverage of all of the Julia Stdlib packages, but it&#39;s not complete. Additionally, the coverage tools themselves &#40;–track-coverage and <a href="https://github.com/JuliaCI/Coverage.jl">https://github.com/JuliaCI/Coverage.jl</a>&#41; could be further enhanced, such as to give better accuracy of statement coverage, or more precision. A successful project may combine a bit of both building code and finding faults in others&#39; code.</p>
<p>Another related side-project might be to explore adding Type information to the coverage reports?</p>
<ul>
<li><p><strong>Recommended Skills</strong>: An eye for detail, a thrill for filing code issues, and the skill of breaking things.</p>
</li>
<li><p><strong>Contact:</strong> <a href="https://github.com/vtjnash">Jameson Nash</a></p>
</li>
</ul>
<h2 id="tensor_network_contraction_order_optimization_and_visualization_summer_of_code"><a href="#tensor_network_contraction_order_optimization_and_visualization_summer_of_code" class="header-anchor">Tensor network contraction order optimization and visualization – Summer of Code</a></h2>
<p><a href="https://github.com/under-Peter/OMEinsum.jl">OMEinsum.jl</a> is a pure Julia package for tensor network computation,  which has been used in various projects, including</p>
<ul>
<li><p><a href="https://github.com/QuEraComputing/GenericTensorNetworks.jl">GenericTensorNetworks.jl</a> for solving combinatorial optimization problems,</p>
</li>
<li><p><a href="https://github.com/QuantumBFS/YaoToEinsum.jl">YaoToEinsum.jl</a> for simulating large scale quantum circuit and</p>
</li>
<li><p><a href="https://github.com/TensorBFS/TensorInference.jl">TensorInference.jl</a> for Bayesian inference.</p>
</li>
</ul>
<p>Unlike other tensor contraction packages such as <code>ITensors.jl</code> and <code>TensorOperations.jl</code>, it is designed for large scale tensor networks with arbitrary topology. The key feature of <code>OMEinsum.jl</code> is that it can automatically optimize the contraction order of a tensor network. Related features are implemented in <a href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl">OMEinsumContractionOrders.jl</a>.</p>
<p>We are looking for a student to work on the following tasks:</p>
<ul>
<li><p>Implement a better contraction order optimizer based on <a href="https://arxiv.org/abs/2202.07793">Tamaki&#39;s algorithm</a>.</p>
</li>
<li><p>Implement a hyper-graph visualization tool based on <a href="https://arxiv.org/abs/2308.05043">arXiv:2308.05043</a></p>
</li>
<li><p>Port the contraction order optimizers to <a href="https://github.com/Jutho/TensorOperations.jl">TensorOperations.jl</a></p>
</li>
</ul>
<p><strong>Recommended skills:</strong> familiarity with tensor networks, graph theory and high performance computing.</p>
<p><strong>Expected results:</strong></p>
<ul>
<li><p>new features added to the package <code>OMEinsumContractionOrders.jl</code> along with tests and relevant documentation.</p>
</li>
<li><p>a new package about hyper-graph visualization, and relevant feature added to <code>OMEinsum.jl</code>.</p>
</li>
<li><p>a pull request to <code>TensorOperations.jl</code> for better contraction order optimization.</p>
</li>
</ul>
<p><strong>Mentors:</strong> <a href="https://github.com/giggleliu">Jin-Guo Liu</a>, <a href="https://github.com/Jutho">Jutho Haegeman</a> and <a href="https://github.com/lkdvos">Lukas Devos</a></p>
<p><strong>Project difficulty:</strong> Medium to Hard</p>
<p><strong>Project length:</strong> 350 hrs</p>
<p><strong>Contact:</strong> feel free to ask questions via <a href="cacate0129@gmail.com">email</a> or the Julia slack &#40;user name: JinGuo Liu&#41;.</p>
<h2 id="documentation_tooling_summer_of_code"><a href="#documentation_tooling_summer_of_code" class="header-anchor">Documentation tooling – Summer of Code</a></h2>
<h3 id="documenterjl"><a href="#documenterjl" class="header-anchor">Documenter.jl</a></h3>
<p>The Julia manual and the documentation for a large chunk of the ecosystem is generated using <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> – essentially a static site generator that integrates with Julia and its docsystem. There are tons of opportunities for improvements for anyone interested in working on the interface of Julia, documentation and various front-end technologies &#40;web, LaTeX&#41;.</p>
<p>Here are some features or areas that are looking for contributions:</p>
<ul>
<li><p>User-contributed notes and examples to documentation &#40;e.g. backed by GitHub Discussions&#41;.</p>
</li>
<li><p>One-page-per-function documentation listings &#40;prototype for main Julia manual&#41;. See <a href="https://github.com/JuliaDocs/Documenter.jl/issues/2133">JuliaDocs/Documenter.jl#2133</a>.</p>
</li>
<li><p>JuliaSyntax-based code highlighter for Julia code that can be re-used for both the HTML and LaTeX/PDF output.</p>
</li>
<li><p>Rework Documenter&#39;s page layout and navigation. See <a href="https://github.com/JuliaDocs/Documenter.jl/issues/2177">JuliaDocs/Documenter.jl#2177</a>.</p>
</li>
<li><p>Improve or rework Documenter&#39;s search index.</p>
</li>
<li><p>Work on any of the ideas that have been <a href="https://github.com/JuliaDocs/Documenter.jl/labels/Type&#37;3A&#37;20Plugin">marked as plugins</a>, as they offer self-contained features to work on.</p>
</li>
</ul>
<p>If any of these sound interesting, please reach out to the mentors to ask for more details and to narrow down the project for a proposal. The possible projects vary in difficulty and size, depending on the project and the ultimate scope.</p>
<p><strong>Recommended skills</strong>: Depends on the project, but the work would generally involved both Julia programming, but also basic web development &#40;HTML, CSS, JS&#41;.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/mortenpi">Morten Piibeleht</a>, <a href="https://github.com/fredrikekre">Fredrik Ekre</a></p>
<h3 id="contact"><a href="#contact" class="header-anchor">Contact</a></h3>
<p>Best way to reach out is to message in the <code>#documentation</code> channel on the <a href="https://julialang.org/slack/">JuliaLang Slack</a>&#33;</p>
<h2 id="fastdifferentiationjl_summer_of_code"><a href="#fastdifferentiationjl_summer_of_code" class="header-anchor">FastDifferentiation.jl – Summer of Code</a></h2>
<p><a href="https://github.com/brianguenter/FastDifferentiation.jl">FastDifferentiation.jl</a> is a Julia package for computing very efficient symbolic derivatives of Julia functions and for compiling the derivatives into  efficient executables. It can differentiate much larger expressions than other symbolic systems, such as Symbolics.jl, and the resulting derivatives are also much more efficient, rivaling hand computed derivatives in some cases &#40;see the website for benchmark examples&#41;.</p>
<p><a href="https://github.com/brianguenter/FastDifferentiation.jl">FastDifferentiation.jl</a> also computes the exact sparsity patterns of Jacobians and Hessians &#40;and any other order derivative&#41; and detects common terms in derivatives of Rⁿ-&gt;Rᵐ functions for large n,m. As a consequence computation time of Jacobians generally scales sub-linearly as a function of n,m.</p>
<p>However, the current system has several weaknesses. It is not currently possible to differentiate through conditional expressions so many commonly used Julia functions cannot be differentiated. Derivatives of any order can be computed but orders above 3 or 4 become increasingly inefficient. These projects aim to address these weaknesse.</p>
<h3 id="add_conditionals_to_fastdifferentiationjl"><a href="#add_conditionals_to_fastdifferentiationjl" class="header-anchor">Add Conditionals to FastDifferentiation.jl</a></h3>
<p>FastDifferentiation supports conditionals in function definitions but cannot yet compute derivatives of functions with conditionals:</p>
<pre><code class="julia hljs">julia&gt; <span class="hljs-meta">@variables</span> x y

julia&gt; f = if_else(x&gt;y,x^<span class="hljs-number">2</span>,y^<span class="hljs-number">2</span>)
(if_else  (x &gt; y) (x ^ <span class="hljs-number">2</span>) (y ^ <span class="hljs-number">2</span>))

julia&gt; derivative(f,x)
ERROR: Your expression contained a if_else expression. FastDifferentiation does not yet support differentiation through this <span class="hljs-keyword">function</span></code></pre>
<blockquote>
<p>The goal of this project is to modify the derivative graph analysis code so that it detects conditional subgraphs and then generates run time code to evaluate conditionals and branches to correct derivative expressions.</p>
</blockquote>
<p><strong>Medium difficulty, 175 hours.</strong></p>
<p><strong>Recommended Skills:</strong> Julia programming experience, previous work with graph algorithms helpful but not required.</p>
<p><strong>Expected Outcome:</strong> Well-tested and well-documented support for conditionals.</p>
<p><strong>Mentor:</strong> <a href="https://github.com/brianguenter/FastDifferentiation.jl">BrianGuenter</a></p>
<h3 id="add_higher_order_derivatives_to_fastdifferentiationjl"><a href="#add_higher_order_derivatives_to_fastdifferentiationjl" class="header-anchor">Add higher order derivatives to FastDifferentiation.jl</a></h3>
<p>FastDifferentiation.jl produces extremely efficient first derivatives. But, higher order derivatives become increasingly less efficient since they are computed by repeatedly applying the differentiation algorithm. </p>
<p>The fundamental cause of this behavior is that repeated higher order intermediate derivative terms are not detected and reused; instead they are computed from scratch. The goal of this project is to extend the FastDifferentiation algorithm to detect these common higher order terms and to reuse, rather than recompute them.</p>
<p>This will require a rewrite of the graph factorization code as well as some theoretical work to determine which higher order terms can be reused.</p>
<p><strong>Hard, 350 hours.</strong></p>
<p><strong>Recommended Skills:</strong> Julia programming experience, previous work with graph algorithms helpful but not required. Understanding of <a href="https://en.wikipedia.org/wiki/Fa&#37;C3&#37;A0_di_Bruno&#37;27s_formula">Faa Di Bruno&#39;s</a> and <a href="https://en.wikipedia.org/wiki/General_Leibniz_rule">Leibniz&#39;s rule</a>.</p>
<p><strong>Expected Outcome:</strong> Well-tested and well-documented support for higher order derivatives.</p>
<p><strong>Mentor:</strong> <a href="https://github.com/brianguenter/FastDifferentiation.jl">BrianGuenter</a></p>
<h3 id="integrate_fastdifferentiationjl_into_symbolicsjl"><a href="#integrate_fastdifferentiationjl_into_symbolicsjl" class="header-anchor">Integrate FastDifferentiation.jl into Symbolics.jl</a></h3>
<p>FastDifferentiation.jl uses a new symbolic algorithm for automatic differentiation that can be orders of magnitude faster than conventional symbolic differentiation methods. Symoblics.jl could compute derivatives much faster using the FastDifferentiation algorithm. However implementation and data structure differences between the two systems make it difficult to add FastDifferentiation capabilities to Symbolics.jl.</p>
<p>For example, Symbolics.jl allows you to define a function <span class="katex"><span class="katex-mathml"><math xmlns="https://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q(t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mclose">)</span></span></span></span> and then to compute a symbolic derivative <span class="katex"><span class="katex-mathml"><math xmlns="https://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>q</mi><mo>˙</mo></mover><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\dot{q}(t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.66786em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.055550000000000016em;"><span class="mord">˙</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mclose">)</span></span></span></span> without defining <span class="katex"><span class="katex-mathml"><math xmlns="https://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span>. Adding this capability to FastDifferentiation.jl requires a change in the graph representation of derivatives. </p>
<p>The goal of this project is to first analyze the sources of the incompatibilities between the two systems and then to modify FastDifferentiation.jl, and perhaps Symbolics.jl, so that they interoperate.</p>
<p>See <a href="https://github.com/brianguenter/Proposals">this</a> page for a more detailed description of tasks.</p>
<p><strong>Medium difficulty, 175 hours.</strong></p>
<p><strong>Recommended Skills:</strong> Julia programming experience, previous work with graph algorithms helpful but not required.</p>
<p><strong>Expected Outcome:</strong> Well-tested and well-documented integration of FastDifferentiation into Symbolics.jl.</p>
<p><strong>Mentor:</strong> <a href="https://github.com/brianguenter/FastDifferentiation.jl">BrianGuenter</a></p>
<h2 id="ferritejl_-_finite_element_toolbox"><a href="#ferritejl_-_finite_element_toolbox" class="header-anchor">Ferrite.jl - Finite Element Toolbox</a></h2>
<p><a href="https://github.com/ferrite-fem/Ferrite.jl">Ferrite.jl</a> is a Julia package providing the basic building blocks to develop finite element simulations of partial differential equations. The package provides extensive examples to start from and is designed as a compromise between simplicity and generality, trying to map finite element concepts 1:1 with the code in a low-level . Ferrite is actively used in teaching finite element to students at several universities across different countries &#40;e.g. Ruhr-University Bochum and Chalmers University of Technology&#41;. Further infrastructure is provided in the form of different mesh parsers and a Julia based visualizer called <a href="https://github.com/Ferrite-FEM/FerriteViz.jl">FerriteViz.jl</a>.</p>
<p>Below we provide a four of potential project ideas in <a href="https://github.com/ferrite-fem/Ferrite.jl">Ferrite.jl</a>. However, interested students should feel free to explore ideas they are interested in. Please contact any of the mentors listed below, or join the <code>#ferrite-fem</code> channel on the Julia slack to discuss. Projects in finite element visualization are also possible with <a href="https://github.com/Ferrite-FEM/FerriteViz.jl">FerriteViz.jl</a>.</p>
<h3 id="fluid-structure_interaction_example"><a href="#fluid-structure_interaction_example" class="header-anchor">Fluid-Structure Interaction Example</a></h3>
<p><strong>Difficulty</strong>: Easy-Medium &#40;depending on your specific background&#41;</p>
<p><strong>Project size</strong>: 150-300 hours</p>
<p><strong>Problem</strong>: <a href="https://github.com/ferrite-fem/Ferrite.jl">Ferrite.jl</a> is designed with the possibility to define partial differential equations on subdomains. This makes it well-suited for interface-coupled multi-physics problems, as for example fluid-structure interaction problems. However, we currently do not have an example showing this capability in our documentation. We also do not provide all necessary utilities for interface-coupled problems.</p>
<p><strong>Minimum goal</strong>: The minimal goal of this project is to create a functional and documented linear fluid-structure interaction example coupling linear elasticity with a stokes flow in a simple setup. The code should come with proper test coverage.</p>
<p><strong>Extended goal</strong>: With this minimally functional example it is possible to extend the project into different directions, e.g. optimized solvers or nonlinear fluid-structure interaction.</p>
<p><strong>Recommended skills</strong>:</p>
<ul>
<li><p>Basic knowledge the finite element method</p>
</li>
<li><p>Basic knowledge about solids or fluids</p>
</li>
<li><p>The ability &#40;or eagerness to learn&#41; to write fast code</p>
</li>
</ul>
<p><strong>Mentors</strong>: <a href="https://github.com/termi-official">Dennis Ogiermann</a> and <a href="https://github.com/fredrikekre/">Fredrik Ekre</a></p>
<h3 id="investigation_of_performant_assembly_strategies"><a href="#investigation_of_performant_assembly_strategies" class="header-anchor">Investigation of Performant Assembly Strategies</a></h3>
<p><strong>Difficulty</strong>: Medium</p>
<p><strong>Project size</strong>: 250-350 hours</p>
<p><strong>Problem</strong>: <a href="https://github.com/ferrite-fem/Ferrite.jl">Ferrite.jl</a> has an outstanding performance in single-threaded finite element simulations due to elaborate elimination of redundant workloads. However, we recently identified that the way the single-threaded assembly works makes parallel assembly memory bound, rendering the implementation for &quot;cheap&quot; assembly loops not scalable on a wide range of systems. This problem will also translate to high-order schemes, where the single-threaded strategy as is prevents certain common optimization strategies &#40;e.g. sum factorization&#41;.</p>
<p><strong>Minimum goal</strong>: As a first step towards better parallel assembly performance it is the investion of different assembly strategies. Local and global matrix-free schemes are a possibility to explore here. The code has to be properly benchmarked and tested to identify different performance problems.</p>
<p><strong>Extended goal</strong>: With this minimally functional example it is possible to extend the project into different directions, e.g. optimized matrix-free solvers or GPU assembly.</p>
<p><strong>Recommended skills</strong>:</p>
<ul>
<li><p>Basic knowledge the finite element method</p>
</li>
<li><p>Basic knowledge about benchmarking</p>
</li>
<li><p>The ability &#40;or eagerness to learn&#41; to write fast code</p>
</li>
</ul>
<p><strong>Mentors</strong>: <a href="https://github.com/koehlerson">Maximilian Köhler</a> and <a href="https://github.com/termi-official">Dennis Ogiermann</a></p>
<h2 id="simulations_of_gaussian_quantum_information"><a href="#simulations_of_gaussian_quantum_information" class="header-anchor">Simulations of Gaussian quantum information</a></h2>
<p>Quantum harmonic oscillators are important modalities for quantum computation and quantum networking. A class of them, known as Gaussian bosonic systems, are efficient to simulate on a classical computer. Although such systems do not provide quantum computational advantage, they are present in most protocols and algorithms in continuous variable quantum information. <a href="https://github.com/apkille/Gabs.jl">Gabs.jl</a> is a Julia library designed to enable fast simulations of Gaussian bosonic circuits and serve as a sandbox for quantum hardware and protocol design.</p>
<h3 id="efficient_classical_simulations_of_linear_combinations_of_gaussian_quantum_states"><a href="#efficient_classical_simulations_of_linear_combinations_of_gaussian_quantum_states" class="header-anchor">Efficient classical simulations of linear combinations of Gaussian quantum states</a></h3>
<p>Non-Gaussian quantum states cannot be simulated via their first- and second-order statistical moments in the phase space representation like Gaussian states. However, there exist fast classical algorithms for simulating superpositions of Gaussian states, which are non-Gaussian in nature. This project involves implementing such algorithmic support for analyzing certain classes of non-Gaussian states.</p>
<p><strong>Recommended skills:</strong> In-depth understanding of the quantum phase space formalism. <a href="https://journals.aps.org/pra/abstract/10.1103/PhysRevA.110.042402">This paper</a> and <a href="https://arxiv.org/abs/2404.07115">also this paper</a> are useful references.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/apkille">Andrew Kille</a> and <a href="https://github.com/Krastanov">Stefan Krastanov</a>.</p>
<p><strong>Expected duration:</strong> 175 hours &#40;but applicants can scope it as longer if they plan more extensive work&#41;</p>
<p><strong>Difficulty:</strong> Medium</p>
<h3 id="matrix_product_state_representations_of_gaussian_and_non-gaussian_quantum_states"><a href="#matrix_product_state_representations_of_gaussian_and_non-gaussian_quantum_states" class="header-anchor">Matrix product state representations of Gaussian and non-Gaussian quantum states</a></h3>
<p>A matrix product state &#40;MPS&#41; is a valuable tensor network method for simulating quantum many-body systems. In particular, large continuous variable quantum systems that contain low entanglement can be simulated extremely fast with the MPS method. This project involves implementing support for MPS representations of Gaussian and non-Gaussian systems.</p>
<p><strong>Recommended skills:</strong> In-depth understanding of the quantum phase space formalism. In addition, familiarity with tensor network methods and software such as <a href="https://github.com/ITensor/ITensors.jl">ITensors.jl</a>. For this project, <a href="https://opg.optica.org/optica/fulltext.cfm?uri&#61;optica-8-10-1306&amp;id&#61;460148">this paper</a> and <a href="https://journals.aps.org/pra/abstract/10.1103/PhysRevA.104.012415">also this paper</a> are useful references.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/apkille">Andrew Kille</a> and <a href="https://github.com/Krastanov">Stefan Krastanov</a>.</p>
<p><strong>Expected duration:</strong> 175 hours &#40;but applicants can scope it as longer if they plan more extensive work&#41;</p>
<p><strong>Difficulty:</strong> Hard</p>
<h3 id="gaussian_cluster_states"><a href="#gaussian_cluster_states" class="header-anchor">Gaussian cluster states</a></h3>
<p>Due to the technological maturity of quantum measurement schemes for photons, one-way quantum computation is an attractive approach for photonic quantum processing. In the continuous variable formalism, Gaussian cluster states serve as an important piece of the measurement-based quantum computation model. This project involves the creation of conversion tools between phase space representations of Gaussian bosonic systems and Gaussian cluster states in the graph formalism.</p>
<p><strong>Recommended skills:</strong> Understanding of the quantum phase space formalism and the measurement-based quantum computation model. <a href="https://journals.aps.org/rmp/pdf/10.1103/RevModPhys.84.621">This review article</a> and <a href="https://journals.aps.org/prxquantum/abstract/10.1103/PRXQuantum.2.030343">recent paper</a> is a useful reference.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/apkille">Andrew Kille</a> and <a href="https://github.com/Krastanov">Stefan Krastanov</a>.</p>
<p><strong>Expected duration:</strong> 175 hours &#40;but applicants can scope it as longer if they plan more extensive work&#41;</p>
<p><strong>Difficulty:</strong> Easy</p>
<h2 id="graph_neural_networks"><a href="#graph_neural_networks" class="header-anchor">Graph Neural Networks</a></h2>
<p>Graph Neural Networks &#40;GNN&#41; are deep learning models that are well adapted to data in the form of graphs with feature vectors associated with nodes and edges. GNNs are a growing area of research and find many applications in complex network analysis, relational reasoning, combinatorial optimization, molecule generation, and many other fields. </p>
<p><a href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl">GraphNeuralNetworks.jl</a> is a pure Julia package for GNNs equipped with many features. It implements common graph convolutional layers, with CUDA support and graph batching for fast parallel operations. There are several ways by which the package could be improved.</p>
<h4 id="adding_models_and_examples"><a href="#adding_models_and_examples" class="header-anchor">Adding models and examples</a></h4>
<p>As part of the documentation and for bootstrapping new projects, we want to add fully worked-out examples and applications of graph neural networks. We can start with entry-level tutorials and progressively introduce the reader to more advanced features. </p>
<p><strong>Duration</strong>: 175h.  </p>
<p><strong>Expected difficulty</strong>: easy.  </p>
<p><strong>Expected outcome</strong>: A few pedagogical and more advanced examples of graph neural network applications.</p>
<h4 id="adding_graph_datasets"><a href="#adding_graph_datasets" class="header-anchor">Adding graph datasets</a></h4>
<p>Provide Julia-friendly wrappers for common graph datasets in <a href="https://github.com/JuliaML/MLDatasets.jl"><code>MLDatasets.jl</code></a>. Create convenient interfaces for the Julia ML and data ecosystem. </p>
<p><strong>Duration</strong>: 175h.  </p>
<p><strong>Expected difficulty</strong>: easy.  </p>
<p><strong>Expected outcome</strong>: A large collection of graph datasets easily available to the Julia ecosystem.</p>
<h4 id="improving_performance_using_sparse_linear_algebra"><a href="#improving_performance_using_sparse_linear_algebra" class="header-anchor">Improving performance using sparse linear algebra </a></h4>
<p>Many graph convolutional layers can be expressed as non-materializing algebraic operations involving the adjacency matrix instead of the slower and more memory-consuming gather/scatter mechanism. We aim at extending as far as possible and in a gpu-friendly way these <em>fused</em> implementation. The project will involve fixing some outstanding issues in CUDA.jl that are blocking sparse adjacency matrix support on GPU.</p>
<p><strong>Duration</strong>: 350h.</p>
<p><strong>Expected difficulty</strong>: hard.</p>
<p><strong>Expected outcome</strong>: A noticeable performance increase for many graph convolutional operations.</p>
<h4 id="support_for_amgdpu_and_apple_silicon"><a href="#support_for_amgdpu_and_apple_silicon" class="header-anchor">Support for AMGDPU and Apple Silicon</a></h4>
<p>We currently support scatter/gather operation only on CPU and CUDA hardware. We aim to extend this to AMDGPU and Apple Silicon leveraging KernelAbstractions.jl, AMDGPU.jl, and Metal.jl.</p>
<p><strong>Duration</strong>: 175h.</p>
<p><strong>Expected difficulty</strong>: medium.</p>
<p><strong>Expected outcome</strong>: Graph convolution speedup for AMD GPU and Apple hardware, performance roughly on par with CUDA.</p>
<h3 id="mentors"><a href="#mentors" class="header-anchor">Mentors </a></h3>
<p><a href="https://github.com/CarloLucibello">Carlo Lucibello</a> &#40;author of <a href="https://github.com/JuliaGraphs/GraphNeuralNetworks.jl">GraphNeuralNetworks.jl</a>&#41;. Feel free to contact me on the <a href="https://Julialang.slack.com/">Julia Slack Workspace</a> or by opening an issue in the GitHub repo.</p>
<h2 id="gpu_projects"><a href="#gpu_projects" class="header-anchor">GPU Projects</a></h2>
<p><a href="https://github.com/JuliaGPU">JuliaGPU</a> provides a suite of packages for programming GPUs in Julia. We have support for AMD, NVIDIA and Intel GPUs through various backends, unified by high-level array abstractions and a common programming model based on kernel programming.</p>
<h3 id="improving_gpu_stack_portability"><a href="#improving_gpu_stack_portability" class="header-anchor">Improving GPU Stack Portability</a></h3>
<p><strong>Difficulty:</strong> Medium</p>
<p><strong>Duration:</strong> 175 or 350 hours &#40;the scope of functionality to port can be adjusted accordingly&#41;</p>
<p><strong>Description:</strong> The Julia GPU stack consists of several layers, from low-level vendor-specific packages like CUDA.jl to high-level abstractions like GPUArrays.jl. While the high-level packages aim to be vendor-agnostic, many optimized operations are still implemented in vendor-specific ways. This project aims to improve portability by moving these implementations to GPUArrays.jl using KernelAbstractions.jl.</p>
<p>The project will involve:</p>
<ul>
<li><p>Identifying vendor-specific kernel implementations in packages like CUDA.jl</p>
</li>
<li><p>Porting these kernels to KernelAbstractions.jl in GPUArrays.jl</p>
</li>
<li><p>Improving KernelAbstractions.jl where needed to support these kernels</p>
</li>
<li><p>Ensuring performance remains competitive with vendor-specific implementations</p>
</li>
<li><p>Adding tests to verify correctness across different GPU backends</p>
</li>
</ul>
<p><strong>Required Skills:</strong></p>
<ul>
<li><p>Experience with Julia programming</p>
</li>
<li><p>Familiarity with GPU programming concepts</p>
</li>
<li><p>Experience with GPU programming in Julia is a plus</p>
</li>
<li><p>Understanding of performance optimization</p>
</li>
</ul>
<p><strong>Expected Results:</strong> A set of optimized GPU kernels in GPUArrays.jl that are vendor-agnostic and performant across different GPU backends. This will improve the portability of the Julia GPU stack and make it easier to support new GPU architectures.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/maleadt">Tim Besard</a>, <a href="https://github.com/vchuravy">Valentin Churavy</a></p>
<h2 id="herbjl_projects"><a href="#herbjl_projects" class="header-anchor">Herb.jl Projects</a></h2>
<p><img src="https://raw.githubusercontent.com/Herb-AI/Herb.jl/refs/heads/documentation/docs/src/assets/herb.png" alt="Herb Logo" /></p>
<p>Wouldn’t it be great if Julia would program itself? Tell it what you want, Julia magic happens, and you get your program directly. We introduce Herb.jl, a library written in Julia that gets us a step closer to our big goal. <a href="https://herb-ai.github.io/">Herb.jl</a> is a library for program synthesis: The task of automatically generating programs from a given specification. Here, “a program” could be anything, from an actual Python program over moves in chess to the synthesis of biochemical molecules. There are numerous works on program synthesis, all speaking a different language in code and terminology. We want to make developing, comparing, and applying ideas in program synthesis easier.</p>
<p>Herb’s main goal is, therefore, two-fold. First, we aim to provide a toolbox for 1. developing new program synthesizers or 2. easily re-implementing existing ones. Second, we aim to unify many different flavors of program synthesis under a joint framework, making program synthesizers easy to use on new problems.</p>
<p>If you have any questions or ideas, please <a href="mailto:t.r.hinnerichs@tudelft.nl">contact Tilman</a>.</p>
<h3 id="project_1_optimizations"><a href="#project_1_optimizations" class="header-anchor">Project 1: Optimizations</a></h3>
<p><strong>Difficulty:</strong> Medium</p>
<p><strong>Estimated Duration:</strong> 350 hours</p>
<p><strong>Project Overview:</strong> <code>Herb.jl</code> has an outstanding performance in enumerating programs. Every generated program also needs to be evaluated, making evaluation the main bottleneck in finding a suitable program. We want to improve this aspect by leveraging various well-engineered projects from the Julia community.</p>
<p>First, we have so far lessened the burden of evaluation by developing custom interpreters. This is time-consuming and error-prone, so we would like to avoid it. The core challenge here is that the explore programs don&#39;t have a fixed structure and are constructed during synthesis; therefore, they cannot be compiled ahead of time. The Julia package <code>DynamicExpressions.jl</code> is developed to overcome this exact problem, allowing for &quot;ridiculously fast symbolic expressions&quot;. We would like to integrate <code>DynamicExpressions.jl</code> into our ecosystem and get a faster evaluation of Julia programs <em>for free</em>.</p>
<p>Second, Herb is limited to Julia so far. Our goal is, however, to make Herb a <em>language agnostic</em> program synthesis library. We would like to extend Herb with connections to other interpreters for common languages like Python, Java, Prolog, et cetera. This would make it possible for Herb users to use any programming language that fits their needs.</p>
<p>Third, another crucial aspect of every program synthesis engine is the construction of candidate programs. State-of-the-art program synthesis tools, like CVC5, have invested significant time into optimizing the program construction step, resulting in significantly improved performance. We want to map these ideas into Herb.</p>
<p><strong>Minimum goal:</strong> Connect <code>DynamicExpressions.jl</code> to <code>Herb.jl</code>. This involves implementing the expression interface from <code>DynamicExpressions.jl</code> for <code>Herb.jl</code>’s expression tree formulation.</p>
<p><strong>Extended goal:</strong> Add support for at least one non-Julia program interpreter or add tricks from CVC5 to Herb.</p>
<p><strong>Recommended skills:</strong></p>
<ul>
<li><p>basic knowledge of data structures</p>
</li>
<li><p>interest in program optimization</p>
</li>
<li><p>the eagerness to learn to write and optimize code</p>
</li>
</ul>
<p><strong>Mentors:</strong> Reuben Gardos-Reid, Tilman Hinnerichs and Sebastijan Dumancic</p>
<p><strong>Some literature:</strong></p>
<ul>
<li><p>The Program Synthesis book &#40;by Gulwani et al., <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/10/program_synthesis_now.pdf">link</a></p>
</li>
<li><p>CVC4SY paper: <a href="https://link.springer.com/chapter/10.1007/978-3-030-25543-5_5">link</a></p>
</li>
<li><p><code>DynamicExpression.jl</code>: <a href="https://ai.damtp.cam.ac.uk/dynamicexpressions/dev/">link</a></p>
</li>
<li><p>Our website: <a href="https://herb-ai.github.io/">link</a></p>
</li>
</ul>
<h3 id="project_2_herblearn_integration"><a href="#project_2_herblearn_integration" class="header-anchor">Project 2: HerbLearn Integration</a></h3>
<p><strong>Difficulty:</strong> Medium</p>
<p><strong>Estimated Duration:</strong> 350h</p>
<p><strong>Problem description:</strong> Neurally-guided program synthesizers form a popular class of synthesizers, which learn a heuristic to guide program generation. Following Herb&#39;s paradigm to unify the field, we want to reach the same goal for this sub-field. Specifically, learning guiding policies comprise the same building blocks of 1. program sampling, 2. program-data-encoding, 3. policy learning with respect to a loss function, and 4. deploying that strategy.</p>
<p>In this project, we want to implement these building blocks to allow researchers to reuse the modules directly. To guide this project, we implemented a template structure to follow and extend.</p>
<p><strong>Minimum goal:</strong> Implement a naive but modular strategy for all four steps. To allow for easy integration of with existing models, we aim to implement the machine learning part using Flux.jl.</p>
<p><strong>Extended goal:</strong> The extended goal is to deepen one or more of these modules that fit the student&#39;s interests. The literature provides numerous ideas on how to make all four steps smarter individually. Concretely, this could include</p>
<ul>
<li><p>smarter program-sampling,</p>
</li>
<li><p>different program encoding strategies from the literature,</p>
</li>
<li><p>implementing and applying different loss functions, and</p>
</li>
<li><p>incorporating this with different search procedures.</p>
</li>
</ul>
<p><strong>Recommended skills:</strong></p>
<ul>
<li><p>Basic knowledge of machine learning principles &#40;neural networks, model training, ...&#41;</p>
</li>
<li><p>Preferably prior experiences with Flux.jl</p>
</li>
</ul>
<p><strong>Mentors:</strong> Tilman Hinnerichs, Reuben Gardos-Reid and Sebastijan Dumancic</p>
<p><strong>Some literature:</strong></p>
<ul>
<li><p>The Program Synthesis book &#40;by Gulwani et al., <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/10/program_synthesis_now.pdf">link</a></p>
</li>
<li><p>Our website: <a href="https://herb-ai.github.io/">https://herb-ai.github.io/</a></p>
</li>
<li><p>BUSTLE: Bottom-up Program Synthesis through learning-guided exploration: <a href="https://arxiv.org/pdf/2007.14381">link</a></p>
</li>
<li><p>DeepCoder <a href="https://arxiv.org/pdf/1611.01989">link</a></p>
</li>
<li><p>DreamCoder <a href="https://dl.acm.org/doi/pdf/10.1145/3453483.3454080">link</a></p>
</li>
</ul>
<h2 id="high_performance_and_parallel_computing_projects_summer_of_code"><a href="#high_performance_and_parallel_computing_projects_summer_of_code" class="header-anchor">High Performance and Parallel Computing Projects – Summer of Code</a></h2>
<p>Julia is emerging as a serious tool for technical computing and is ideally suited for the ever-growing needs of big data analytics. This set of proposed projects addresses specific areas for improvement in analytics algorithms and distributed data management.</p>
<h3 id="distributed_training"><a href="#distributed_training" class="header-anchor">Distributed Training</a></h3>
<p><strong>Difficulty:</strong> Hard &#40;350h&#41;</p>
<p>Add a distributed training API for Flux models built on top of <a href="https://github.com/JuliaParallel/Dagger.jl">Dagger.jl</a>. More detailed milestones include building Dagger.jl abstractions for <a href="https://github.com/JuliaParallel/UCX.jl">UCX.jl</a>, then building tools to map Flux models into data parallel Dagger DAGs. The final result should demonstrate a Flux model training with multiple devices in parallel via the Dagger.jl APIs. A stretch goal will include mapping operations with a model to a DAG to facilitate model parallelism as well.</p>
<p>There are projects now that host the building blocks: <a href="https://github.com/FluxML/DaggerFlux.jl">DaggerFlux.jl</a> and <a href="https://github.com/DhairyaLGandhi/ResNetImageNet.jl">Distributed Data Parallel Training</a> which can serve as jumping off points.</p>
<p><strong>Skills:</strong> Familiarity with UCX, representing execution models as DAGs, Flux.jl, CUDA.jl and data/model parallelism in machine learning</p>
<p><strong>Mentors:</strong> <a href="https://github.com/jpsamaroo">Julian Samaroo</a>, and <a href="https://github.com/DhairyaLGandhi">Dhairya Gandhi</a></p>
<h3 id="optimizing_gpu_scheduler_in_daggerjl_with_multistreams"><a href="#optimizing_gpu_scheduler_in_daggerjl_with_multistreams" class="header-anchor">Optimizing GPU scheduler in Dagger.jl with Multistreams</a></h3>
<p><strong>Difficulty:</strong> Hard &#40;350h&#41;</p>
<p>This project aims to explore and enhance GPU performance by integrating <a href="https://github.com/JuliaParallel/Dagger.jl">Dagger.jl</a>, Julia’s high-performance parallel computing framework, with GPU multistream capabilities. Dagger.jl enables task-based parallelism, allowing complex computations to be broken down into smaller, manageable tasks that can be efficiently scheduled across computing resources. By incorporating GPU multistreams, students will investigate how multiple streams can be used to overlap data transfers with kernel executions, enabling concurrent operations on the GPU. This overlapping reduces idle times, as data movement and computations occur simultaneously, thus maximizing GPU resource utilization. The project will focus on designing and implementing parallel workflows where independent tasks are executed concurrently, leveraging Dagger’s dynamic task scheduling and GPU’s ability to manage multiple streams effectively. Students will experiment with different workload patterns, measure performance improvements, and analyze the impact of multistream execution on throughput and latency. Through performance benchmarking and optimization, this project will provide hands-on experience in GPU programming, parallel algorithm design, and high-performance computing, equipping students with valuable skills for tackling real-world scientific and data-intensive applications.</p>
<p>There are projects now that host the building blocks: <a href="https://github.com/JuliaGPU/DaggerGPU.jl">DaggerGPU.jl</a> and <a href="https://github.com/JuliaParallel/Dagger.jl">Dagger.jl</a> which can serve as jumping off points.</p>
<p><strong>Skills:</strong> Familiarity with GPU, representing execution models as DAGs, CUDA.jl</p>
<p><strong>Mentors:</strong> <a href="https://github.com/jpsamaroo">Julian Samaroo</a>, and <a href="https://github.com/Rabab53">Rabab Alomairy</a></p>
<h3 id="distributed_linear_algebra"><a href="#distributed_linear_algebra" class="header-anchor">Distributed Linear Algebra</a></h3>
<p><strong>Difficulty:</strong> Hard &#40;350h&#41;</p>
<p>Add distributed linear algebra capabilities to Dagger.jl. This project will involve building abstractions for distributed linear algebra operations, such as matrix multiplication, matrix factorizations, and different data distribution schemes &#40;cyclic, block-cyclic, 2D, 3D&#41;. The student will build on top of Dagger.jl to enable distributed linear algebra operations across multiple devices. The final result should demonstrate a linear algebra operation running across multiple devices in parallel via the Dagger.jl APIs.</p>
<p><strong>Skills:</strong> Familiarity with distributed computing, numerical linear algebra, Dagger.jl</p>
<p><strong>Mentors:</strong> <a href="https://github.com/fda-tome">Felipe Tomé</a>, and <a href="https://github.com/Rabab53">Rabab Alomairy</a></p>
<h3 id="optimizing_mpi_integration_in_daggerjl"><a href="#optimizing_mpi_integration_in_daggerjl" class="header-anchor">Optimizing MPI integration in Dagger.jl</a></h3>
<p><strong>Difficulty:</strong> Hard &#40;350h&#41;</p>
<p>This project aims to enhance the performance of the already implemented MPI integration in Dagger.jl. The student will investigate and optimize the communication patterns between ranks, focusing on reducing communication overhead and latency. The project will involve profiling and benchmarking different communication schemes, such as point-to-point, collective and Random Memory Access &#40;RMA&#41; strategies, and analyzing their impact on performance. Through performance benchmarking and optimization, this project will provide hands-on experience in parallel algorithm design and , distributed computing, equipping students with valuable skills for tackling real-world scientific and data-intensive applications.</p>
<p><strong>Skills:</strong> Familiarity with MPI, representing execution models as DAGs, Dagger.jl, RMA</p>
<p><strong>Mentors:</strong> <a href="https://github.com/fda-tome">Felipe Tomé</a>, and <a href="https://github.com/jpsamaroo">Julian Samaroo</a></p>
<h2 id="dynamical_systems_complex_systems_nonlinear_dynamics_summer_of_code"><a href="#dynamical_systems_complex_systems_nonlinear_dynamics_summer_of_code" class="header-anchor">Dynamical systems, complex systems &amp; nonlinear dynamics – Summer of Code</a></h2>
<h3 id="agentsjl"><a href="#agentsjl" class="header-anchor">Agents.jl</a></h3>
<p><strong>Difficulty</strong>: Medium to Hard.</p>
<p><strong>Length</strong>: 175 to 350 hours depending on the project.</p>
<p><a href="https://juliadynamics.github.io/Agents.jl/stable/">Agents.jl</a> is a pure Julia framework for agent-based modeling &#40;ABM&#41;.  It has an extensive list of features, excellent performance and is easy to learn, use, and extend. Comparisons with other popular frameworks written in Python or Java &#40;NetLOGO, MASON, Mesa&#41;, show that Agents.jl outperforms all of them in computational speed, list of features and usability.</p>
<p>In this project, contributors will be paired with lead developers of Agents.jl to improve Agents.jl with more features, better performance, and overall higher polish. We are open to discuss with potential candidate a project description and outline for it&#33;</p>
<p>Possible features to implement are:</p>
<div class="tight-list"><ul>
<li><p>GPU and/or HPC support in Agents.jl by integrating existing ABM packages &#40;Vanaha.jl or CellBasedModels.jl&#41; into Agents.jl API.</p>
</li>
<li><p>Integrating Agents.jl with ReinforcementLearning.jl</p>
</li>
<li><p>Differentiation / parameter fitting of ABMs in Agents.jl by utilizing StochasticAD.jl or similar frameworks.</p>
</li>
</ul></div>
<p><strong>Pre-requisite</strong>: Having already contributed to a Julia package either in JuliaDynamics or of sufficient relevance to JuliaDynamics.</p>
<p><strong>Recommended Skills</strong>: Familiarity with agent based modelling, Agents.jl and Julia&#39;s Type System,  and achieving high-end computational performance within Julia. Research background in complex systems, sociology, agent based modelling, or nonlinear dynamics is not required but would be advantageous.</p>
<p><strong>Expected Results</strong>: Well-documented, well-tested useful new features for Agents.jl.</p>
<p><strong>Mentors</strong>: <a href="https://github.com/Datseris">George Datseris</a>.</p>
<h3 id="dynamicalsystemsjl"><a href="#dynamicalsystemsjl" class="header-anchor">DynamicalSystems.jl</a></h3>
<p><strong>Difficulty:</strong> Easy to Medium to Hard, depending on the project.</p>
<p><strong>Length</strong>: 175 to 350 hours, depending on the project.</p>
<p><a href="https://juliadynamics.github.io/DynamicalSystems.jl/latest/">DynamicalSystems.jl</a> is an <a href="https://dsweb.siam.org/The-Magazine/Article/winners-of-the-dsweb-2018-software-contest">award-winning</a> Julia software library for dynamical systems, nonlinear dynamics, deterministic chaos, and nonlinear time series analysis. It has an impressive list of features, but one can never have enough. In this project, contributors will be able to enrich DynamicalSystems.jl with new algorithms and enrich their knowledge of nonlinear dynamics and computer-assisted exploration of complex systems.</p>
<p>Here is a list of high-impact, Hard &#40;350 hours&#41; projects that we want to prioritize.</p>
<div class="tight-list"><ul>
<li><p>Local and global continuation in dynamical systems combined in one. This will be a ground-breaking feature, combining cutting edge research on multistable dynamical systems with the established bifurcation-continuation analysis.</p>
</li>
</ul></div>
<p>Other than that, we do not outline more possible projects here, and instead we invite interested candidates  to explore the documentation and list of open features of any of the subpackages of DynamicalSystems.jl. Then the candidates can reach out to one of the developers of the subpackage to devise a project outline. We strongly welcome candidates that already have potential project ideas in mind already irrespectively of the open list of issues.</p>
<p><strong>Pre-requisite</strong>: Having already contributed to a Julia package either in JuliaDynamics or of sufficient relevance to JuliaDynamics.</p>
<p><strong>Recommended Skills</strong>: Familiarity with nonlinear dynamics and/or differential equations and/or timeseries analysis based on the Julia language.</p>
<p><strong>Expected Results</strong>: Well-documented, well-tested new algorithms for DynamicalSystems.jl.</p>
<p><strong>Mentors</strong>: <a href="https://github.com/Datseris">George Datseris</a></p>
<h2 id="juliagenai_projects_summer_of_code"><a href="#juliagenai_projects_summer_of_code" class="header-anchor">JuliaGenAI Projects – Summer of Code</a></h2>
<p><img src="https://github.com/JuliaGenAI/juliagenai.org/blob/main/assets/logos/logo-256.png?raw&#61;true" alt="JuliaGenAI Logo" /></p>
<p><a href="https://github.com/JuliaGenAI">JuliaGenAI</a> is an organization focused on advancing Generative AI research and looking for its applications within the Julia programming language ecosystem. Our community comprises AI researchers, developers, and enthusiasts passionate about pushing the boundaries of Generative AI using Julia&#39;s high-performance capabilities. We strive to create innovative tools and solutions that leverage the unique strengths of Julia in handling complex AI challenges.</p>
<p><strong>IMPORTANT:</strong> There will not be any projects mentored this year by Jan Siml &#40;<code>svilupp</code>&#41; and Cameron Pfiffer &#40;<code>cpfiffer</code>&#41; due to time constraints, but we will be happy to answer any questions you might have - see below how to contact us.</p>
<p>There is a high overlap with other organizations, you should definitely check out these projects:</p>
<ul>
<li><p><a href="https://julialang.org/jsoc/gsoc/MLJ/">Projects with MLJ.jl</a> - For more traditional machine learning projects</p>
</li>
<li><p><a href="https://julialang.org/jsoc/gsoc/machine-learning/">Projects in Reinforcement Learning</a> - For projects around AlphaZero.jl</p>
</li>
<li><p><a href="https://fluxml.ai/gsoc/">Projects with FluxML</a> - For projects around Flux.jl, the backbone of Julia&#39;s deep learning ecosystem</p>
</li>
</ul>
<h3 id="how_to_contact_us"><a href="#how_to_contact_us" class="header-anchor">How to Contact Us</a></h3>
<p>Probably the easiest way is to join our <a href="https://julialang.org/slack/">JuliaLang Slack</a> and join the <code>#generative-ai</code> channel. You can also reach out to us on <a href="https://julialang.zulipchat.com/#narrow/stream/423470-generative-ai">Julia Zulip</a> or post a GitHub Issue on our website <a href="https://github.com/JuliaGenAI/juliagenai.org">JuliaGenAI</a>.</p>
<h2 id="juliahealth_projects_summer_of_code"><a href="#juliahealth_projects_summer_of_code" class="header-anchor">JuliaHealth Projects – Summer of Code</a></h2>
<p>JuliaHealth is an organization dedicated to improving healthcare by promoting open-source technologies and data standards. Our community is made up of researchers, data scientists, software developers, and healthcare professionals who are passionate about using technology to improve patient outcomes and promote data-driven decision-making. We believe that by working together and sharing our knowledge and expertise, we can create powerful tools and solutions that have the potential to transform healthcare.</p>
<h3 id="observational_health_subecosystem_projects"><a href="#observational_health_subecosystem_projects" class="header-anchor">Observational Health Subecosystem Projects</a></h3>
<h4 id="project_1_supporting_patient_level_prediction_pipelines_within_juliahealth"><a href="#project_1_supporting_patient_level_prediction_pipelines_within_juliahealth" class="header-anchor">Project 1: Supporting Patient Level Prediction Pipelines within JuliaHealth</a></h4>
<p><strong>Description:</strong> Patient level prediction &#40;PLP&#41; is an important area of research in observational health research that involves using patient data to predict outcomes such as disease progression, response to treatment, and hospital readmissions. JuliaHealth is interested in developing supportive tooling for PLP that utilizes historical patient data, such as patient medical claims or electronic health records, that follow the OMOP Common Data Model &#40;OMOP CDM&#41;, a widely used data standard that allows researchers to analyze large, heterogeneous healthcare datasets in a consistent and efficient manner. For this project, we are looking for students interested in developing supportive PLP tooling within JuliaHealth.</p>
<ul>
<li><p><strong>Mentor:</strong> Jacob S. Zelko &#40;aka TheCedarPrince&#41; &#91;email: jacobszelko@gmail.com&#93;</p>
</li>
<li><p><strong>Difficulty</strong>: Medium</p>
</li>
<li><p><strong>Duration</strong>: 175 hours</p>
</li>
<li><p><strong>Suggested Skills and Background</strong>:</p>
<ul>
<li><p>Experience with Julia</p>
</li>
<li><p>Exposure to machine learning concepts and ideas</p>
</li>
<li><p>Familiarity with some of the following Julia packages would be a strong asset:</p>
<ul>
<li><p>DataFrames.jl</p>
</li>
<li><p>OMOPCDMCohortCreator.jl</p>
</li>
<li><p>MLJ.jl</p>
</li>
<li><p>ModelingToolkit.jl</p>
</li>
</ul>
</li>
<li><p>Comfort with the OMOP Common Data Model &#40;or a willingness to learn&#41;</p>
</li>
</ul>
</li>
<li><p><strong>Outcomes:</strong></p>
</li>
</ul>
<p>This project will be very experimental and exploratory in nature. To constrain the expectations for this project, here is a possible approach students will follow while working on this project:</p>
<ul>
<li><p>Review existing literature on approaches to PLP</p>
</li>
<li><p>Familiarize oneself with tools for machine learning and prediction within the Julia ecosystem</p>
</li>
<li><p>Develop infrastructure needed for doing PLP within the JuliaHealth ecosystem such as:</p>
<ul>
<li><p>Consistent DataFrames.jl interface</p>
</li>
<li><p>Data harmonization methods</p>
</li>
<li><p>Sampling considerations for large scale patient data</p>
</li>
</ul>
</li>
<li><p>Document findings and novel software</p>
</li>
</ul>
<p>In whatever functionality that gets developed for tools within JuliaHealth, it will also be expected for students to contribute to the existing package documentation to highlight how new features can be used. Another perspective of this project is that its intended goal is to provide the foundational support needed within JuliaHealth to better accommodate multiple modalities of data available within public health settings. The long term goal is to use the development of foundational tooling with JuliaHealth to better support patient level prediction workflows across observational health data and additional information such as survey data, social determinants of health data, and climate data.</p>
<p>Additionally, depending on the success of the package, there is a potential to run experiments on actual patient data to generate actual patient population insights based on a chosen research question. This could possibly turn into a separate research paper, conference submission, or poster submission. Whatever may occur in this situation will be supported by project mentors.</p>
<h2 id="medical_imaging_subecosystem_projects"><a href="#medical_imaging_subecosystem_projects" class="header-anchor">Medical Imaging Subecosystem Projects</a></h2>
<h2 id="julia_radiomics"><a href="#julia_radiomics" class="header-anchor">Julia Radiomics</a></h2>
<p><strong>Project Title:</strong> Julia Radiomics   <strong>Difficulty:</strong> Medium   <strong>Duration:</strong> 375 hours &#40;22 Weeks&#41;   <strong>Mentor:</strong> Jakub Mitura  </p>
<h3 id="description"><a href="#description" class="header-anchor">Description</a></h3>
<p>Radiomic features are quantitative metrics extracted from medical images using data-characterization algorithms. These features capture tissue and lesion characteristics, such as heterogeneity and shape, which may provide valuable insights beyond what the naked eye can perceive.</p>
<p>This project aims to implement algorithms for extracting radiomic features from 2D and 3D medical images, similar to PyRadiomics, using Julia. The implementation will include Gray Level Co-occurrence Matrix &#40;GLCM&#41;, Gray Level Size Zone Matrix &#40;GLSZM&#41;, Gray Level Run Length Matrix &#40;GLRM&#41;, Neighborhood Gray Tone Difference Matrix &#40;NGTDM&#41;, and Gray Level Dependence Matrix &#40;GLDM&#41;. The extracted features will be validated against PyRadiomics and applied to medical imaging data, such as the AutoPET dataset, to demonstrate the methodology. </p>
<h3 id="deliverables"><a href="#deliverables" class="header-anchor">Deliverables</a></h3>
<h4 id="implementation_of_radiomic_feature_extraction_algorithms"><a href="#implementation_of_radiomic_feature_extraction_algorithms" class="header-anchor">Implementation of Radiomic Feature Extraction Algorithms</a></h4>
<ul>
<li><p><strong>First Group:</strong> GLCM, GLSZM, GLRM</p>
</li>
<li><p><strong>Second Group:</strong> NGTDM, GLDM</p>
</li>
</ul>
<h4 id="feature_extraction_pipeline"><a href="#feature_extraction_pipeline" class="header-anchor">Feature Extraction Pipeline</a></h4>
<ul>
<li><p>Extract all features from segmented lesions in PET and CT modalities.</p>
</li>
<li><p>Use MedImages.jl for image handling.</p>
</li>
<li><p>Leverage KernelAbstractions.jl for performance optimization where possible.</p>
</li>
</ul>
<h4 id="validation"><a href="#validation" class="header-anchor">Validation</a></h4>
<ul>
<li><p>Compare extracted features against PyRadiomics outputs.</p>
</li>
<li><p>Ensure statistical equivalence in extracted features.</p>
</li>
</ul>
<h4 id="final_report_code_repository"><a href="#final_report_code_repository" class="header-anchor">Final Report &amp; Code Repository</a></h4>
<ul>
<li><p>Methodology, results, benchmarking.</p>
</li>
<li><p>Public GitHub repository under an MIT license.</p>
</li>
</ul>
<h3 id="success_criteria_and_timeline"><a href="#success_criteria_and_timeline" class="header-anchor">Success Criteria and Timeline</a></h3>
<h4 id="literature_review_and_setup_3_weeks"><a href="#literature_review_and_setup_3_weeks" class="header-anchor"><ol>
<li><p>Literature Review and Setup &#40;3 Weeks&#41;</p>
</li>
</ol>
</a></h4>
<ul>
<li><p>Review PyRadiomics documentation, MedImages.jl, KernelAbstractions.jl APIs, and AutoPET dataset structure.</p>
</li>
<li><p><strong>Success Criteria:</strong> Understanding of feature definitions, dataset access, and GPU kernel design.</p>
</li>
</ul>
<h4 id="ol_start2_feature_implementation_6_weeks"><a href="#ol_start2_feature_implementation_6_weeks" class="header-anchor"><ol start="2">
<li><p>Feature Implementation &#40;6 Weeks&#41;</p>
</li>
</ol>
</a></h4>
<ul>
<li><p>Implement GLCM, GLSZM, GLRM, NGTDM, and GLDM matrices.</p>
</li>
<li><p>Validate outputs against PyRadiomics &#40;&gt;90&#37; similarity in unit tests&#41;.</p>
</li>
<li><p><strong>Success Criteria:</strong> GPU-accelerated implementation for 3D volumes.</p>
</li>
</ul>
<h4 id="ol_start3_feature_extraction_pipeline_4_weeks"><a href="#ol_start3_feature_extraction_pipeline_4_weeks" class="header-anchor"><ol start="3">
<li><p>Feature Extraction Pipeline &#40;4 Weeks&#41;</p>
</li>
</ol>
</a></h4>
<ul>
<li><p>Build a pipeline to process AutoPET lesions using MedImages.jl.</p>
</li>
<li><p><strong>Success Criteria:</strong> Extraction of 100&#43; features per lesion, support for batch processing.</p>
</li>
</ul>
<h4 id="ol_start4_validation_3_weeks"><a href="#ol_start4_validation_3_weeks" class="header-anchor"><ol start="4">
<li><p>Validation &#40;3 Weeks&#41;</p>
</li>
</ol>
</a></h4>
<ul>
<li><p>Compare Julia feature extraction results with PyRadiomics.</p>
</li>
<li><p><strong>Success Criteria:</strong> Statistical equivalence &#40;e.g., t-test p &gt; 0.05&#41;, with documented discrepancies &lt;5&#37;.</p>
</li>
</ul>
<h4 id="ol_start5_documentation_and_packaging_4_weeks"><a href="#ol_start5_documentation_and_packaging_4_weeks" class="header-anchor"><ol start="5">
<li><p>Documentation and Packaging &#40;4 Weeks&#41;</p>
</li>
</ol>
</a></h4>
<ul>
<li><p>Write documentation for the Julia-based radiomics library.</p>
</li>
<li><p>Write automated tests for the proper functioning of the library.</p>
</li>
<li><p>Register the package in the Julia package registry.</p>
</li>
<li><p><strong>Success Criteria:</strong> The final working library is successfully available in the Julia ecosystem.</p>
</li>
</ul>
<h4 id="ol_start6_reporting_2_weeks"><a href="#ol_start6_reporting_2_weeks" class="header-anchor"><ol start="6">
<li><p>Reporting &#40;2 Weeks&#41;</p>
</li>
</ol>
</a></h4>
<ul>
<li><p>Document methodology, results, and benchmarking.</p>
</li>
<li><p><strong>Success Criteria:</strong> Reproducible code, Jupyter notebooks, open-source repository.</p>
</li>
</ul>
<h3 id="stretch_goals"><a href="#stretch_goals" class="header-anchor">Stretch Goals</a></h3>
<ul>
<li><p>Implementation of additional radiomic features such as:</p>
<ul>
<li><p>Wavelet Features &#40;Transform-based texture analysis&#41;</p>
</li>
<li><p>Fractal Analysis &#40;Estimating complexity in medical images&#41;</p>
</li>
<li><p>Laplacian of Gaussian &#40;LoG&#41; Features &#40;Edge detection-based feature extraction&#41;</p>
</li>
</ul>
</li>
<li><p>Optimized parallel computation using GPU acceleration in KernelAbstractions.jl.</p>
</li>
<li><p>Implementation of an interactive Julia-based visualization tool for extracted radiomic features.</p>
</li>
</ul>
<h3 id="clarification"><a href="#clarification" class="header-anchor">Clarification</a></h3>
<p>This implementation will be done entirely in Julia, and Python will not be used in any part of the implementation.   Any cross-validation with PyRadiomics is purely for benchmarking purposes.</p>
<h3 id="importance_and_impact"><a href="#importance_and_impact" class="header-anchor">Importance and Impact</a></h3>
<h4 id="technical_impact"><a href="#technical_impact" class="header-anchor">Technical Impact</a></h4>
<ul>
<li><p><strong>Julia Ecosystem Growth:</strong> First native Radiomics toolkit in Julia.</p>
</li>
<li><p><strong>GPU Acceleration:</strong> Utilizes KernelAbstractions.jl for efficient 3D feature extraction.</p>
</li>
<li><p><strong>Reproducibility:</strong> Open-source implementation ensures transparency in radiomics research.</p>
</li>
</ul>
<h4 id="clinical_impact"><a href="#clinical_impact" class="header-anchor">Clinical Impact</a></h4>
<ul>
<li><p><strong>Cancer Differentiation:</strong> Model insights may aid in non-invasive cancer subtyping.</p>
</li>
<li><p><strong>Standardization:</strong> Cross-tool validation enhances study comparability across different platforms.</p>
</li>
</ul>
<h4 id="community_impact"><a href="#community_impact" class="header-anchor">Community Impact</a></h4>
<ul>
<li><p><strong>Foundation for Future Work:</strong> Enables Julia-based radiomics pipelines for projects like TCIA.</p>
</li>
<li><p><strong>Educational Value:</strong> Demonstrates GPU-accelerated medical image processing in Julia for researchers and students.</p>
</li>
</ul>
<h3 id="references"><a href="#references" class="header-anchor">References</a></h3>
<ul>
<li><p><a href="https://pyradiomics.readthedocs.io">PyRadiomics Documentation</a></p>
</li>
<li><p><a href="https://autopet.grand-challenge.org/">AutoPET Dataset</a></p>
</li>
<li><p><a href="https://github.com/JuliaHealth/MedImages.jl">MedImages.jl</a></p>
</li>
<li><p><a href="https://github.com/JuliaGPU/KernelAbstractions.jl">KernelAbstractions.jl</a></p>
</li>
<li><p>Radiomics Research: Various studies on the clinical relevance of radiomics in medical imaging.</p>
</li>
<li><p>Kumar, V., et al. &quot;Radiomics: the process and the challenges.&quot; Magnetic Resonance Imaging, 2012.</p>
</li>
<li><p>Gillies, R.J., et al. &quot;Radiomics: images are more than pictures, they are data.&quot; Nature Reviews Cancer, 2016.</p>
</li>
<li><p>Lambin, P., et al. &quot;Radiomics: extracting more information from medical images using advanced feature analysis.&quot; European Journal of Cancer, 2012.</p>
</li>
</ul>
<h2 id="enhancing_medpipe3d_building_a_comprehensive_medical_imaging_pipeline_in_julia"><a href="#enhancing_medpipe3d_building_a_comprehensive_medical_imaging_pipeline_in_julia" class="header-anchor">Enhancing MedPipe3D: Building a Comprehensive Medical Imaging Pipeline in Julia</a></h2>
<h3 id="description__2"><a href="#description__2" class="header-anchor">Description</a></h3>
<p>MedPipe3D was created to improve integration between other parts of the small ecosystem &#40;MedEye3D, MedEval3D, and MedImage&#41;. Currently, it needs to be expanded and adapted to serve as the basis for a fully functional medical imaging pipeline.</p>
<p><strong>Mentor:</strong> Jakub Mitura &#91;email: jakub.mitura14@gmail.com&#93;</p>
<h3 id="project_difficulty_and_timeline"><a href="#project_difficulty_and_timeline" class="header-anchor">Project Difficulty and Timeline</a></h3>
<p><strong>Difficulty:</strong> Medium   <strong>Duration:</strong> 12 weeks</p>
<h3 id="required_skills_and_background"><a href="#required_skills_and_background" class="header-anchor">Required Skills and Background</a></h3>
<ul>
<li><p>Strong knowledge of the Julia programming language is required.</p>
</li>
<li><p>Experience with the following Julia packages is highly desirable:</p>
<ul>
<li><p>MedPipe3D.jl</p>
</li>
<li><p>MedEye3D.jl</p>
</li>
<li><p>MedEval3D.jl</p>
</li>
<li><p>MedImage.jl</p>
</li>
</ul>
</li>
<li><p>Familiarity with the following packages would be a valuable asset:</p>
<ul>
<li><p>Lux.jl</p>
</li>
<li><p>TensorBoard</p>
</li>
<li><p>Logging.jl</p>
</li>
</ul>
</li>
</ul>
<h3 id="potential_outcomes"><a href="#potential_outcomes" class="header-anchor">Potential Outcomes</a></h3>
<ul>
<li><p>Implement comprehensive logging with TensorBoard Integration and Error and Warning Logs with Logging.jl for better tracking and debugging.</p>
</li>
<li><p>Improve the performance of augmentations.</p>
</li>
<li><p>Enable per-layer memory usage inspection of Lux models.</p>
</li>
<li><p>Enable gradient checkpointing of chosen layers to save memory.</p>
</li>
<li><p>Support loading tabular data &#40;e.g., clinical data&#41; together with the image into the supplied model.</p>
</li>
<li><p>Enhance documentation with in-depth tutorial, code examples, and a refined README for easy onboarding.</p>
</li>
</ul>
<p>This set of changes, although time-consuming to implement, should not pose a significant issue to anyone with experience with the Julia programming language. Each feature will be implemented using existing Julia libraries and frameworks where possible. However, implementing these changes will be a huge step in making the Julia language a good alternative to Python for developing end-to-end medical imaging segmentation algorithms.</p>
<h3 id="success_criteria_and_time_needed"><a href="#success_criteria_and_time_needed" class="header-anchor">Success Criteria and Time Needed</a></h3>
<ol>
<li><p><strong>Logging:</strong> Implement logging to track the progress and debug issues - 2 weeks.</p>
</li>
<li><p><strong>Performance Improvements:</strong> Optimize the performance of augmentations to ensure efficient processing - 2 weeks.</p>
</li>
<li><p><strong>Memory Usage Inspection:</strong> Enable per-layer memory usage inspection of Lux models to monitor and optimize memory consumption - 2 weeks.</p>
</li>
<li><p><strong>Gradient Checkpointing:</strong> Enable gradient checkpointing of chosen layers to save memory during training - 4 weeks.</p>
</li>
<li><p><strong>Tabular Data Support:</strong> Support loading tabular data &#40;e.g., clinical data&#41; together with the image into the supplied model - 1 week.</p>
</li>
<li><p><strong>Documentation:</strong> Improve documentation to provide clear instructions and examples for users - 1 week.</p>
</li>
</ol>
<p><strong>Total estimated time:</strong> 12 weeks.</p>
<h3 id="why_implementation_of_these_features_is_important"><a href="#why_implementation_of_these_features_is_important" class="header-anchor">Why Implementation of These Features is Important</a></h3>
<p>Implementing these features is crucial for advancing medical imaging technology. Enhanced logging with TensorBoard integration will allow for better insight into model training. Performance improvements ensure reliable and efficient processing of large datasets. Improved documentation and memory management make the tools more accessible and usable for medical professionals, facilitating better integration into clinical workflows. Supporting tabular data alongside imaging allows for comprehensive analysis, combining clinical and imaging data to improve diagnostic accuracy and patient outcomes.</p>
<p>For each point, the mentor will also supply the person responsible for implementation with examples of required functionalities in Python or will point to the Julia libraries already implementing it &#40;that just need to be integrated&#41;.</p>
<h2 id="project_title_a_digital_twin_approach_for_advanced_supervoxel_visualization_for_multi-image_view_in_medical_imaging"><a href="#project_title_a_digital_twin_approach_for_advanced_supervoxel_visualization_for_multi-image_view_in_medical_imaging" class="header-anchor">Project Title: A Digital Twin Approach for Advanced Supervoxel Visualization for Multi-Image View in Medical Imaging</a></h2>
<h3 id="general_idea"><a href="#general_idea" class="header-anchor">General Idea</a></h3>
<p>This project aims to develop visualization and interaction software for advanced supervoxel visualization on multi-image views. Building on the experiences from MedEye3D, the project will focus on creating a tool that allows users to interact with and visualize supervoxels across different imaging modalities &#40;e.g., CT and MRI&#41; simultaneously. The software will highlight corresponding supervoxels in different images when the user hovers over them, facilitating reliable analysis even in the presence of natural elastic deformations.</p>
<h3 id="potential_outcomes__2"><a href="#potential_outcomes__2" class="header-anchor">Potential Outcomes</a></h3>
<ul>
<li><p><strong>Enhanced Visualization:</strong> A software tool that provides side-by-side views of different imaging studies, displaying supervoxel borders and highlighting corresponding supervoxels across images.</p>
</li>
<li><p><strong>Improved Interaction:</strong> An interactive interface allowing users to manually correct supervoxel associations by clicking and highlighting supervoxels in both images.</p>
</li>
<li><p><strong>Control Points Annotation:</strong> Support for annotating and displaying control points to aid in registration and user orientation.</p>
</li>
<li><p><strong>User Feedback Integration:</strong> Mechanisms for users to indicate incorrect supervoxel associations, improving the reliability of the tool.</p>
</li>
</ul>
<h3 id="success_criteria_and_time_needed__2"><a href="#success_criteria_and_time_needed__2" class="header-anchor">Success Criteria and Time Needed</a></h3>
<ul>
<li><p><strong>Software Development:</strong> &#91;10 Weeks&#93;</p>
<ul>
<li><p>Develop the core visualization tool with side-by-side image views.</p>
</li>
<li><p>Implement supervoxel border display and highlighting functionality.</p>
</li>
<li><p>Integrate control points annotation and display features.</p>
</li>
</ul>
</li>
<li><p><strong>User Interaction Features:</strong> &#91;6 Weeks&#93;</p>
<ul>
<li><p>Develop interactive features for manual correction of supervoxel associations.</p>
</li>
<li><p>Implement user feedback mechanisms for indicating incorrect associations.</p>
</li>
</ul>
</li>
<li><p><strong>Testing and Validation:</strong> &#91;2 Weeks&#93;</p>
<ul>
<li><p>Conduct extensive testing with sample medical imaging data.</p>
</li>
<li><p>Validate the tool&#39;s accuracy and reliability in highlighting corresponding supervoxels.</p>
</li>
</ul>
</li>
<li><p><strong>Documentation and User Training:</strong> &#91;2 Weeks&#93;</p>
<ul>
<li><p>Create comprehensive documentation for the software.</p>
</li>
<li><p>Develop training materials and conduct user training sessions.</p>
</li>
</ul>
</li>
<li><p><strong>Final Review and Deployment:</strong> &#91;2 Weeks&#93;</p>
<ul>
<li><p>Review the project outcomes and make necessary adjustments.</p>
</li>
<li><p>Deploy the software for use by the scientific community.</p>
</li>
</ul>
</li>
</ul>
<p>The total estimated time for the project is approximately 22 weeks. Success will be measured by the tool&#39;s ability to accurately highlight corresponding supervoxels, ease of use, and positive feedback from users in the medical imaging community.</p>
<h3 id="technical_requirements_and_expected_expertise"><a href="#technical_requirements_and_expected_expertise" class="header-anchor">Technical Requirements and Expected Expertise</a></h3>
<ul>
<li><p>Strong programming skills in Julia/C&#43;&#43;</p>
</li>
<li><p>Experience with medical imaging libraries &#40;ITK, SimpleITK, NIfTI&#41;</p>
</li>
<li><p>Familiarity with GUI development &#40;preferably ModernGL.jl&#41;</p>
</li>
<li><p>Understanding of 3D visualization techniques</p>
</li>
<li><p>Basic knowledge of medical image processing concepts</p>
</li>
<li><p>Experience with version control &#40;Git&#41;</p>
</li>
</ul>
<h3 id="tools_and_technologies"><a href="#tools_and_technologies" class="header-anchor">Tools and Technologies</a></h3>
<ul>
<li><p><strong>Primary Language:</strong> Julia</p>
</li>
<li><p><strong>GUI Framework:</strong> ModernGL.jl/ Vulkan.jl</p>
</li>
<li><p><strong>Image Processing:</strong> ITK/SimpleITK</p>
</li>
<li><p><strong>Visualization:</strong> OpenGL</p>
</li>
<li><p><strong>Building upon:</strong> MedEye3D framework</p>
</li>
</ul>
<h3 id="user_interaction_examples"><a href="#user_interaction_examples" class="header-anchor">User Interaction Examples</a></h3>
<ul>
<li><p><strong>Hovering Over Supervoxels:</strong> When the user hovers the mouse over a supervoxel in one image &#40;e.g., CT scan&#41;, the corresponding supervoxel in the other image &#40;e.g., MRI scan&#41; will be highlighted automatically.</p>
</li>
<li><p><strong>Manual Correction:</strong> If the user identifies an incorrect supervoxel association, they can click on the supervoxel in one image to freeze it, then manually find and click the correct supervoxel in the other image to establish the correct association.</p>
</li>
<li><p><strong>Control Points:</strong> Users can annotate control points by clicking on corresponding anatomical areas in both images. These points will be saved and displayed to assist in image registration and orientation.</p>
</li>
</ul>
<h3 id="importance_and_impact__2"><a href="#importance_and_impact__2" class="header-anchor">Importance and Impact</a></h3>
<p>This project is significant because it addresses the challenges of non-rigid registration in medical imaging, which is crucial for accurate diagnosis and treatment planning. By providing a reliable tool for visualizing and interacting with supervoxels across different imaging modalities, the project has the potential to:</p>
<ul>
<li><p>Enhance the accuracy of image registration and subsequent measurements.</p>
</li>
<li><p>Reduce the time required for manual registration by radiologists and nuclear medicine specialists.</p>
</li>
<li><p>Enable the development of new algorithms and methods in the medical imaging field.</p>
</li>
<li><p>Improve clinical decision-making by providing more reliable imaging data.</p>
</li>
</ul>
<p>While various medical image visualization tools exist, there is currently no software solution that specifically addresses supervoxel-based visualization across multiple imaging modalities with interactive correction capabilities. This project builds upon MedEye3D as an independent extension, enhancing its capabilities with new features for supervoxel visualization and interaction.</p>
<h3 id="visual_examples"><a href="#visual_examples" class="header-anchor">Visual Examples</a></h3>
<ol>
<li><p>2 Different Patient&#39;s MRI and CT Studies on Transversal plane with supervoxels</p>
</li>
</ol>
<p><img src="../../assets/contribute/gsoc/supervoxel_one.png" alt="MRI and CT Supervoxels" /></p>
<ol start="2">
<li><p>Highlighting the same anatomical region in both images with supervoxel display</p>
</li>
</ol>
<p><img src="../../assets/contribute/gsoc/supervoxel_two.png" alt="MRI and CT Supervoxels with same anatomical regions highlighted" /></p>
<p>Overall, this project aims to contribute to the advancement of medical imaging technology, ultimately benefiting both the scientific community and patient care. Additionally, it will serve as a support tool for digital twin projects, enhancing the reliability of image registration and subsequent measurements.</p>
<h2 id="music_data_analysis"><a href="#music_data_analysis" class="header-anchor">Music data analysis</a></h2>
<p><a href="https://github.com/JuliaMusic">JuliaMusic</a> is an organization providing packages and functionalities that allow analyzing the properties of music performances. </p>
<h3 id="midification_of_music_from_wave_files"><a href="#midification_of_music_from_wave_files" class="header-anchor">MIDIfication of music from wave files</a></h3>
<p><strong>Difficulty</strong>: Medium.</p>
<p><strong>Length</strong>: 350 hours.</p>
<p>It is easy to analyze timing and intensity fluctuations in music that is the form of MIDI data.  This format is already digitalized, and packages such as MIDI.jl and MusicManipulations.jl allow for seamless data processing. But arguably the most interesting kind of music to analyze is the live one. Live music performances are recorded in wave formats.  Some algorithms exist that can detect the &quot;onsets&quot; of music hits,  but they are typically focused only on the timing information and hence forfeit detecting e.g., the intensity of the played note. Plus, there are very few code implementations online for this problem, almost all of which are old and unmaintained. We would like to implement an algorithm in MusicProcessing.jl that given a recording of a single instrument, it can &quot;MIDIfy&quot; it, which means to digitalize it into the MIDI format.</p>
<p><strong>Recommended Skills</strong>: Background in music, familiarity with digital signal processing.</p>
<p><strong>Expected results</strong>: A well-tested, well-documented function <code>midify</code> in MusicProcessing.jl.</p>
<p><strong>Mentors</strong>: <a href="https://github.com/Datseris/">George Datseris</a>.</p>
<h2 id="juliareach"><a href="#juliareach" class="header-anchor">JuliaReach</a></h2>
<p><a href="https://github.com/JuliaReach">JuliaReach</a> is the Julia ecosystem for reachability computations of dynamical systems. Application domains of set-based reachability include formal verification, controller synthesis and estimation under uncertain model parameters or inputs. For further context reach us on the <a href="https://julialang.zulipchat.com/#narrow/stream/278609-juliareach">JuliaReach zulip</a> stream. You may also refer to the review article <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-control-071420-081941">Set Propagation Techniques for Reachability Analysis</a>.</p>
<h3 id="efficient_symbolic-numeric_set_computations"><a href="#efficient_symbolic-numeric_set_computations" class="header-anchor">Efficient symbolic-numeric set computations</a></h3>
<p><strong>Difficulty</strong>: Medium.</p>
<p><strong>Description.</strong> <a href="https://github.com/JuliaReach/LazySets.jl">LazySets</a> is the core library of JuliaReach. It provides ways to symbolically compute with geometric sets, with a focus on lazy set representations and efficient high-dimensional processing. The library has been described in the article <a href="https://proceedings.juliacon.org/papers/10.21105/jcon.00097">LazySets.jl: Scalable Symbolic-Numeric Set Computations</a>.</p>
<p>The main interest in this project is to implement algorithms that leverage the structure of the sets. Typical examples include polytopes and zonotopes &#40;convex&#41;, polynomial zonotopes and Taylor models &#40;non-convex&#41; to name a few.</p>
<p><strong>Expected Results.</strong> The goal is to implement certain efficient state-of-the-art algorithms from the literature. The code is to be documented, tested, and evaluated in benchmarks. Specific tasks may include &#40;to be driven by the interets of the candidate&#41;: efficient vertex enumeration of <a href="https://juliareach.github.io/LazySets.jl/dev/lib/sets/Zonotope/#LazySets.Zonotope">zonotopes</a>; operations on polynomial zonotopes; operations on <a href="http://archive.www6.in.tum.de/www6/Main/Publications/Althoff2011f.pdf">zonotope bundles</a>; efficient disjointness checks between different set types; <a href="https://ieeexplore.ieee.org/document/7525593">complex zonotopes</a>.</p>
<p><strong>Expected Length.</strong> 175 hours.</p>
<p><strong>Recommended Skills.</strong> Familiarity with Julia and Git/GitHub is mandatory. Familiarity with <a href="https://github.com/JuliaReach/LazySets.jl">LazySets</a> is recommended. Basic knowledge of geometric terminology is appreciated but not required.</p>
<p><strong>Mentors</strong>: <a href="https://github.com/mforets">Marcelo Forets</a>, <a href="https://github.com/schillic">Christian Schilling</a>.</p>
<h3 id="reachability_with_sparse_polynomial_zonotopes"><a href="#reachability_with_sparse_polynomial_zonotopes" class="header-anchor">Reachability with sparse polynomial zonotopes</a></h3>
<p><strong>Difficulty</strong>: Medium.</p>
<p><strong>Description.</strong> Sparse polynomial zonotopes are a new non-convex set representation that are well-suited for reachability analysis of nonlinear dynamical systems. This project is a continuation of <a href="https://summerofcode.withgoogle.com/archive/2022/projects/feZrZfQX">GSoC&#39;2022 - Reachability with sparse polynomial zonotopes</a>, which implemented the basics in <a href="https://github.com/JuliaReach/LazySets.jl">LazySets</a>.</p>
<p><strong>Expected Results.</strong> It is expected to add efficient Julia implementations of a reachability algorithm for dynamical systems in <a href="https://github.com/JuliaReach/ReachabilityAnalysis.jl">ReachabilityAnalysis</a> which leverages polynomial zonotopes. A successful project should:</p>
<ul>
<li><p>Replicate the results from the article &#91;Reachability Analysis for Linear Systems with Uncertain Parameters using Polynomial Zonotopes</p>
</li>
</ul>
<p>&#93;&#40;https://dl.acm.org/doi/abs/10.1145/3575870.3587130&#41;.</p>
<ul>
<li><p>The code shall be documented, tested, and evaluated extensively in benchmarks.</p>
</li>
</ul>
<p>For ambitious candidates it is possible to draw connections with neural-network control systems as implemented in <a href="https://github.com/JuliaReach/ClosedLoopReachability.jl">ClosedLoopReachability.jl</a>.</p>
<p><strong>Expected Length.</strong> 175 hours.</p>
<p><strong>Recommended Skills.</strong> Familiarity with Julia and Git/GitHub is mandatory. Familiarity with the mentioned Julia packages is appreciated but not required. The project does not require theoretical contributions, but it requires reading a research literature, hence a certain level of academic experience is recommended.</p>
<p><strong>Literature and related packages.</strong> <a href="https://www.youtube.com/watch?v&#61;iMtq6YeIsjA">This video</a> explains the concept of polynomial zonotopes &#40;slides <a href="https://github.com/JuliaReach/juliareach-days-3-reachathon/blob/master/Challenge_5/Challenge5_PolynomialZonotopes.pdf">here</a>&#41;. The relevant theory is described in <a href="https://arxiv.org/pdf/1901.01780">this research article</a>. There exists a Matlab implementation in <a href="https://tumcps.github.io/CORA/">CORA</a> &#40;the implementation of polynomial zonotopes can be found in <a href="https://github.com/TUMcps/CORA/tree/master/contSet/&#37;40polyZonotope">this folder</a>&#41;.</p>
<p><strong>Mentors</strong>: <a href="https://github.com/mforets">Marcelo Forets</a>, <a href="https://github.com/schillic">Christian Schilling</a>.</p>
<h3 id="improving_the_hybrid_systems_reachability_api"><a href="#improving_the_hybrid_systems_reachability_api" class="header-anchor">Improving the hybrid systems reachability API</a></h3>
<p><strong>Difficulty</strong>: Medium.</p>
<p><strong>Description.</strong> <a href="https://github.com/JuliaReach/ReachabilityAnalysis.jl">ReachabilityAnalysis</a> is a Julia library for set propagation of dynamical systems. One of the main aims is to handle systems with mixed discrete-continuous behaviors &#40;known as hybrid systems in the literature&#41;. This project will focus on enhancing the capabilities of the library and overall improvement of the ecosystem for users.</p>
<p><strong>Expected Results.</strong>   Specific tasks may include: problem-specific heuristics for hybrid systems; API for time-varying input sets; flowpipe underapproximations. The code is to be documented, tested, and evaluated in benchmarks. Integration with <a href="https://github.com/SciML/ModelingToolkit.jl">ModelingToolkit.jl</a> can also be considered if there is interest.</p>
<p><strong>Expected Length.</strong> 175 hours.</p>
<p><strong>Recommended Skills.</strong> Familiarity with Julia and Git/GitHub is mandatory. Familiarity with <a href="https://github.com/JuliaReach/LazySets.jl">LazySets</a> and <a href="https://github.com/JuliaReach/ReachabilityAnalysis.jl">ReachabilityAnalysis</a> is welcome but not required.</p>
<p><strong>Mentors</strong>: <a href="https://github.com/mforets">Marcelo Forets</a>, <a href="https://github.com/schillic">Christian Schilling</a>.</p>
<h2 id="machine_learning_projects"><a href="#machine_learning_projects" class="header-anchor">Machine Learning Projects</a></h2>
<p><strong>Note: FluxML participates as a NumFOCUS sub-organization. Head to <a href="http://fluxml.ai/gsoc/">the FluxML GSoC page</a> for their idea list.</strong></p>
<h4 id="reinforcement_learning_environments"><a href="#reinforcement_learning_environments" class="header-anchor">Reinforcement Learning Environments</a></h4>
<p>Time: 175h</p>
<p>Develop a series of reinforcement learning environments, in the spirit of the <a href="https://gym.openai.com">OpenAI Gym</a>. Although we have wrappers for the gym available, it is hard to install &#40;due to the Python dependency&#41; and, since it&#39;s written in Python and C code, we can&#39;t do more interesting things with it &#40;such as differentiate through the environments&#41;.</p>
<h5 id="expected_outcome"><a href="#expected_outcome" class="header-anchor">Expected Outcome</a></h5>
<p>A pure-Julia version of selected environments that supports a similar API and visualisation options would be valuable to anyone doing RL with Flux.</p>
<p>Mentors: <a href="https://github.com/DhairyaLGandhi/">Dhairya Gandhi</a>.</p>
<h2 id="molecular_simulation"><a href="#molecular_simulation" class="header-anchor">Molecular Simulation</a></h2>
<p>Much of science can be explained by the movement and interaction of molecules. Molecular dynamics &#40;MD&#41; is a computational technique used to explore these phenomena, from noble gases to biological macromolecules. <a href="https://github.com/JuliaMolSim/Molly.jl">Molly.jl</a> is a pure Julia package for MD, and for the simulation of physical systems more broadly. The package is currently under development with a focus on proteins and differentiable molecular simulation. There are a number of ways that the package could be improved:</p>
<ul>
<li><p><strong>Machine learning potentials &#40;duration: 175h, expected difficulty: easy to medium&#41;:</strong> in the last few years machine learning potentials have been improved significantly. Models such as ANI, ACE, NequIP and Allegro can be added to Molly.</p>
</li>
<li><p><strong>Better GPU performance &#40;duration: 175h, expected difficulty: medium&#41;:</strong> custom GPU kernels can be written to significantly speed up molecular simulation and make the performance of Molly comparable to mature software.</p>
</li>
<li><p><strong>Constraint algorithms &#40;duration: 175h, expected difficulty: medium&#41;:</strong> many simulations keep fast degrees of freedom such as bond lengths and bond angles fixed using approaches such as SHAKE, RATTLE and SETTLE. A fast implementation of these algorithms would be a valuable contribution.</p>
</li>
<li><p><strong>Electrostatic summation &#40;duration: 175h, expected difficulty: medium to hard&#41;:</strong> methods such as particle-mesh Ewald &#40;PME&#41; are in wide use for molecular simulation. Developing fast, flexible implementations and exploring compatibility with GPU acceleration and automatic differentiation would be an <a href="https://discourse.julialang.org/t/electrostatics-in-julia/41633">important contribution</a>.</p>
</li>
</ul>
<p><strong>Recommended skills:</strong> familiarity with computational chemistry, structural bioinformatics or simulating physical systems.</p>
<p><strong>Expected results:</strong> new features added to the package along with tests and relevant documentation.</p>
<p><strong>Mentor:</strong> <a href="https://github.com/jgreener64">Joe Greener</a></p>
<p><strong>Contact:</strong> feel free to ask questions via <a href="http://jgreener64.github.io">email</a> or #juliamolsim on the <a href="https://join.slack.com/t/julialang/shared_invite/zt-2a5wdtotu-H52pQQTMDOa4NwsTSgQ_lQ">Julia Slack</a>.</p>
<h2 id="numerical_projects_summer_of_code"><a href="#numerical_projects_summer_of_code" class="header-anchor">Numerical Projects – Summer of Code</a></h2>
<h3 id="numerical_linear_algebra"><a href="#numerical_linear_algebra" class="header-anchor">Numerical Linear Algebra</a></h3>
<h4 id="matrix_functions"><a href="#matrix_functions" class="header-anchor">Matrix functions</a></h4>
<p>Matrix functions map matrices onto other matrices, and can often be interpreted as generalizations of ordinary functions like sine and exponential, which map numbers to numbers. Once considered a niche province of numerical algorithms, matrix functions now appear routinely in applications to cryptography, aircraft design, nonlinear dynamics, and finance.</p>
<p>This project proposes to implement state of the art algorithms that extend the currently available matrix functions in Julia, as outlined in issue <a href="https://github.com/JuliaLang/julia/issues/5840">#5840</a>. In addition to matrix generalizations of standard functions such as real matrix powers, surds and logarithms, contributors will be challenged to design generic interfaces for lifting general scalar-valued functions to their matrix analogues for the efficient computation of arbitrary &#40;well-behaved&#41; matrix functions and their derivatives.</p>
<p><strong>Recommended Skills</strong>: A strong understanding of calculus and numerical analysis.</p>
<p><strong>Expected Results</strong>: New and faster methods for evaluating matrix functions.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/jiahao">Jiahao Chen</a>, <a href="https://github.com/stevengj">Steven Johnson</a>.</p>
<p><strong>Difficulty:</strong> Hard</p>
<h3 id="better_bignums_integration"><a href="#better_bignums_integration" class="header-anchor">Better Bignums Integration</a></h3>
<p>Julia currently supports big integers and rationals, making use of the GMP. However, GMP currently doesn&#39;t permit good integration with a garbage collector.</p>
<p>This project therefore involves exploring ways to improve BigInt, possibly including:</p>
<div class="tight-list"><ul>
<li><p>Modifying GMP to support high-performance garbage-collection</p>
</li>
<li><p>Reimplementation of aspects of BigInt in Julia</p>
</li>
<li><p>Lazy graph style APIs which can rewrite terms or apply optimisations</p>
</li>
</ul></div>
<p>This experimentation could be carried out as a package with a new implementation, or as patches over the existing implementation in Base.</p>
<p><strong>Expected Results</strong>: An implementation of BigInt in Julia with increased performance over the current one.</p>
<p><strong>Require Skills</strong>: Familiarity with extended precision numerics OR performance considerations. Familiarity either with Julia or GMP.</p>
<p><strong>Mentors</strong>: <a href="https://github.com/vtjnash">Jameson Nash</a></p>
<p><strong>Difficulty:</strong> Hard</p>
<h4 id="special_functions"><a href="#special_functions" class="header-anchor">Special functions</a></h4>
<p>As a technical computing language, Julia provides a huge number of <a href="https://en.wikipedia.org/wiki/Special_functions">special functions</a>, both in Base as well as packages such as <a href="https://github.com/JuliaStats/StatsFuns.jl">StatsFuns.jl</a>. At the moment, many of these are implemented in external libraries such as <a href="https://github.com/JuliaLang/Rmath-julia">Rmath</a> and <a href="https://github.com/JuliaLang/openspecfun">openspecfun</a>. This project would involve implementing these functions in native Julia &#40;possibly utilising the work in <a href="https://github.com/nolta/SpecialFunctions.jl">SpecialFunctions.jl</a>&#41;, seeking out opportunities for possible improvements along the way, such as supporting <code>Float32</code> and <code>BigFloat</code>, exploiting fused multiply-add operations, and improving errors and boundary cases.</p>
<p><strong>Recommended Skills</strong>: A strong understanding of calculus.</p>
<p><strong>Expected Results</strong>: New and faster methods for evaluating properties of special functions.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/stevengj">Steven Johnson</a>, <a href="https://github.com/oscardssmith">Oscar Smith</a>. Ask on Discourse or on slack</p>
<h4 id="a_julia-native_ccsa_optimization_algorithm"><a href="#a_julia-native_ccsa_optimization_algorithm" class="header-anchor">A Julia-native CCSA optimization algorithm</a></h4>
<p>The CCSA algorithm by <a href="https://epubs.siam.org/doi/10.1137/S1052623499362822">Svanberg &#40;2001&#41;</a> is a <a href="https://en.wikipedia.org/wiki/Nonlinear_programming">nonlinear programming algorithm</a> widely used in <a href="https://en.wikipedia.org/wiki/Topology_optimization">topology optimization</a> and for other large-scale optimization problems: it is a robust algorithm that can handle arbitrary nonlinear inequality constraints and huge numbers of degrees of freedom.  Moreover, the relative simplicity of the algorithm makes it possible to easily incorporate sparsity in the Jacobian matrix &#40;for handling huge numbers of constraints&#41;, approximate-Hessian preconditioners, and as special-case optimizations for affine terms in the objective or constraints.  However, currently it is only available in Julia via the <a href="https://github.com/JuliaOpt/NLopt.jl">NLopt.jl</a> interface to an external C implementation, which greatly limits its flexibility.</p>
<p><strong>Recommended Skills</strong>: Experience with nonlinear optimization algorithms and understanding of <a href="https://en.wikipedia.org/wiki/Duality_&#40;optimization&#41;">Lagrange duality</a>, familiarity with sparse matrices and other Julia data structures.</p>
<p><strong>Expected Results</strong>: A package implementing a native-Julia CCSA algorithm.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/stevengj">Steven Johnson</a>.</p>
<h2 id="plutojl_projects"><a href="#plutojl_projects" class="header-anchor">Pluto.jl projects</a></h2>
<p>Unfortunately we won&#39;t have time to mentor this year.  Check back next year&#33;</p>
<h2 id="pythia_summer_of_code"><a href="#pythia_summer_of_code" class="header-anchor">Pythia – Summer of Code</a></h2>
<h3 id="machine_learning_time_series_regression"><a href="#machine_learning_time_series_regression" class="header-anchor">Machine Learning Time Series Regression</a></h3>
<p><a href="https://github.com/ababii/Pythia.jl">Pythia</a> is a package for scalable machine learning time series forecasting and nowcasting in Julia.</p>
<p>The project mentors are <a href="https://ababii.github.io/">Andrii Babii</a> and <a href="https://www.turing.ac.uk/people/researchers/sebastian-vollmer/">Sebastian Vollmer</a>.</p>
<h3 id="machine_learning_for_nowcasting_and_forecasting"><a href="#machine_learning_for_nowcasting_and_forecasting" class="header-anchor">Machine learning for nowcasting and forecasting</a></h3>
<p>This project involves developing scalable machine learning time series regressions for nowcasting and forecasting. Nowcasting in economics is the prediction of the present, the very near future, and the very recent past state of an economic indicator. The term is a contraction of &quot;now&quot; and &quot;forecasting&quot; and originates in meteorology.</p>
<p>The objective of this project is to introduce scalable regression-based nowcasting and forecasting methodologies that demonstrated the empirical success in data-rich environment recently. Examples of existing popular packages for regression-based nowcasting on other platforms include the &quot;MIDAS Matlab Toolbox&quot;, as well as the &#39;midasr&#39; and &#39;midasml&#39; packages in R. The starting point for this project is porting the &#39;midasml&#39; package from R to Julia. Currently Pythia has the sparse-group LASSO regression functionality for forecasting.</p>
<p>The following functions are of interest: in-sample and out-of sample forecasts/nowcasts, regularized MIDAS with Legendre polynomials, visualization of nowcasts, AIC/BIC and time series cross-validation tuning, forecast evaluation, pooled and fixed effects panel data regressions for forecasting and nowcasting, HAC-based inference for sparse-group LASSO, high-dimensional Granger causality tests. Other widely used existing functions from R/Python/Matlab are also of interest.</p>
<p><strong>Recommended skills:</strong> Graduate-level knowledge of time series analysis, machine learning, and optimization is helpful.</p>
<p><strong>Expected output:</strong> The contributor is expected to produce code, documentation, visualization, and real-data examples.</p>
<p><strong>References:</strong> Contact project mentors for references.</p>
<h3 id="time_series_forecasting_at_scales"><a href="#time_series_forecasting_at_scales" class="header-anchor">Time series forecasting at scales</a></h3>
<p>Modern business applications often involve forecasting hundreds of thousands of time series. Producing such a gigantic number of reliable and high-quality forecasts is computationally challenging, which limits the scope of potential methods that can be used in practice, see, e.g., the &#39;forecast&#39;, &#39;fable&#39;, or &#39;prophet&#39; packages in R. Currently, Julia lacks the scalable time series forecasting functionality and this project aims to develop the automated data-driven and scalable time series forecasting methods.</p>
<p>The following  functionality is of interest: forecasting intermittent demand &#40;Croston, adjusted Croston, INARMA&#41;, scalable seasonal ARIMA with covariates, loss-based forecasting &#40;gradient boosting&#41;, unsupervised time series clustering, forecast combinations, unit root tests &#40;ADF, KPSS&#41;. Other widely used existing functions from R/Python/Matlab are also of interest.</p>
<p><strong>Recommended skills:</strong> Graduate-level knowledge of time series analysis is helpful.</p>
<p><strong>Expected output:</strong> The contributor is expected to produce code, documentation, visualization, and real-data examples.</p>
<p><strong>References:</strong> Contact project mentors for references.</p>
<h2 id="tools_for_simulation_of_quantum_clifford_circuits"><a href="#tools_for_simulation_of_quantum_clifford_circuits" class="header-anchor">Tools for simulation of Quantum Clifford Circuits</a></h2>
<p>Clifford circuits are a class of quantum circuits that can be simulated efficiently on a classical computer. As such, they do not provide the computational advantage expected of universal quantum computers. Nonetheless, they are extremely important, as they underpin most techniques for quantum error correction and quantum networking. Software that efficiently simulates such circuits, at the scale of thousands or more qubits, is essential to the design of quantum hardware. The <a href="https://github.com/Krastanov/QuantumClifford.jl">QuantumClifford.jl</a> Julia project enables such simulations.</p>
<h3 id="gpu_accelerated_simulator_of_clifford_circuits"><a href="#gpu_accelerated_simulator_of_clifford_circuits" class="header-anchor">GPU accelerated simulator of Clifford Circuits.</a></h3>
<p>Simulation of Clifford circuits involves significant amounts of linear algebra with boolean matrices. This enables the use of many standard computation accelerators like GPUs, as long as these accelerators support bit-wise operations. The main complications is that the elements of the matrices under consideration are usually packed in order to increase performance and lower memory usage, i.e. a vector of 64 elements would be stored as a single 64 bit integer instead of as an array of 64 bools. A Summer of Code project could consist of implement the aforementioned linear algebra operations in GPU kernels, and then seamlessly integrating them in the rest of the QuantumClifford library. At a minimum that would include <a href="https://github.com/Krastanov/QuantumClifford.jl/blob/v0.4.0/src/QuantumClifford.jl#L725">Pauli-Pauli products</a> and certain <a href="https://github.com/Krastanov/QuantumClifford.jl/blob/v0.4.0/src/symbolic_cliffords.jl">small Clifford operators</a>, but could extend to general <a href="https://github.com/Krastanov/QuantumClifford.jl/blob/v0.4.0/src/QuantumClifford.jl#L1385">stabilizer tableau multiplication</a> and even <a href="https://github.com/Krastanov/QuantumClifford.jl/blob/v0.4.0/src/QuantumClifford.jl#L985">tableau diagonalization</a>. Some of these features are already implemented, but significant polish and further improvements and implementation of missing features is needed.</p>
<p><strong>Recommended skills:</strong> Basic knowledge of the <a href="https://krastanov.github.io/QuantumClifford.jl/dev/references/">stabilizer formalism</a> used for simulating Clifford circuits. Familiarity with performance profiling tools in Julia and Julia&#39;s GPU stack, including <a href="https://github.com/JuliaGPU/KernelAbstractions.jl">KernelAbstractions</a> and <a href="https://github.com/mcabbott/Tullio.jl">Tullio</a>.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/Krastanov">Stefan Krastanov</a> <a href="mailto:stefan@krastanov.org">&lt;stefan@krastanov.org&gt;</a> and QuantumClifford.jl team members</p>
<p><strong>Expected duration:</strong> 175 hours &#40;but applicants can scope it to a longer project by including work on GPU-accelerated Gaussian elimination used in the canonicalization routines&#41;</p>
<p><strong>Difficulty:</strong> Medium if the applicant is familiar with Julia, even without understanding of Quantum Information Science &#40;but applicants can scope it to &quot;hard&quot; by including the aforementioned additional topics&#41;</p>
<h3 id="a_zoo_of_quantum_error_correcting_codes_andor_decoders"><a href="#a_zoo_of_quantum_error_correcting_codes_andor_decoders" class="header-anchor">A Zoo of Quantum Error Correcting codes and/or decoders</a></h3>
<p>Quantum Error Correcting codes are typically represented in a form similar to the parity check matrix of a classical code. This form is referred to as a Stabilizer tableaux. This project would involve creating a comprehensive library of frequently used quantum error correcting codes and/or implementing syndrome-decoding algorithms for such codes. The library already includes some simple codes and interfaces to a few decoders – adding another small code or providing a small documentation pull request could be a good way to prove competence when applying for this project. The project can be extended to a much longer one if work on decoders is included. A large part of this project would involve literature surveys. Some suggestions for codes to include: color codes, higher-dimensional topological codes, hyper graph product codes, twists in codes, newer LDPC codes, honeycomb codes, Floquet codes. Some suggestions for decoders to work on: iterative, small-set flip, ordered statistical decoding, belief propagation, neural belief propagation.</p>
<p><strong>Recommended skills:</strong> Knowledge of the <a href="https://krastanov.github.io/QuantumClifford.jl/dev/references/">stabilizer formalism</a> used for simulating Clifford circuits. Familiarity with tools like python&#39;s <code>ldpc</code>, <code>pymatching</code>, and <code>stim</code> can help. Consider checking out the <code>PyQDecoders.jl</code> julia wrapper package as well.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/Krastanov">Stefan Krastanov</a> <a href="mailto:stefan@krastanov.org">&lt;stefan@krastanov.org&gt;</a> and QuantumClifford.jl team members</p>
<p><strong>Expected duration:</strong> 175 hours &#40;but applicants can scope it as longer, depending on the list of functionality they plan to implement&#41;</p>
<p><strong>Difficulty:</strong> Medium. Easy with some basic knowledge of quantum error correction</p>
<h3 id="leftright_multiplications_with_small_gates"><a href="#leftright_multiplications_with_small_gates" class="header-anchor">Left/Right multiplications with small gates.</a></h3>
<p>Applying an n-qubit Clifford gate to an n-qubit state &#40;tableaux&#41; is an operation similar to matrix multiplication, requiring O&#40;n^3&#41; steps. However, applying a single-qubit or two-qubit gate to an n-qubit tableaux is much faster as it needs to address only one or two columns of the tableaux. This project would focus on extending the left-multiplication special cases already started in <a href="https://github.com/Krastanov/QuantumClifford.jl/blob/master/src/symbolic_cliffords.jl">symbolic_cliffords.jl</a> and creating additional right-multiplication special cases &#40;for which <a href="https://github.com/Krastanov/QuantumClifford.jl/commit/d3e84c16b7b08ef6f1bc24e2bcf98641c2fff1ab#r67183201">the Stim library is a good reference</a>&#41;.</p>
<p><strong>Recommended skills:</strong> Knowledge of the <a href="https://krastanov.github.io/QuantumClifford.jl/dev/references/">stabilizer formalism</a> used for simulating Clifford circuits. Familiarity with performance profiling tools in Julia. Understanding of C/C&#43;&#43; if you plan to use the Stim library as a reference.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/Krastanov">Stefan Krastanov</a> <a href="mailto:stefan@krastanov.org">&lt;stefan@krastanov.org&gt;</a> and QuantumClifford.jl team members</p>
<p><strong>Expected duration:</strong> 175 hours &#40;but applicants can scope it as longer if they plan for other significant optimization and API design work&#41;</p>
<p><strong>Difficulty:</strong> Easy</p>
<h3 id="generation_of_fault_tolerant_ecc_circuits_flag_qubit_circuits_and_more"><a href="#generation_of_fault_tolerant_ecc_circuits_flag_qubit_circuits_and_more" class="header-anchor">Generation of Fault Tolerant ECC Circuits, Flag Qubit Circuits and more</a></h3>
<p>The QuantumClifford library already has some <a href="https://github.com/QuantumSavory/QuantumClifford.jl/blob/v0.8.19/src/ecc/circuits.jl">support for generating different types of circuits related to error correction</a> &#40;mostly in terms of syndrome measurement circuits like Shor&#39;s&#41; and for evaluating the quality of error correcting codes and decoders. Significant improvement can be made by implementing more modern compilation schemes, especially ones relying on flag qubits.</p>
<p><strong>Recommended skills:</strong> Knowledge of the variety of flag qubit methods. Some useful references could be <a href="https://link.aps.org/accepted/10.1103/PhysRevLett.121.050502">a</a>, <a href="https://www.nature.com/articles/s41534-018-0085-z">b</a>, <a href="https://journals.aps.org/prxquantum/pdf/10.1103/PRXQuantum.1.010302">c</a>, and this <a href="https://www.youtube.com/watch?v&#61;etA9l2NUCXI">video lecture</a>.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/Krastanov">Stefan Krastanov</a> <a href="mailto:stefan@krastanov.org">&lt;stefan@krastanov.org&gt;</a> and QuantumClifford.jl team members</p>
<p><strong>Expected duration:</strong> 175 hours &#40;but applicants can scope it as longer if they plan more extensive work&#41;</p>
<p><strong>Difficulty:</strong> Hard</p>
<h3 id="measurement-based_quantum_computing_mbqc_compiler"><a href="#measurement-based_quantum_computing_mbqc_compiler" class="header-anchor">Measurement-Based Quantum Computing &#40;MBQC&#41; compiler</a></h3>
<p>The MBQC model of quantum computation has a lot of overlap with the study of Stabilizer states. This project would be about the creation of an MBQC compiler and potentially simulator in Julia. E.g. if one is given an arbitrary graph state and a circuit, how is this circuit to be compiled in an MBQC model.</p>
<p><strong>Recommended skills:</strong> Knowledge of the MBQC model of quantum computation. This <a href="https://arxiv.org/pdf/2212.11975.pdf">paper and the related python library</a> can be a useful reference. Consider also <a href="https://quantum-journal.org/papers/q-2021-03-25-421/">this reference</a>.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/Krastanov">Stefan Krastanov</a> <a href="mailto:stefan@krastanov.org">&lt;stefan@krastanov.org&gt;</a> and QuantumClifford.jl team members</p>
<p><strong>Expected duration:</strong> 175 hours &#40;but applicants can scope it as longer if they plan more extensive work&#41;</p>
<p><strong>Difficulty:</strong> Hard</p>
<h3 id="implementing_a_graph_state_simulator"><a href="#implementing_a_graph_state_simulator" class="header-anchor">Implementing a Graph State Simulator</a></h3>
<p>The graph states formalism is a way to work more efficiently with stabilizer states that have a sparse tableaux. This project would involve creation of the necessary gate simulation algorithms and conversions tools between graph formalism and stabilizer formalism &#40;some of which are <a href="https://github.com/QuantumSavory/QuantumClifford.jl/blob/master/src/graphs.jl">already available in the library</a>&#41;.</p>
<p><strong>Recommended skills:</strong> Understanding of the graph formalism. This <a href="https://arxiv.org/abs/quant-ph/0504117">paper can be a useful reference</a>.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/Krastanov">Stefan Krastanov</a> <a href="mailto:stefan@krastanov.org">&lt;stefan@krastanov.org&gt;</a> and QuantumClifford.jl team members</p>
<p><strong>Expected duration:</strong> 175 hours &#40;but applicants can scope it as longer if they plan more extensive work&#41;</p>
<p><strong>Difficulty:</strong> Medium</p>
<h3 id="simulation_of_slightly_non-clifford_circuits_and_states"><a href="#simulation_of_slightly_non-clifford_circuits_and_states" class="header-anchor">Simulation of Slightly Non-Clifford Circuits and States</a></h3>
<p>There are various techniques used to augment Clifford circuit simulators to model circuits that are only &quot;mostly&quot; Clifford. Particularly famous are the Clifford&#43;T gate simulators. This project is about implementing such extensions.</p>
<p><strong>Recommended skills:</strong> In-depth understanding of the Stabilizer formalism, and understanding of some of the extensions to that method. We have some <a href="https://github.com/QuantumSavory/QuantumClifford.jl/blob/master/src/nonclifford.jl">initial implementations</a>. This <a href="https://arxiv.org/pdf/1808.00128.pdf">IBM paper</a> can also be a useful reference for other methods.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/Krastanov">Stefan Krastanov</a> <a href="mailto:stefan@krastanov.org">&lt;stefan@krastanov.org&gt;</a> and QuantumClifford.jl team members</p>
<p><strong>Expected duration:</strong> 175 hours &#40;but applicants can scope it as longer if they plan more extensive work&#41;</p>
<p><strong>Difficulty:</strong> Hard</p>
<h3 id="magic_state_modeling_-_distillation_injection_etc"><a href="#magic_state_modeling_-_distillation_injection_etc" class="header-anchor">Magic State Modeling - Distillation, Injection, Etc</a></h3>
<p>Magic states are important non-stabilizer states that can be used for inducing non-Clifford gates in otherwise Clifford circuits. They are crucial for the creation of error-corrected universal circuits. This project would involve contributing tools for the analysis of such states and for the evaluation of distillation circuits and ECC circuits involving such states.</p>
<p><strong>Recommended skills:</strong> In-depth understanding of the theory of magic states and their use in fault tolerance.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/Krastanov">Stefan Krastanov</a> <a href="mailto:stefan@krastanov.org">&lt;stefan@krastanov.org&gt;</a> and QuantumClifford.jl team members</p>
<p><strong>Expected duration:</strong> 175 hours &#40;but applicants can scope it as longer if they plan more extensive work&#41;</p>
<p><strong>Difficulty:</strong> Hard</p>
<h2 id="quantum_optics_and_state_vector_modeling_tools"><a href="#quantum_optics_and_state_vector_modeling_tools" class="header-anchor">Quantum Optics and State Vector Modeling Tools</a></h2>
<p>The most common way to represent and model quantum states is the state vector formalism &#40;underlying Schroedinger&#39;s and Heisenberg&#39;s equations as well as many other master equations&#41;. The <a href="https://github.com/qojulia/QuantumOptics.jl">QuantumOptics.jl</a> Julia project enables such simulations, utilizing much of the uniquely powerful DiffEq infrastructure in Julia.</p>
<h3 id="gpu_accelerated_operators_and_ode_solvers"><a href="#gpu_accelerated_operators_and_ode_solvers" class="header-anchor">GPU accelerated operators and ODE solvers</a></h3>
<p>Much of the internal representation of quantum states in QuantumOptics.jl relies on standard dense arrays. Thanks to the multiple-dispatch nature of Julia, much of these objects can already work well with GPU arrays. This project would involve a thorough investigation and validation of the current interfaces to make sure they work well with GPU arrays. In particular, attention will have to be paid to the &quot;lazy&quot; operators as special kernels might need to be implemented for them.</p>
<p><strong>Recommended skills:</strong> Familiarity with performance profiling tools in Julia and Julia&#39;s GPU stack, potentially including <a href="https://github.com/JuliaGPU/KernelAbstractions.jl">KernelAbstractions</a>.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/Krastanov">Stefan Krastanov</a> <a href="mailto:stefan@krastanov.org">&lt;stefan@krastanov.org&gt;</a> and QuantumOptics.jl team members</p>
<p><strong>Expected duration:</strong> 175 hours &#40;but applicants can scope it as longer if they plan more extensive work&#41;</p>
<p><strong>Difficulty:</strong> Medium</p>
<h3 id="autodifferentiation"><a href="#autodifferentiation" class="header-anchor">Autodifferentiation</a></h3>
<p>Autodifferentiation is the capability of automatically generating efficient code to evaluate the numerical derivative of a given Julia function. Similarly to the GPU case above, much of this functionality already &quot;magically&quot; works, but there is no detailed test suite for it and no validation has been done. This project would involve implementing, validating, and testing the use of Julia autodiff tools in QuantumOptics.jl. ForwardDiff, Enzyme, Zygote, Diffractor, and AbstractDifferentiation are all tools that should have some level of validation and support, both in ODE solving and in simple operator applications.</p>
<p><strong>Recommended skills:</strong> Familiarity with the <a href="https://juliadiff.org/">Julia autodiff stack</a> and the SciML sensitivity analysis tooling. Familiarity with the difficulties to autodiff complex numbers &#40;in general and specifically in Julia&#41;. Understanding of the AbstractDifferentiation.jl package.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/Krastanov">Stefan Krastanov</a> <a href="mailto:stefan@krastanov.org">&lt;stefan@krastanov.org&gt;</a> and QuantumOptics.jl team members</p>
<p><strong>Expected duration:</strong> 175 hours &#40;but applicants can scope it as longer if they plan more extensive work&#41;</p>
<p><strong>Difficulty:</strong> Easy-to-Medium</p>
<h3 id="closer_integration_with_the_sciml_ecosystem"><a href="#closer_integration_with_the_sciml_ecosystem" class="header-anchor">Closer Integration with the SciML Ecosystem</a></h3>
<p>SciML is the umbrella organization for much of the base numerical software development in the Julia ecosystem. We already use many of their capabilities, but it would be beneficial to more closely match the interfaces they expect. This project would be heavily on the software <strong>engineering</strong> side. Formal and informal interfaces we want to support include: better support for <a href="https://github.com/qojulia/QuantumOptics.jl/issues/298">DiffEq problem types</a> &#40;currently we wrap DiffEq problems in our own infrastructure and it is difficult to reuse them in SciML&#41;; better support for broadcast operations over state objects &#40;so that we can treat them closer to normal arrays and <a href="https://github.com/qojulia/QuantumOpticsBase.jl/pull/16">we can simply provide an initial state to a DiffEq solver without having to wrap/unwrap the data</a>&#41;; relying more heavily on <a href="https://docs.sciml.ai/SciMLOperators/stable/">SciMLOperators</a> which have significant <a href="https://github.com/qojulia/QuantumOpticsBase.jl/issues/99">overlap with our lazy operators</a>.</p>
<p><strong>Recommended skills:</strong> Familiarity with the SciML stack.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/Krastanov">Stefan Krastanov</a> <a href="mailto:stefan@krastanov.org">&lt;stefan@krastanov.org&gt;</a> and QuantumOptics.jl team members</p>
<p><strong>Expected duration:</strong> 175 hours &#40;but applicants can scope it as longer if they plan more extensive work&#41;</p>
<p><strong>Difficulty:</strong> Easy</p>
<h2 id="rimujl_-_projector_quantum_monte_carlo"><a href="#rimujl_-_projector_quantum_monte_carlo" class="header-anchor">Rimu.jl - Projector Quantum Monte Carlo</a></h2>
<p><a href="https://github.com/RimuQMC/Rimu.jl">Rimu.jl</a> is a Julia package for finding ground states &#40;and low-lying excited states&#41; of quantum many-body problems with projector quantum Monte Carlo &#40;using a flavour called full configuration interaction quantum Monte Carlo, FCIQMC&#41; and with exact diagonalisation.</p>
<h3 id="ab-initio_quantum_chemistry_with_rimujl"><a href="#ab-initio_quantum_chemistry_with_rimujl" class="header-anchor">Ab-Initio Quantum Chemistry with Rimu.jl</a></h3>
<p><strong>Difficulty</strong>: Easy to medium &#40;if the recommended skills are available&#41;</p>
<p><strong>Project size</strong>: 175 - 350 hours</p>
<p><strong>Problem</strong>: <a href="https://github.com/RimuQMC/Rimu.jl">Rimu.jl</a> provides an interface for defining a custom quantum many-body Hamiltonian and currently implements a selection of model Hamiltonians &#40;e.g. variants of the Hubbard model and the Fröhlich polaron model&#41;.  The high-level goal of the project is to implement the required functionality to solve ab-initio quantum chemistry problems with <a href="https://github.com/RimuQMC/Rimu.jl">Rimu.jl</a> and embed the package into the <a href="https://github.com/JuliaMolSim">JuliaMolSim</a> ecosystem, in particular with <a href="https://github.com/fkfest/ElemCo.jl">ElemCo.jl</a>.</p>
<p><strong>Minimum goal</strong>: A minimum goal would be to enable reading in the relevant information about the molecular orbital basis set and integrals that define the molecular Hamiltonian from a file &#40;in the standard FCIDUMP format&#41; and defining an appropriate Hamiltonian type for Rimu.jl that enables its usage for exact diagonalisation and FCIQMC.</p>
<p><strong>Extended goal</strong>: An extended goal would be to make the molecular Hamiltonian efficient for FCIQMC, e.g. by finding and implementing an appropriate strategy for an excitation generator, e.g. a variant of &#40;precomputed&#41; heat-bath sampling. Another worthwhile extension would be to implement variants of the Configuration Interaction &#40;CI&#41; method by filtering the configurations to a relevant subspace &#40;e.g. CI-SD, selctive CI, etc.&#41; for the exact-diagonalisation part of Rimu.jl.</p>
<p><strong>Recommended skills</strong>:</p>
<ul>
<li><p>prior exposure to or strong interest in quantum chemistry</p>
</li>
<li><p>good to excellent Julia coding skills</p>
</li>
</ul>
<p><strong>Mentors</strong>: <a href="https://github.com/joachimbrand">Joachim Brand</a>, <a href="https://github.com/dnkats">Daniel Kats</a>, <a href="https://github.com/ElkePahl">Elke Pahl</a></p>
<p>If you are interested please get in touch by <a href="mailto:j.brand@massey.ac.nz">email</a>.</p>
<h3 id="load_balancing_rimujl_for_multi-node_hpc_calculations"><a href="#load_balancing_rimujl_for_multi-node_hpc_calculations" class="header-anchor">Load balancing Rimu.jl for multi-node &#40;HPC&#41; calculations</a></h3>
<p><strong>Difficulty</strong>: Medium to hard</p>
<p><strong>Project size</strong>: 175 - 350 hours</p>
<p><strong>Problem</strong>: <a href="https://github.com/RimuQMC/Rimu.jl">Rimu.jl</a> parallelises the workload of FCIQMC by making extensive use of native threading for shared-memory parallelism. In high-performance computing environments the primary data structure containing information about the sampled configurations and their amplitudes can further be distributed across nodes, which communicate using the MPI protocol in every time step &#40;making use of <a href="https://github.com/JuliaParallel/MPI.jl">MPI.jl</a>&#41;. In the current implementation the distribution of configurations to nodes is done passively &#40;in a pseudo-random fashion using a hashing algorithm&#41;. While this is fast and easy and usually leads to a fairly even distribution of data and work across the nodes, it does not scale very well when employing hundreds of nodes as every MPI rank has to wait for the slowest one to complete the work done at each time step.</p>
<p><strong>Minimum goal</strong>: Implement an active load-balancing approach where load information of each MPI rank is monitored and work load is shifted between nodes to even out the workload.</p>
<p><strong>Extended goal</strong>: Explore other load-balancing strategies like agent-based approaches, possibly even exploring algorithmic alternatives &#40;e.g. continuous-time Monte Carlo&#41;. Design communication protocols that take into account the network topology.</p>
<p><strong>Recommended skills</strong>:</p>
<ul>
<li><p>experience with HPC environments and MPI-style programming</p>
</li>
<li><p>good to excellent Julia coding skills</p>
</li>
</ul>
<p><strong>Mentors</strong>: <a href="https://github.com/mtsch">Matija Čufar</a>, <a href="https://github.com/joachimbrand">Joachim Brand</a></p>
<p>If you are interested please get in touch with <a href="mailto:matijacufar@gmail.com">Matija</a> or <a href="mailto:j.brand@massey.ac.nz">Joachim</a>.</p>
<h2 id="symbolic_computation_project_ideas"><a href="#symbolic_computation_project_ideas" class="header-anchor">Symbolic computation project ideas</a></h2>
<h3 id="efficient_tensor_differentiation"><a href="#efficient_tensor_differentiation" class="header-anchor">Efficient Tensor Differentiation</a></h3>
<p>Implement the <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/main-65.pdf">D* algorithm</a> for tensor expressions.</p>
<p><strong>Recommended Skills</strong>: High school/freshman calculus and basic graph theory &#40;optional&#41;</p>
<p><strong>Expected Results</strong>: A working implementation of the D* algorithm that is capable of performing efficient differentiations on tensor expressions.</p>
<p><strong>Mentors</strong>: <a href="https://github.com/YingboMa">Yingbo Ma</a></p>
<p><strong>Duration</strong>: 350 hours</p>
<h3 id="symbolic_integration_in_symbolicsjl"><a href="#symbolic_integration_in_symbolicsjl" class="header-anchor">Symbolic Integration in Symbolics.jl</a></h3>
<p>Implement the <a href="https://dspace.mit.edu/handle/1721.1/11997">heuristic approach to symbolic integration</a>. Then hook into a repository of rules such as <a href="https://rulebasedintegration.org/">RUMI</a>. See also the potential of using symbolic-numeric integration techniques &#40;https://github.com/SciML/SymbolicNumericIntegration.jl&#41;</p>
<p><strong>Recommended Skills</strong>: High school/Freshman Calculus</p>
<p><strong>Expected Results</strong>: A working implementation of symbolic integration in the Symbolics.jl library, along with documentation and tutorials demonstrating its use in scientific disciplines.</p>
<p><strong>Mentors</strong>: <a href="https://github.com/shashi">Shashi Gowda</a>, <a href="https://github.com/YingboMa">Yingbo Ma</a></p>
<p><strong>Duration</strong>: 350 hours</p>
<h3 id="xla-style_optimization_from_symbolic_tracing"><a href="#xla-style_optimization_from_symbolic_tracing" class="header-anchor">XLA-style optimization from symbolic tracing</a></h3>
<p>Julia functions that take arrays and output arrays or scalars can be traced using Symbolics.jl variables to produce a trace of operations. This output can be optimized to use fused operations or call highly specific NNLib functions. In this project you will trace through Flux.jl neural-network functions and apply optimizations on the resultant symbolic expressions. This can be mostly implemented as rule-based rewriting rules &#40;see https://github.com/JuliaSymbolics/Symbolics.jl/pull/514&#41;.</p>
<p><strong>Recommended Skills</strong>: Knowledge of space and time complexities of array operations, experience in optimizing array code.</p>
<p><strong>Mentors</strong>: <a href="https://github.com/shashi">Shashi Gowda</a></p>
<p><strong>Duration</strong>: 175 hours</p>
<h3 id="automatically_improving_floating_point_accuracy_herbie"><a href="#automatically_improving_floating_point_accuracy_herbie" class="header-anchor">Automatically improving floating point accuracy &#40;Herbie&#41;</a></h3>
<p><a href="https://herbie.uwplse.org/">Herbie</a> documents a way to optimize floating point functions so as to reduce instruction count while reorganizing operations such that floating point inaccuracies do not get magnified. It would be a great addition to have this written in Julia and have it work on Symbolics.jl expressions. An ideal implementation would use the e-graph facilities of Metatheory.jl to implement this.</p>
<p><strong>Mentors</strong>: <a href="https://github.com/shashi">Shashi Gowda</a>, <a href="https://github.com/0x0f0f0f">Alessandro Cheli</a></p>
<p><strong>Duration</strong>: 350 hours</p>
<h3 id="reparametrizing_ode_models_with_scaling_transformations"><a href="#reparametrizing_ode_models_with_scaling_transformations" class="header-anchor">Reparametrizing ODE models with scaling transformations</a></h3>
<p><strong>Project Overview:</strong> Many ODE models appearing in applications have hidden symmetries which makes the solution of data fitting problem nonunique. <a href="https://github.com/SciML/StructuralIdentifiability.jl">StructuralIdentifiability.jl</a> offers algorithms for proposing new coordinates for the model removing this redundancy. The approach used at the moment relies on heavy computations and may be very slow for larger models. Scaling is a particular type of reparametrizations which can be discovered much faster. The goal of the project would be to implement such faster algorithms &#40;adapting them to the context of identifiability assessment&#41; and integrate into StructuralIdentifiability.jl.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/sumiya11">Alexander Demin</a>, <a href="https://www.lix.polytechnique.fr/Labo/Gleb.POGUDIN/">Gleb Pogudin</a></p>
<p><strong>Project Difficulty</strong>: Medium</p>
<p><strong>Estimated Duration</strong>: 350 hours</p>
<p><strong>Ideal Candidate Profile:</strong></p>
<ul>
<li><p>Basic experience with Julia</p>
</li>
<li><p>Knowledge of linear algebra</p>
</li>
</ul>
<p><strong>Project Goals and Deliverables:</strong></p>
<ul>
<li><p>Implementation of an algorithm in Julia to perform scaling reparametrization of ODEs</p>
</li>
<li><p>Comprehensive documentation and examples</p>
</li>
<li><p>&#40;Bonus&#41; Integration with <a href="https://github.com/SciML/StructuralIdentifiability.jl">StructuralIdentifiability.jl</a></p>
</li>
</ul>
<p><strong>Useful References:</strong></p>
<ul>
<li><p><a href="https://journals.plos.org/ploscompbiol/article?id&#61;10.1371/journal.pcbi.1008248">Paper on scaling transformations</a></p>
</li>
<li><p><a href="https://inria.hal.science/hal-00668882/">More involved paper on scaling transformations</a></p>
</li>
<li><p><a href="https://desr.readthedocs.io/en/latest/intro.html">Implementation in Python</a></p>
</li>
</ul>
<h3 id="polynomialization_of_ordinary_differential_equations"><a href="#polynomialization_of_ordinary_differential_equations" class="header-anchor">Polynomialization of ordinary differential equations</a></h3>
<p><strong>Project Overview:</strong> Many ODE models arising in modeling involve nonpolynomial functions &#40;fractions, exponentials, trigonometric, etc&#41;. Polynomialization is the rewriting of nonpolynomial functions as equivalent polynomial equations. It is a necessary preprocessing step in several contexts &#40;structural identifiability, model order reduction, reaction network synthesis&#41;. The project aims at implementing a package for polynomialization of ODEs and, potentially, adapting it for use in <a href="https://github.com/SciML/StructuralIdentifiability.jl">StructuralIdentifiability.jl</a>.</p>
<p><strong>Mentors:</strong> <a href="https://github.com/sumiya11">Alexander Demin</a>, <a href="https://www.lix.polytechnique.fr/Labo/Gleb.POGUDIN/">Gleb Pogudin</a>, <a href="https://www.chrisrackauckas.com/">Chris Rackauckas</a></p>
<p><strong>Project Difficulty</strong>: Medium</p>
<p><strong>Estimated Duration</strong>: 350 hours</p>
<p><strong>Ideal Candidate Profile:</strong></p>
<ul>
<li><p>Basic experience with Julia</p>
</li>
<li><p>Knowledge of ordinary differential equations</p>
</li>
</ul>
<p><strong>Project Goals and Deliverables:</strong></p>
<ul>
<li><p>Implementation of an algorithm in Julia to perform polynomialization of ODEs</p>
</li>
<li><p>Comprehensive documentation and examples</p>
</li>
<li><p>&#40;Bonus&#41; Integration with <a href="https://github.com/SciML/StructuralIdentifiability.jl">StructuralIdentifiability.jl</a></p>
</li>
</ul>
<p><strong>Useful References:</strong></p>
<ul>
<li><p><a href="https://inria.hal.science/hal-03220725">Paper on polynomialization #1</a></p>
</li>
<li><p><a href="https://dl.acm.org/doi/10.1145/1687399.1687474">Paper on polynomialization #2</a></p>
</li>
<li><p><a href="https://github.com/SciML/StructuralIdentifiability.jl/issues/144">Relevant GitHub issue</a></p>
</li>
<li><p><a href="https://github.com/AndreyBychkov/QBee/blob/master/qbee/polynomialization.py">An implementation of similar algorithms in Python</a></p>
</li>
</ul>
<h2 id="topopt_projects_summer_of_code"><a href="#topopt_projects_summer_of_code" class="header-anchor">TopOpt Projects – Summer of Code</a></h2>
<p><a href="https://github.com/JuliaTopOpt/TopOpt.jl">TopOpt.jl</a> is a <a href="https://en.wikipedia.org/wiki/Topology_optimization">topology optimization</a> package written in pure Julia. Topology optimization is an exciting field at the intersection of shape representation, physics simulations and mathematical optimization, and the Julia language is a great fit for this field. To learn more about <code>TopOpt.jl</code>, check the following <a href="https://www.youtube.com/watch?v&#61;sBqdkxPXluU">JuliaCon talk</a>.</p>
<p>The following is a tentative list of projects in topology optimization that you could be working on in the coming Julia Season of Contributions or Google Summer of Code. If you are interested in exploring any of these topics or if you have other interests related to topology optimization, please reach out to the main mentor <a href="https://github.com/mohamed82008">Mohamed Tarek</a> via email.</p>
<h3 id="testing_and_benchmarking_of_topoptjl"><a href="#testing_and_benchmarking_of_topoptjl" class="header-anchor">Testing and benchmarking of TopOpt.jl</a></h3>
<p><strong>Project difficulty</strong>: Medium</p>
<p><strong>Work load</strong>: 350 hours</p>
<p><strong>Description</strong>: The goal of this project is to improve the unit test coverage and reliability of TopOpt.jl by testing its implementations against other software&#39;s outputs. Testing and benchmarking stress and buckling constraints and their derivatives will be the main focus of this project. Matlab scripts from papers may have to be translated to Julia for correctness and performance comparison.</p>
<p><strong>Knowledge prerequisites</strong>: structural mechanics, optimization, Julia programming</p>
<h3 id="machine_learning_in_topology_optimization"><a href="#machine_learning_in_topology_optimization" class="header-anchor">Machine learning in topology optimization</a></h3>
<p><strong>Project difficulty</strong>: Medium</p>
<p><strong>Work load</strong>: 350 hours</p>
<p><strong>Description</strong>: There are numerous ways to use machine learning for design optimization in topology optimization. The following are all recent papers with applications of neural networks and machine learning in topology optimization. There are also exciting research opportunities in this direction.</p>
<ul>
<li><p><a href="https://openreview.net/pdf?id&#61;DUy-qLzqvlU">DNN-based Topology optimization: Spatial Invariance and Neural Tangent Kernel</a></p>
</li>
<li><p><a href="https://openreview.net/pdf?id&#61;bBHHU4dW88g">NTopo: Mesh-free Topology Optimization using Implicit Neural Representations</a></p>
</li>
<li><p><a href="https://www.sciencedirect.com/science/article/pii/S004578252100414X?via&#37;3Dihub">TONR: An exploration for a novel way combining neural network with topology optimization</a></p>
</li>
<li><p><a href="https://link.springer.com/article/10.1007/s00158-020-02748-4">TOuNN: Topology Optimization using Neural Networks</a></p>
</li>
</ul>
<p>In this project you will implement one of the algorithms discussed in any of these papers.</p>
<p><strong>Knowledge prerequisites</strong>: neural networks, optimization, Julia programming</p>
<h3 id="optimization_on_a_uniform_rectilinear_grid"><a href="#optimization_on_a_uniform_rectilinear_grid" class="header-anchor">Optimization on a uniform rectilinear grid</a></h3>
<p><strong>Project difficulty</strong>: Medium</p>
<p><strong>Work load</strong>: 350 hours</p>
<p><strong>Description</strong>: Currently in TopOpt.jl, there are only unstructured meshes supported. This is a very flexible type of mesh but it&#39;s not as memory efficient as uniform rectilinear grids where all the elements are assumed to have the same shape. This is the most common grid used in topology optimization in practice. Currently in TopOpt.jl, the uniform rectilinear grid will be stored as an unstructured mesh which is unnecessarily inefficient. In this project, you will optimize the finite element analysis and topology optimization codes in TopOpt.jl for uniform rectilinear grids.</p>
<p><strong>Knowledge prerequisites</strong>: knowledge of mesh types, Julia programming</p>
<h3 id="adaptive_mesh_refinement_for_topology_optimization"><a href="#adaptive_mesh_refinement_for_topology_optimization" class="header-anchor">Adaptive mesh refinement for topology optimization</a></h3>
<p><strong>Project difficulty</strong>: Medium</p>
<p><strong>Work load</strong>: 350 hours</p>
<p><strong>Description</strong>: Topology optimization problems with more mesh elements take longer to simulate and to optimize. In this project, you will explore the use of adaptive mesh refinement starting from a coarse mesh, optimizing and only refining the elements that need further optimization. This is an effective way to accelerate topology optimization algorithms.</p>
<p><strong>Knowledge prerequisites</strong>: adaptive mesh refinement, Julia programming</p>
<h3 id="heat_transfer_design_optimization"><a href="#heat_transfer_design_optimization" class="header-anchor">Heat transfer design optimization</a></h3>
<p><strong>Project difficulty</strong>: Medium</p>
<p><strong>Work load</strong>: 175 or 350 hours</p>
<p><strong>Description</strong>: All of the examples in TopOpt.jl and problem types are currently of the linear elasticity, quasi-static class of problems. The goal of this project is to implement more problem types and examples from the field of heat transfer. Both steady-state heat transfer problems and linear elasticity problems make use of elliptic partial differential equations so the code from linear elasticity problems should be largely reusable for heat transfer problems with minimum changes.</p>
<p><strong>Knowledge prerequisites</strong>: finite element analysis, heat equation, Julia programming</p>
<h2 id="modern_computational_fluid_dynamics_with_trixijl"><a href="#modern_computational_fluid_dynamics_with_trixijl" class="header-anchor">Modern computational fluid dynamics with Trixi.jl</a></h2>
<p><a href="https://github.com/trixi-framework/Trixi.jl/">Trixi.jl</a> is a Julia package for adaptive high-order numerical simulations of conservation laws. It is designed to be simple to use for students and researchers, extensible for research and teaching, as well as efficient and suitable for high-performance computing.</p>
<h3 id="advanced_visualization_and_in-situ_visualization_with_paraview"><a href="#advanced_visualization_and_in-situ_visualization_with_paraview" class="header-anchor">Advanced visualization and in-situ visualization with ParaView</a></h3>
<p><strong>Difficulty</strong>: Medium</p>
<p><strong>Project size</strong>: 175 hours or 350 hours, depending on the chosen subtasks</p>
<p>Visualizing and documenting results is a crucial part of the scientific process. In <a href="https://github.com/trixi-framework/Trixi.jl/">Trixi.jl</a>, we rely for visualization on a combination of pure Julia packages &#40;such as <a href="https://github.com/JuliaPlots/Plots.jl">Plots.jl</a> and <a href="https://github.com/MakieOrg/Makie.jl">Makie.jl</a>&#41; and the open-source scientific visualization suite <a href="https://www.paraview.org">ParaView</a>. While the Julia solutions are excellent for visualizing 1D and 2D data, ParaView is the first choice for creating publication-quality figures from 3D data.</p>
<p>Currently, visualization with ParaView is only possible after a simulation is finished and requires an additional postprocessing step, where the native output files of Trixi.jl are converted to <a href="https://vtk.org">VTK</a> files using <a href="https://github.com/trixi-framework/Trixi2Vtk.jl">Trixi2Vtk.jl</a>. This extra step makes it somewhat inconvenient to use, especially when the current state of a numerical solution is to be checked during a long, multi-hour simulation run.</p>
<p>The goal of this project is therefore to make such visualizations easier by introducing two significant improvements:</p>
<ul>
<li><p>Add the capability to write out native <a href="https://docs.vtk.org/en/latest/design_documents/VTKFileFormats.html#vtkhdf-file-format">VTKHDF</a> files directly during a simulation, in serial and parallel.</p>
</li>
<li><p>Enable parallel in-situ visualization of the results, i.e., to visualize results by connecting ParaView to a currently running, parallel Trixi.jl simulation using the <a href="https://catalyst-in-situ.readthedocs.io/en/latest/index.html">Catalyst API</a>.</p>
</li>
</ul>
<p>Both tasks are related in that they require the student to familiarize themselves with both the data formats internally used in Trixi.jl as well as the visualization pipelines of VTK/ParaView. However, they can be performed independently and thus this project is suitable for either a 175 hour or a 350 hour commitment, depending on whether one or both tasks are to be tackled.</p>
<p>This project is good for both software engineers interested in the fields of visualization and scientific data analysis as well as those students who are interested in pursuing graduate research in the field of numerical analysis and high-performance computing.</p>
<p><strong>Recommended skills</strong>: Some knowledge of at least one numerical discretization scheme &#40;e.g., finite volume, discontinuous Galerkin, finite differences&#41; is helpful; initial knowledge about visualization or parallel processing; preferably the ability &#40;or eagerness to learn&#41; to write fast code.</p>
<p><strong>Expected results</strong>: Scalable, production quality visualization of scientific results for Trixi.jl.</p>
<p><strong>Mentors</strong>: <a href="https://github.com/sloede">Michael Schlottke-Lakemper</a>, <a href="https://www.mi.uni-koeln.de/NumSim/dr-benedict-geihe/">Benedict Geihe</a>, <a href="https://github.com/jmark">Johannes Markert</a></p>
<h3 id="asynchronous_computing_for_communication_blocking_mpi_and_multi-gpu_computing_using_trixijl"><a href="#asynchronous_computing_for_communication_blocking_mpi_and_multi-gpu_computing_using_trixijl" class="header-anchor">Asynchronous computing for communication blocking MPI and multi-GPU computing using Trixi.jl</a></h3>
<p><strong>Difficulty</strong>: Medium</p>
<p><strong>Project size</strong>: 175 hours or 350 hours, depending on the chosen subtasks</p>
<p>The high performance of modern scientific software is built on parallel computing using MPI and GPUs. The communication speed has not kept up with the exponential increase in compute speed and algorithms are often communication bound, leading to underutilization of hardware capabilities. Asynchronous computing avoids communication bottlenecks by performing non-blocking sends and using algorithms that can give reliable results using the currently available data. This approach gives great scalability on parallel computing systems.</p>
<p><a href="https://github.com/trixi-framework/Trixi.jl/">Trixi.jl</a> currently performs distributed memory parallelization using <a href="https://github.com/JuliaParallel/MPI.jl">MPI.jl</a>, and has experimental GPU capabilities using <a href="https://github.com/JuliaGPU/CUDA.jl">CUDA.jl</a> and <a href="https://github.com/JuliaGPU/KernelAbstractions.jl">KernelAbstractions.jl</a>. The goal of this project is to implement a subset of features of <a href="https://github.com/trixi-framework/Trixi.jl/">Trixi.jl</a> that can perform parallel simulations asynchronously.</p>
<p>The possible subtasks in this project include:</p>
<ul>
<li><p>Explore and implement a simple code for asynchronous algorithms for solving the 1D advection equation or 1D compressible Euler equations using the API of <a href="https://github.com/trixi-framework/Trixi.jl/">Trixi.jl</a>.</p>
</li>
<li><p>Taking the simple code as a prototype, explore and implement an asynchronous algorithm starting with the basic <a href="https://trixi-framework.github.io/Trixi.jl/stable/meshes/tree_mesh/">TreeMesh</a> type in <a href="https://github.com/trixi-framework/Trixi.jl/">Trixi.jl</a> and potentially extending up to <a href="https://trixi-framework.github.io/Trixi.jl/stable/meshes/p4est_mesh/">P4estMesh</a>.</p>
</li>
<li><p>Explore and implement asynchronous algorithms for a multi-GPU setup, in the 1D prototype and in <a href="https://github.com/trixi-framework/Trixi.jl/">Trixi.jl</a>.</p>
</li>
<li><p>Explore and implement asynchronous algorithms using <a href="https://juliaparallel.org/MPI.jl/dev/reference/onesided/">Remote Memory Access Programming using MPI.jl</a>.</p>
</li>
<li><p>Optimize and compare the performance of the above implementations across different hardwares.</p>
</li>
</ul>
<p>This project is good for both software engineers interested in the fields of scientific computing, machine learning and numerical analysis as well as those students who are interested in pursuing graduate research in the field.</p>
<p><strong>Recommended skills:</strong> Some knowledge of GPU or MPI programming. Knowledge of any numerical analysis &#40;e.g., finite differences&#41; will help, but is not strictly required.</p>
<p><strong>Expected results:</strong> Draft of a working subset of the functionality of <a href="https://github.com/trixi-framework/Trixi.jl/">Trixi.jl</a> efficiently using asynchronous computing.</p>
<p><strong>Mentors</strong>: <a href="https://github.com/arpit-babbar">Arpit Babbar</a>, <a href="https://github.com/ranocha">Hendrik Ranocha</a>, <a href="https://github.com/sloede">Michael Schlottke-Lakemper</a></p>
<h3 id="adaptive_mesh_refinement_on_gpus_with_cuda_dynamic_parallelism"><a href="#adaptive_mesh_refinement_on_gpus_with_cuda_dynamic_parallelism" class="header-anchor">Adaptive mesh refinement on GPUs with CUDA dynamic parallelism</a></h3>
<p><strong>Difficulty</strong>: Hard</p>
<p><strong>Project size</strong>: 175 hours or 350 hours, depending on the chosen subtasks</p>
<p><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cuda-dynamic-parallelism">Dynamic parallelism</a> is designed for applications with either a variation of work across space or a dynamically varying workload over time. It is perfect for tasks like mesh refinement. When a thread discovers that an area needs to be refined, it can launch a new grid to perform computations on the refined area without the overhead of terminating the current grid, reporting to the host, and launching the new grid from the host.</p>
<p><a href="https://trixi-framework.github.io/Trixi.jl/stable/tutorials/adaptive_mesh_refinement/">Adaptive mesh refinement &#40;AMR&#41;</a> is applied in <a href="https://github.com/trixi-framework/Trixi.jl/">Trixi.jl</a> to dynamically refine the mesh during simulations, ensuring finer resolution in critical regions for improved accuracy. Currently, the mesh refinement process is performed on CPUs using parallelism with <a href="https://github.com/JuliaParallel/MPI.jl">MPI.jl</a>. The goal of this project is to migrate AMR to GPUs using dynamic parallelism for acceleration with <a href="https://github.com/JuliaGPU/CUDA.jl">CUDA.jl</a>.</p>
<p>The possible subtasks in this project include:</p>
<ul>
<li><p>Implementing the abstract tree initialization process on GPUs.</p>
</li>
<li><p>Exploring the <a href="https://trixi-framework.github.io/Trixi.jl/stable/meshes/tree_mesh/"><code>TreeMesh</code></a> initialization processes on GPUs based on the implementation of the first task and combining them.</p>
</li>
<li><p>Integrating the above into <a href="https://trixi-framework.github.io/Trixi.jl/stable/tutorials/adaptive_mesh_refinement/#Callback"><code>AMRCallback</code></a> in the simulation using <a href="https://cuda.juliagpu.org/stable/api/kernel/#Dynamic-parallelism">dynamic parallelism</a> &#40;via CUDA.jl&#41;.</p>
</li>
<li><p>Optimizing the code for data transfer, kernel launch overhead, occupancy, etc.</p>
</li>
<li><p>Starting the above work in 1D and then expanding it to 2D and 3D problems.</p>
</li>
<li><p>&#40;Optional&#41; Try similar work for <a href="https://trixi-framework.github.io/Trixi.jl/stable/meshes/p4est_mesh/"><code>P4estMesh</code></a> in 2D and 3D.</p>
</li>
</ul>
<p>This project is good for people who are interested in GPU programming, parallel computing, parallel algorithm optimization, and scientific computing.</p>
<p><strong>Recommended skills:</strong> GPU programming, knowledge of CUDA dynamic parallelism, and familiarity with mesh refinement. &#40;For beginners or those unfamiliar with dynamic parallelism, it is recommended to start with the <a href="https://github.com/NVIDIA/cuda-samples/tree/master/Samples/3_CUDA_Features/cdpQuadtree">CUDA quadtree example</a>.&#41;</p>
<p><strong>Expected results:</strong> A working example of AMR running on GPUs.</p>
<p><strong>Mentors</strong>: <a href="https://github.com/huiyuxie">Huiyu Xie</a>, <a href="https://github.com/jlchan">Jesse Chan</a>, <a href="https://github.com/ranocha">Hendrik Ranocha</a></p>
<h2 id="turing_projects"><a href="#turing_projects" class="header-anchor">Turing Projects</a></h2>
<p><a href="https://turinglang.org/">Turing.jl</a> is a universal probabilistic programming language embedded in Julia. Turing allows the user to write statistical models in standard Julia syntax, and provides a wide range of sampling-based inference methods for solving problems across probabilistic machine learning, Bayesian statistics, and data science. Since Turing is implemented in pure Julia code, its compiler and inference methods are amenable to hacking: new model families and inference methods can be easily added.</p>
<p>The Turing team is currently planning projects for GSoC 2025, and will post them here once they are ready. You are also welcome to propose your own projects. If you are interested in working on Turing for GSoC 2025, please reach out to Markus Hauru &#40;@mhauru&#41; on Julia&#39;s <a href="https://julialang.org/slack/">Slack</a> or <a href="https://discourse.julialang.org/">Discourse</a>.</p>
<h2 id="vs_code_projects"><a href="#vs_code_projects" class="header-anchor">VS Code projects</a></h2>
<h3 id="vs_code_extension"><a href="#vs_code_extension" class="header-anchor">VS Code extension</a></h3>
<p>We are generally looking for folks that want to help with the <a href="https://www.julia-vscode.org/">Julia VS Code extension</a>. We have a long list of open issues, and some of them amount to significant projects.</p>
<p><strong>Required Skills</strong>: TypeScript, Julia, web development.</p>
<p><strong>Expected Results</strong>: Depends on the specific projects we would agree on.</p>
<p><strong>Mentors</strong>: <a href="https://github.com/davidanthoff">David Anthoff</a></p>
<h3 id="package_installation_ui"><a href="#package_installation_ui" class="header-anchor">Package installation UI</a></h3>
<p>The VSCode extension for Julia could provide a simple way to browse available packages and view what&#39;s installed on a users system. To start with, this project could simply provide a GUI that reads in package data from a <code>Project.toml</code>/<code>Manifest.toml</code> and show some UI elements to add/remove/manage those packages.</p>
<p>This could also be extended by having metadata about the package, such as a readme, github stars, activity and so on &#40;somewhat similar to the VSCode-native extension explorer&#41;.</p>
<p><strong>Expected Results</strong>: A UI in VSCode for package operations.</p>
<p><strong>Recommended Skills</strong>: Familiarity with TypeScript and Julia development.</p>
<p><strong>Mentors</strong>: <a href="https://github.com/pfitzseb">Sebastian Pfitzner</a></p>
<p><em>Also take a look at <a href="https://julialang.org/jsoc/gsoc/pluto/">Pluto - VS Code integration</a>&#33;</em></p>
<h2 id="web_platform_projects_summer_of_code"><a href="#web_platform_projects_summer_of_code" class="header-anchor">Web Platform Projects – Summer of Code</a></h2>
<p>Julia has early support for targeting WebAssembly and running in the web browser. Please note that this is a rapidly moving area &#40;see the <a href="https://github.com/Keno/julia-wasm">project repository</a> for a more detailed overview&#41;, so if you are interested in this work, please make sure to inform yourself of the current state and talk to us to scope out an appropriate project. The below is intended as a set of possible starting points.</p>
<p>Mentor for these projects is <a href="https://github.com/Keno">Keno Fischer</a> unless otherwise stated.</p>
<h3 id="code_generation_improvements_and_async_abi"><a href="#code_generation_improvements_and_async_abi" class="header-anchor">Code generation improvements and async ABI</a></h3>
<p>Because Julia relies on an asynchronous task runtime and WebAssembly currently lacks native support for stack management, Julia needs to explicitly manage task stacks in the wasm heap and perform a compiler transformation to use this stack instead of the native WebAssembly stack. The overhead of this transformation directly impacts the performance of Julia on the wasm platform. Additionally, since all code Julia uses &#40;including arbitrary C/C&#43;&#43; libraries&#41; must be compiled using this transformation, it needs to cover a wide variety of inputs and be coordinated with other users having similar needs &#40;e.g. the Pyodide project to run python on the web&#41;. The project would aim to improve the quality, robustness and flexibility of this transformation.</p>
<p><strong>Recommended Skills</strong>: Experience with LLVM.</p>
<h3 id="wasm_threading"><a href="#wasm_threading" class="header-anchor">Wasm threading</a></h3>
<p>WebAssembly is in the process of standardizing <a href="https://github.com/WebAssembly/threads">threads</a>. Simultaneously, work is ongoing to introduce a new threading runtime in Julia &#40;see <a href="https://github.com/JuliaLang/julia/pull/22631">#22631</a> and replated PRs&#41;. This project would investigate enabling threading support for Julia on the WebAssembly platform, implementing runtime parallel primitives on the web assembly platform and ensuring that high level threading constructs are correctly mapped to the underlying platform. Please note that both the WebAssembly and Julia threading infrastructure is still in active development and may continue to change over the duration of the project. An informed understanding of the state of these projects is a definite prerequisite for this project.</p>
<p><strong>Recommended Skills</strong>: Experience with C and multi-threaded programming.</p>
<h3 id="high_performance_low-level_integration_of_js_objects"><a href="#high_performance_low-level_integration_of_js_objects" class="header-anchor">High performance, Low-level integration of js objects</a></h3>
<p>WebAssembly is in the process of adding <a href="https://github.com/WebAssembly/reference-types">first class references to native objects</a> to their specification. This capability should allow very high performance integration between julia and javascript objects. Since it is not possible to store references to javascript objects in regular memory, adding this capability will require several changes to the runtime system and code generation &#40;possibly including at the LLVM level&#41; in order to properly track these references and emit them either as direct references to as indirect references to the reference table.</p>
<p><strong>Recommended Skills</strong>: Experience with C.</p>
<h3 id="dom_integration"><a href="#dom_integration" class="header-anchor">DOM Integration</a></h3>
<p>While Julia now runs on the web platform, it is not yet a language that&#39;s suitable for first-class development of web applications. One of the biggest missing features is integration with and abstraction over more complicated javascript objects and APIs, in particular the DOM. Inspiration may be drawn from similar projects in <a href="https://github.com/koute/stdweb">Rust</a> or other languages.</p>
<p><strong>Recommended Skills</strong>: Experience with writing libraries in Julia, experience with JavaScript Web APIs.</p>
<h3 id="porting_existing_web-integration_packages_to_the_wasm_platform"><a href="#porting_existing_web-integration_packages_to_the_wasm_platform" class="header-anchor">Porting existing web-integration packages to the wasm platform</a></h3>
<p>Several Julia libraries &#40;e.g. WebIO.jl, Escher.jl&#41; provide input and output capabilities for the web platform. Porting these libraries to run directly on the wasm platform would enable a number of existing UIs to automatically work on the web.</p>
<p><strong>Recommended Skills</strong>: Experience with writing libraries in Julia.</p>
<h3 id="native_dependencies_for_the_web"><a href="#native_dependencies_for_the_web" class="header-anchor">Native dependencies for the web</a></h3>
<p>The Julia project uses <a href="https://github.com/JuliaPackaging/BinaryBuilder.jl">BinaryBuilder</a> to provide binaries of native dependencies of julia packages. Experimental support exists to extend this support to the wasm platform, but few packages have been ported. This project would consist of attempting to port a significant fraction of the binary dependencies of the julia ecosystem to the web platform by improving the toolchain support in BinaryBuilder or &#40;if necessary&#41;, porting upstream packages to fix assumptions not applicable on the wasm platform.</p>
<p><strong>Recommended Skills</strong>: Experience with building native libraries in Unix environments.</p>
<h3 id="distributed_computing_with_untrusted_parties"><a href="#distributed_computing_with_untrusted_parties" class="header-anchor">Distributed computing with untrusted parties</a></h3>
<p>The Distributed computing abstractions in Julia provide convenient abstraction for implementing programs that span many communicating Julia processes on different machines. However, the existing abstractions generally assume that all communicating processes are part of the same trust domain &#40;e.g. they allow messages to execute arbitrary code on the remote&#41;. With some of the nodes potentially running in the web browser &#40;or multiple browser nodes being part of the same distributed computing cluster via WebRPC&#41;, this assumption no longer holds true and new interfaces need to be designed to support multiple trust domains without overly restricting usability.</p>
<p><strong>Recommended Skills</strong>: Experience with distributed computing and writing libraries in Julia.</p>
<h3 id="deployment"><a href="#deployment" class="header-anchor">Deployment</a></h3>
<p>Currently supported use cases for Julia on the web platform are primarily geared towards providing interactive environments to support exploration of the full language. Of course, this leads to significantly larger binaries than would be required for using Julia as part of a production deployment. By disabling dynamic language features &#40;e.g. eval&#41; one could generate small binaries suitable for deployment. Some progress towards this exists in packages like <a href="https://github.com/JuliaLang/PackageCompiler.jl">PackageCompiler.jl</a>, though significant work remains to be done.</p>
<p><strong>Recommended Skills</strong>: Interest in or experience with Julia internals.</p>

</div><br><br>

<!-- CONTENT ENDS HERE -->
    
        



    
    
        <script src="/libs/highlight/highlight.min.js"></script>


    

    <!-- http://tutsplus.github.io/clipboard/ -->

<script>
(function(){

	// Get the elements.
	// - the 'pre' element.
	// - the 'div' with the 'paste-content' id.

	var pre = document.getElementsByTagName('pre');

	// Add a copy button in the 'pre' element.
	// which only has the className of 'language-' or ' hljs'(if enable highlight.js pre-render).

	for (var i = 0; i < pre.length; i++) {
		var tag_name = pre[i].children[0].className
            	var isLanguage = tag_name.startsWith('language-') || tag_name.endsWith(' hljs');
		if ( isLanguage ) {
			var button           = document.createElement('button');
					button.className = 'copy-button';
					button.textContent = 'Copy';

					pre[i].appendChild(button);
		}
	};

	// Run Clipboard

	var copyCode = new Clipboard('.copy-button', {
		target: function(trigger) {
			return trigger.previousElementSibling;
    }
	});

	// On success:
	// - Change the "Copy" text to "Copied".
	// - Swap it to "Copy" in 2s.
	// - Lead user to the "contenteditable" area with Velocity scroll.

	copyCode.on('success', function(event) {
		event.clearSelection();
		event.trigger.textContent = 'Copied';
		window.setTimeout(function() {
			event.trigger.textContent = 'Copy';
		}, 2000);

	});

	// On error (Safari):
	// - Change the  "Press Ctrl+C to copy"
	// - Swap it to "Copy" in 2s.

	copyCode.on('error', function(event) {
		event.trigger.textContent = 'Press "Ctrl + C" to copy';
		window.setTimeout(function() {
			event.trigger.textContent = 'Copy';
		}, 5000);
	});

})();
</script>


    <footer class="container-fluid footer-copy">
  <div class="container">
    <div class="row footrow">
      <ul>
        <li><a href="/project">About</a></li>
        <li><a href="/about/help">Get Help</a></li>
        <li><a href="/governance/">Governance</a></li>
        <li><a href="/research/#publications">Publications</a></li>
        <li><a href="/community/sponsors/">Sponsors</a></li>
      </ul>
      <ul>
        <li><a href="/downloads/">Downloads</a></li>
        <li><a href="/downloads/">All Releases</a></li>
        <li><a href="https://github.com/JuliaLang/julia">Source Code</a></li>
        <li><a href="/downloads/#current_stable_release">Current Stable Release</a></li>
        <li><a href="/downloads/#long_term_support_release">Longterm Support Release</a></li>
      </ul>
      <ul>
        <li><a href="https://docs.julialang.org/en/v1/">Documentation</a></li>
        <li><a href="https://juliaacademy.com">JuliaAcademy</a></li>
        <li><a href="https://www.youtube.com/user/JuliaLanguage">YouTube</a></li>
        <li><a href="/learning/getting-started/">Getting Started</a></li>
        <li><a href="https://docs.julialang.org/en/v1/manual/faq/">FAQ</a></li>
        <li><a href="/learning/books">Books</a></li>
      </ul>
      <ul>
        <li><a href="/community/">Community</a></li>
        <li><a href="/community/standards/">Code of Conduct</a></li>
        <li><a href="/community/stewards/">Stewards</a></li>
        <li><a href="/diversity/">Diversity</a></li>
        <li><a href="https://juliagenderinclusive.github.io">Julia Gender Inclusive</a></li>
        <li><a href="https://juliacon.org">JuliaCon</a></li>
        <li><a href="/community/#julia_user_and_developer_survey">User/Developer Survey</a></li>
        <li><a href="/shop/">Shop Merchandise</a></li>
      </ul>
      <ul>
        <li><a href="https://github.com/JuliaLang/julia/blob/master/CONTRIBUTING.md">Contributing</a></li>
        <li><a href="/contribute">Contributor's Guide</a></li>
        <li><a href="https://github.com/JuliaLang/julia/issues">Issue Tracker</a></li>
        <li><a href="https://github.com/JuliaLang/julia/security/policy">Report a Security Issue</a></li>
        <li><a href="https://github.com/search?q=is%3Aopen+is%3Aissue+language%3AJulia+label%3A%22help+wanted%22">Help Wanted Issues</a></li>
        <li><a href="https://github.com/search?q=is%3Aopen+is%3Aissue+language%3AJulia+label%3A%22good+first+issue%22">Good First Issue</a></li>
        <li><a href="https://docs.julialang.org/en/v1/devdocs/init/">Dev Docs</a></li>
      </ul>
    </div>
    <div id="footer-bottom" class="row">
      <div class="col-md-10 py-2">
        <p>This site is powered by <a href="https://www.netlify.com">Netlify</a>, <a href="https://franklinjl.org">Franklin.jl</a>, and the <a href="https://julialang.org">Julia Programming Language</a>.</p>
        <p>We thank <a href="https://www.fastly.com">Fastly</a> for their generous infrastructure support.</p>
        <p>©2024 JuliaLang.org <a href="https://github.com/JuliaLang/www.julialang.org/graphs/contributors">contributors</a>. The content on this website is made available under the <a href="https://github.com/JuliaLang/www.julialang.org/blob/master/LICENSE.md">MIT license</a>.</p>
      </div>
      <div class="col-md-2 py-2">
        <span class="float-sm-right">
          <a class="github-button" href="https://github.com/sponsors/julialang" data-icon="octicon-heart" data-size="large" aria-label="Sponsor @julialang on GitHub">Sponsor</a>
        </span>
      </div>
    </div>
  </div>
</footer>

<script src="/libs/jquery/jquery.min.js"></script>
<script src="/libs/bootstrap/bootstrap.min.js"></script>
<!-- <script src="/libs/highlight/highlight.min.js"></script> -->
<!--  -->

    <script src="/libs/groups.js"></script>
    <script src="/libs/map.js"></script>
  </body>
</html>
