<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv=x-ua-compatible  content="ie=edge"> <meta http-equiv=content-type  content="text/html; charset=utf-8" /> <meta name=author  content="Jeff Bezanson, Stefan Karpinski, Viral Shah, Alan Edelman, et al." /> <meta name=description  content="The official website for the Julia Language. Julia is a language that is fast, dynamic, easy to use, and open source. Click here to learn more."/> <meta property="og:title" content="The Julia Language"/> <meta property="og:image" content="/assets/images/julia-open-graph.png"/> <meta property="og:description" content="Official website for the Julia programming language"/> <link href="https://fonts.googleapis.com/css?family=Roboto:400,400i,500,500i,700,700i" rel=stylesheet > <link href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel=stylesheet > <link rel=stylesheet  href="/libs/bootstrap/bootstrap.min.css" /> <link rel=stylesheet  href="/css/app.css" /> <link rel=stylesheet  href="/css/fonts.css" /> <link rel=stylesheet  href="/css/franklin.css" /> <script async defer src="/libs/buttons.js"></script> <!-- --> <script type="application/javascript"> var doNotTrack = false; if (!doNotTrack) { window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga('create', 'UA-28835595-1', 'auto'); ga('send', 'pageview'); } </script> <script async src='https://www.google-analytics.com/analytics.js'></script> <link rel=icon  href="/assets/infra/julia.ico"> <title>GSoC 2018 and Speech Recognition for the Flux Model Zoo: The Conclusion</title> <style> .container ul li p {margin-bottom: 0;} </style> <div class="container py-3 py-lg-0"> <nav class="navbar navbar-expand-lg navbar-light bg-light" id=main-menu > <a class=navbar-brand  href="/" id=logo > <img src="/assets/infra/logo.svg" height=55  width=85  alt="JuliaLang Logo"/> </a> <button class="navbar-toggler ml-auto hidden-sm-up float-xs-left" type=button  data-toggle=collapse  data-target="#navbarSupportedContent" aria-controls=navbarSupportedContent  aria-expanded=false  aria-label="Toggle navigation"> <span class=navbar-toggler-icon ></span> </button> <div class="collapse navbar-collapse" id=navbarSupportedContent > <ul class="navbar-nav mr-auto"> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/downloads/">Download</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="https://docs.julialang.org">Documentation</a> <li class="nav-item active flex-md-fill text-md-center"> <a class=nav-link  href="/blog/">Blog</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/community/">Community</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/learning/">Learning</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/research/">Research</a> <li class="nav-item flex-md-fill text-md-center"> <a class=nav-link  href="/jsoc/">JSoC</a> <li class="nav-item donate flex-md-fill text-md-center"> <a class=github-button  href="https://github.com/sponsors/julialang" data-icon=octicon-heart  data-size=large  aria-label="Sponsor @julialang on GitHub">Sponsor</a> </ul> </div> </nav> </div> <br><br> <div class="container blog-title"> <h1>GSoC 2018 and Speech Recognition for the Flux Model Zoo: The Conclusion <a type="application/rss+xml" href="https://julialang.org/feed.xml"> <i style="color:#e2802f" class="fa fa-rss-square"></i> </a> </h1> <h3> <span style="font-weight: lighter;"> 14 August 2018 </span> | <span style="font-weight: bold;"></span> <span style="font-weight: bold;"><a href="https://github.com/maetshju">Matthew C. Kelley</a> </span> </h3> </div> <div class=container ><p>Here we are on the other end of Google Summer of Code 2018. It has been a challenging and educational experience, and I wouldn&#39;t have it any other way. I am thankful to the Julia community, and especially my mentor <a href="https://github.com/mikeinnes">@MikeInnes</a>, for supporting me through this. I&#39;ve learned a lot and become even more familiar with neural nets than I was before, and I learned how to do basic GPU programming, which will be incredibly useful for my academic career.</p> <p>The rest of this blog post will summarize my project and the work I&#39;ve done over the whole summer, remark on what work remains to be done, and conclude with a brief tutorial of how to run the code I&#39;ve written to try it out for yourself.</p> <div class=franklin-toc ><ol><li><a href="#have_you_ever_wanted_your_computer_to_understand_speech">Have you ever wanted your computer to understand speech?</a><li><a href="#results_of_the_ctc_network">Results of the CTC network</a><li><a href="#results_of_the_framewise_network">Results of the framewise network</a><li><a href="#what_remains_to_be_done">What remains to be done</a><li><a href="#running_the_models">Running the models</a><ol><li><a href="#ctc_model">CTC model</a><li><a href="#framewise_model">Framewise model</a></ol><li><a href="#get_the_code">Get the code</a><li><a href="#references">References</a></ol></div> <h1 id=have_you_ever_wanted_your_computer_to_understand_speech ><a href="#have_you_ever_wanted_your_computer_to_understand_speech">Have you ever wanted your computer to understand speech?</a></h1> <p>Speech recognition is currently in vogue among many tech companies. Google and Amazon, for example, are heavily pushing their standalone digital assistant devices, Google Home and Alexa, respectively. Without functional speech recognition, these products would be dead in the water.</p> <p>Unfortunately for many researchers and potential users of speech recognition, there doesn&#39;t seem to be as much documentation available for speech recognition systems as there is for image recognition, for example. The goal of this Google Summer of Code 2018 project was to contribute some speech recognition models to the <a href="https://github.com/FluxML/model-zoo">Flux model zoo</a> so that there would be some freely available models for others to work from.</p> <p>At the end of the project, two different models were coded. The first is a rather new approach to using a loss function called connectionist temporal classification &#40;CTC&#41; &#40;Graves et al., 2006&#41;. The model to be implemented was from Zhang et al. &#40;2017&#41;, and it uses convolutional layers to learn temporal dependencies in the data, unlike traditional approaches to using the CTC loss which use recurrent layers. It is a very deep network, which the authors believe allows it to learn temporal dependencies.</p> <p>The second network was an older style framewise recognition model, inspired by Graves &amp; Schmidhuber &#40;2005&#41;. It predicts the class for each chunk of audio that is passed through the network and uses categorical cross-entropy as its loss function. It would serve as a baseline for the CTC network to compare against.</p> <p>For those who are unfamiliar with speech recognition systems, the mapping of acoustics to phone labels is still an unsolved problem in the sense that no one is achieving 95&#37; or 99&#37; accuracy on just the label identification for frames of audio. As such, the reported accuracies may seem underwhelming &#40;and the CTC network&#39;s certainly are&#41;, but that&#39;s also characteristic of speech recognition systems.</p> <h1 id=results_of_the_ctc_network ><a href="#results_of_the_ctc_network">Results of the CTC network</a></h1> <p>Once broken down into steps, the main tasks for this project were to implement the network architecture and to implement the CTC loss function in Flux and Julia. Naive implementations of both of these tasks came easy, but the performance was not suitable to be able to train the network. Improving the network&#39;s computational efficiency was not that difficult in retrospect because it only took adding a <code>reshape</code> call in Flux&#39;s <code>Chain</code> function to connect the convolutional layers to the fully-connected ones.</p> <p>The real trial was getting the CTC loss to run correctly and efficiently. I at first was mucking around with CPU implementations before finally deciding to work on a simple port of Baidu&#39;s GPU implementation of CTC, <a href="https://github.com/baidu-research/warp-ctc">warp-ctc</a>. This was my first foray into writing GPU kernels, and I learned a lot. But after a couple weeks working on porting the kernels, I had a working GPU implementation of the loss function. Or so I thought. I spent weeks trying different training configurations and routines with a variety of optimizers, but I couldn&#39;t get the network to output predictions beyond the blank phone label category. I wrote about this in a <a href="https://maetshju.github.io/update3.html">couple of</a> <a href="https://maetshju.github.io/update4.html">blog posts</a>.</p> <p>As it would turn out, there was a slight error in my implementation that stemmed from Baidu&#39;s warp-ctc library itself. As I did when I wrote a <a href="https://maetshju.github.io/update5.html">blog post about this error</a>, I do not know whether it is actually an error in the context of the rest of Baidu&#39;s code. However, after fixing the error, I saw the loss decrease significantly in my code. Specifically, there was a section of code that evaluated to</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="https://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mo stretchy=false >(</mo><mi>t</mi><mo separator=true >,</mo><mi>u</mi><mo stretchy=false >)</mo><mo>=</mo><msubsup><mi>y</mi><msubsup><mi>l</mi><mi>u</mi><mo mathvariant=normal  lspace=0em  rspace=0em >′</mo></msubsup><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mi>u</mi></mrow><mrow><mi>g</mi><mo stretchy=false >(</mo><mi>u</mi><mo stretchy=false >)</mo></mrow></munderover><mi>β</mi><mo stretchy=false >(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo separator=true >,</mo><mi>i</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex"> \beta(t, u) = y_{l&#x27;_{u}}^{t+1}\sum_{i=u}^{g(u)}\beta(t+1,i) </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class=mopen >(</span><span class="mord mathdefault">t</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">u</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:3.2386740000000005em;vertical-align:-1.277669em;"></span><span class=mord ><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.8641079999999999em;"><span style="top:-2.4085610000000006em;margin-left:-0.03588em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.6828285714285715em;"><span style="top:-2.214em;margin-left:-0.01968em;margin-right:0.07142857142857144em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">u</span></span></span></span><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.286em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.4916389999999998em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.9610050000000003em;"><span style="top:-1.872331em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mathdefault mtight">u</span></span></span></span><span style="top:-3.050005em;"><span class=pstrut  style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.386005em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">g</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">u</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.277669em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class=mopen >(</span><span class="mord mathdefault">t</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord >1</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class=mclose >)</span></span></span></span></span> </p> <p>when it should have evaluated to</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="https://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mo stretchy=false >(</mo><mi>t</mi><mo separator=true >,</mo><mi>u</mi><mo stretchy=false >)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mi>u</mi></mrow><mrow><mi>g</mi><mo stretchy=false >(</mo><mi>u</mi><mo stretchy=false >)</mo></mrow></munderover><mi>β</mi><mo stretchy=false >(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo separator=true >,</mo><mi>i</mi><mo stretchy=false >)</mo><msubsup><mi>y</mi><msubsup><mi>l</mi><mi>i</mi><mo mathvariant=normal  lspace=0em  rspace=0em >′</mo></msubsup><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow><annotation encoding="application/x-tex"> \beta(t, u) = \sum_{i=u}^{g(u)}\beta(t+1,i)y_{l&#x27;_{i}}^{t+1} </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class=mopen >(</span><span class="mord mathdefault">t</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">u</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:3.2386740000000005em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.9610050000000003em;"><span style="top:-1.872331em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mathdefault mtight">u</span></span></span></span><span style="top:-3.050005em;"><span class=pstrut  style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.386005em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">g</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">u</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.277669em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class=mopen >(</span><span class="mord mathdefault">t</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:1.4141789999999999em;vertical-align:-0.5500710000000001em;"></span><span class=mord >1</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class=mclose >)</span><span class=mord ><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.8641079999999999em;"><span style="top:-2.3755290000000002em;margin-left:-0.03588em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.7416285714285715em;"><span style="top:-2.177714285714286em;margin-left:-0.01968em;margin-right:0.07142857142857144em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-2.8448em;margin-right:0.07142857142857144em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.3222857142857143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.5500710000000001em;"><span></span></span></span></span></span></span></span></span></span></span> </p> <p>More information on this is available in <a href="https://maetshju.github.io/update5.html">my previous post on it</a>. Making this change caused the network to finally output label predictions for each time step of data. The labels don&#39;t necessarily always make sense, but it is at least making predictions.</p> <p>And this is where the speech recognition system is sitting right now. The network architecture should be implemented correctly, and the loss function would seem to be running correctly now. That is, the network runs and learns, to an extent. You can assess for yourself how well it&#39;s learning based off the example output below:</p> <p><strong>Textual transcription</strong></p> <pre><code class="plaintext hljs">The reasons for this dive seemed foolish now.</code></pre>
<p><strong>Target sequence of phones</strong></p>
<pre><code class="plaintext hljs">h# dh ix r iy z ax n z f axr dh ih s dcl d ay v s iy m dcl d f uw l ix sh epi n aw h#</code></pre>
<p><strong>Predicted sequence of phones</strong></p>
<pre><code class="plaintext hljs">h# pau w iy bcl r iy ux z bcl b iy bcl b uw z ay n pcl p z iy n dcl d v w iy er h#</code></pre>
<p>The phone error rate for this prediction compared to the target was approximately 84&#37;. This model is obviously not ready to be added to the model zoo, as it is not performing well.</p>
<h1 id=results_of_the_framewise_network ><a href="#results_of_the_framewise_network">Results of the framewise network</a></h1>
<p>The main task for the framewise network was to find how to efficiently train the network. In terms of recognition results, the framewise network fared much better than the CTC network. In just two epochs of training, it reached approximately <strong>53.5&#37; label prediction accuracy on the test set</strong>. Obviously, the network should be trained longer than that to achieve similar performance as Graves &amp; Schmidhuber, but it&#39;s noteworthy that it&#39;s outperforming the CTC network even at such an early stage. The discrepancy between this network and the CTC network&#39;s performance is astounding. Even though the task of the CTC network is more difficult, it is striking, if not surprising, that allowing the network to exploit extra information in the training data grants an improvement of this magnitude.</p>
<h1 id=what_remains_to_be_done ><a href="#what_remains_to_be_done">What remains to be done</a></h1>
<p><strong>The framewise network is for all intents and purposes done.</strong> It should suit its purpose as a demonstration network, and it comes pretty close to matching Graves&#39;s reported performance for the network. If it were desired to have it run faster, it could be made to work with batching and run on the GPU.</p>
<p><strong>For the CTC network, there needs to be an investigation as to why it is not learning to perform to the degree Zhang et al. report.</strong> The following figure is a plot of the training and validation loss over time from the first time running the network with the corrected loss function mentioned above. The optimizer was AMSGrad with a learning rate of <span class=katex ><span class=katex-mathml ><math xmlns="https://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>4</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{-4}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8141079999999999em;vertical-align:0em;"></span><span class=mord >1</span><span class=mord ><span class=mord >0</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span></span>. It is characteristic of the behavior I&#39;ve seen with other optimizers and training configurations, whether they are fresh starts or continuing previous training.</p>
<p><img src="/assets/blog/2018-08-14-GSoC2018-speech-recognition/ctcloss.png" alt="CTC loss over time. Note that the y-axis is presented in logarithmic scale." /></p>
<p>The validation loss is settling at a suboptimal level, even though the training loss continues to decrease. I am unsure at this juncture what the cause of this behavior may be, since I have endeavored to hew as closely as possible to the implementation details given by Zhang et al. I don&#39;t believe it is in the CTC function since I have tested the CTC loss function several times against hand-worked solutions and seen it produce correct results; similarly, the gradients it provided allowed the network to fit one training example to a near-zero level of loss, so it would seem the function is providing a loss signal reliable enough to minimize the loss. It is possible that how I called the backpropagation needs to be investigated to see if the loss values from within a batch were being composed properly.</p>
<h1 id=running_the_models ><a href="#running_the_models">Running the models</a></h1>
<p>Running the training procedure for the models should be straightforward. Make sure that the WAV, Flux, CuArrays, JLD, and BSON packages are installed. As well, install <a href="https://github.com/maetshju/MFCC.jl">the fork I&#39;ve made of the MFCC package</a> &#40;which only updates one line to make a function run on Julia 0.6&#41;. Start by cloning the Git repository for the project:</p>
<pre><code class="bash hljs">$&gt; git <span class=hljs-built_in >clone</span> https://github.com/maetshju/gsoc2018.git</code></pre>
<p>The user will need to download the TIMIT speech corpus from the Linguistic Data Consortium, as I discussed in the first section of <a href="https://maetshju.github.io/speech-features.html">this previous blog post</a>.</p>
<h2 id=ctc_model ><a href="#ctc_model">CTC model</a></h2>
<p>Navigate into the <code>speech-cnn</code> folder. To extract the data from the TIMIT corpus, use the <code>00-data.jl</code> script. More information on this script can be found in <a href="https://maetshju.github.io/speech-features.html">the blog post dedicated to it</a>.</p>
<pre><code class="bash hljs">$&gt; julia 00-data.jl</code></pre>
<p>Now, to train the network, run the <code>01-speech-cnn.jl</code> script. Make sure you&#39;ve removed the <code>README.md</code> files from the data folders, if you downloaded them.</p>
<pre><code class="bash hljs">$&gt; julia 01-speech-cnn.jl</code></pre>
<p>Note that it is essentially necessary to have a GPU to train the network on because the training process is extremely slow on just the CPU. Additionally, the script calls out to the GPU implementation of the CTC algorithm, which will fail without a GPU. The script will likely take over a day to run, so come back to it later. After the script finishes, the model should be trained and ready for use in making predictions.</p>
<h2 id=framewise_model ><a href="#framewise_model">Framewise model</a></h2>
<p>Navigate into the <code>speech-blstm</code> folder. To extract the data from the TIMIT corpus, use the <code>00-data.jl</code> script.</p>
<pre><code class="bash hljs">$&gt; julia 00-data.jl</code></pre>
<p>Now, to train the network, run the <code>01-speech-blstm.jl</code> script. Make sure you&#39;ve removed the <code>README.md</code> files from the data folders, if you downloaded them.</p>
<pre><code class="bash hljs">$&gt; julia 01-speech-blstm.jl</code></pre>
<p>This network trains reasonably fast on the CPU, so GPU functionality was not implemented.</p>
<h1 id=get_the_code ><a href="#get_the_code">Get the code</a></h1>
<p>The code written during this project may be found <a href="https://github.com/maetshju/gsoc2018">on my GitHub</a>. There are also several pull requests that were made to contribute code to the larger package ecosystem:</p>
<ul>
<li><p><a href="https://github.com/FluxML/Flux.jl/pull/306">Adding epsilon term to Flux&#39;s binary cross entropy loss</a></p>

<li><p><a href="https://github.com/FluxML/Flux.jl/pull/342">Adding CTC loss to Flux</a></p>

<li><p><a href="https://github.com/FluxML/model-zoo/pull/50">Adding the framewise speech recognition model to the Flux model zoo</a></p>

</ul>
<h1 id=references ><a href="#references">References</a></h1>
<ul>
<li><p>Graves, A., &amp; Schmidhuber, J. &#40;2005&#41;. Framewise phoneme classification with bidirectional LSTM and other neural network architectures. <em>Neural Networks, 18</em>&#40;5-6&#41;, 602-610.</p>

<li><p>Graves, A., Fernández, S., Gomez, F., &amp; Schmidhuber, J. &#40;2006&#41;. Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks. In <em>Proceedings of the 23rd international conference on machine learning</em> &#40;pp. 369-376&#41;. ACM.</p>

<li><p>Zhang, Y., Pezeshki, M., Brakel, P., Zhang, S., Bengio, C. L. Y., &amp; Courville, A. &#40;2017&#41;. Towards end-to-end speech recognition with deep convolutional neural networks. <em>arXiv preprint arXiv:1701.02720</em>.</p>

</ul>
</div><br><br>


    
    

    <footer class="container-fluid footer-copy">
  <div class=container >
    <div class=row >
      <div class="col-md-10 py-2">
        <p>This website is built with <a style="color: #7a95dd" href="https://franklinjl.org">Franklin.jl</a> - a Julia native package for
          building websites. We thank <a style="color: #7a95dd" href="https://www.fastly.com">Fastly</a> for their generous infrastructure support.
        <p>©2020 JuliaLang.org <a style="color: #7a95dd" href="https://github.com/JuliaLang/www.julialang.org/graphs/contributors">contributors</a>. The content on this website is made available under the <a style="color: #7a95dd" href="https://github.com/JuliaLang/www.julialang.org/blob/master/LICENSE.md">MIT license</a>.
      </div>
      <div class="col-md-2 py-2">
        <a class=github-button  href="https://github.com/sponsors/julialang" data-icon=octicon-heart  data-size=large  aria-label="Sponsor @julialang on GitHub">Sponsor</a>
      </div>
    </div>
  </div>
</footer>

<script src="/libs/jquery/jquery.min.js"></script>
<script src="/libs/bootstrap/bootstrap.min.js"></script>
<script src="/libs/platform.js"></script>