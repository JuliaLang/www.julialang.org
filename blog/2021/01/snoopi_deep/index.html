<!doctype html>
<html lang="en">
<head>
	<!-- parts for all pages -->
	<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="x-ua-compatible" content="ie=edge">
<meta name="author" content="Jeff Bezanson, Stefan Karpinski, Viral Shah, Alan Edelman, et al.">
<meta name="description" content="The official website for the Julia Language. Julia is a language that is fast, dynamic, easy to use, and open source. Click here to learn more.">
<meta name="robots" content="max-image-preview:large">
<meta name="twitter:site:id" content="1237720952"> <!-- @JuliaLanguage -->
<meta name="google-site-verification" content="9VDSjBtchQj6PQYIVwugTPY7pVCfLYgvkXiRHjc_Bzw" /> <!-- Google News Feed -->


	<link rel="icon" href="/assets/infra/julia.ico">

  <!-- Franklin stylesheets for generated pages -->
  
   <link rel="stylesheet" href="/libs/highlight/github.min.css">
  

	<!-- NOTE: specific stylesheets -->
<link rel="stylesheet" href="/libs/bootstrap/bootstrap.min.css">
<link rel="stylesheet" href="/css/app.css">
<link rel="stylesheet" href="/css/franklin.css">
<link rel="stylesheet" href="/css/fonts.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:400,400i,500,500i,700,700i" rel="stylesheet">
<link href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
<script async defer src="/libs/buttons.js"></script>
<script src="/libs/clipboard.min.js"></script>
<script src="/libs/detectdark.js"></script>


<script defer data-domain="julialang.org" src="https://plausible.io/js/script.js"></script>

<!-- scripts for map rendering -->
<link rel="stylesheet" href="https://unpkg.com/leaflet@1.7.1/dist/leaflet.css"
integrity="sha512-xodZBNTC5n17Xt2atTPuE1HxjVMSvLVW9ocqUKLsCC5CXdbqCmblAshOMAS6/keqq/sMZMZ19scR4PsZChSR7A=="
crossorigin=""/>

<script src="https://unpkg.com/leaflet@1.7.1/dist/leaflet.js"
 integrity="sha512-XQoYMqMTK8LvdxXYG3nZ448hOEQiglfqkJs1NOQV44cWnUrBc8PkAOcXy20w0vlaXaVUearIOBhiXZ5V3ynxwA=="
 crossorigin=""></script>

<!-- https://github.com/Leaflet/Leaflet.markercluster -->
<script src="https://cdn.jsdelivr.net/npm/leaflet.markercluster@1.4.1/dist/leaflet.markercluster-src.min.js"></script>

<script src="https://kit.fontawesome.com/f030d443fe.js" crossorigin="anonymous"></script>


   <title>Profiling type-inference</title>   

  
  <style>
	  .container ul li p {margin-bottom: 0;}
		.container ol li p {margin-bottom: 0;}
		.container ul ul {margin: .4em 0 .4em 0;}
		.container ul ol {margin: .4em 0 .4em 0;}
		.container ol ul {margin: .4em 0 .4em 0;}
		.container ol ol {margin: .4em 0 .4em 0;}
  </style>
  

  <!-- Specific style for blog pages (except the /blob/index) -->
  
  <style>
    .main { font-family: Georgia; }
    .main pre {
  	  margin-left: auto;
  	  margin-right: auto;
    }
    .main { width: 100%; font-size: 100%; }
    .main code { font-size: 90%; }
    .main pre code { font-size: 90%; }
    @media (min-width: 940px) {
      .main { width: 800px; }
      .container.blog-title { width: 800px;}
    }
  </style>
  

  <!-- OGP Metadata -->
	<meta property="og:title" content="Profiling type-inference">
<meta property="og:description" content="Profiling type-inference">
<meta property="og:image" content="/assets/images/julia-open-graph.png">


</head>

<body>

<div class="container py-3 py-lg-0">
  <nav class="navbar navbar-expand-lg navbar-light bg-light" id="main-menu">
    <!-- LOGO -->
    <a class="navbar-brand" href="/">
      <img class="julialogo" src="/assets/infra/logo.svg" alt="JuliaLang Logo">
    </a>

    <button class="navbar-toggler ml-auto hidden-sm-up float-xs-left" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

      <!-- MENU: DOWNLOAD | DOCUMENTATION | BLOG ... -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mx-auto">
        <li class="nav-item   flex-md-fill text-md-center">
          <a class="nav-link" href="/downloads/">Download</a>
        </li>
        <li class="nav-item flex-md-fill text-md-center">
          <a class="nav-link" href="https://docs.julialang.org">Documentation</a>
        </li>
        <li class="nav-item   flex-md-fill text-md-center">
          <a class="nav-link" href="/learning/">Learn</a>
        </li>
        <li class="nav-item active flex-md-fill text-md-center">
          <a class="nav-link" href="/blog/">Blog</a>
        </li>
        <li class="nav-item   flex-md-fill text-md-center">
          <a class="nav-link" href="/community/">Community</a>
        </li>
        <li class="nav-item   flex-md-fill text-md-center">
          <a class="nav-link" href="/contribute/">Contribute</a>
        </li>
        <li class="nav-item   flex-md-fill text-md-center">
          <a class="nav-link" href="/jsoc/">JSoC</a>
        </li>
      </ul>
      <span class="navbar-right">
        <a class="github-button" href="https://github.com/JuliaLang/julia" data-size="large" data-show-count="true" aria-label="Star JuliaLang/julia on GitHub">Star</a>
        <a class="github-button" href="https://github.com/sponsors/julialang" data-icon="octicon-heart" data-size="large" aria-label="Sponsor @julialang on GitHub">Sponsor</a>
      </span>
    </div>

  </nav>
</div>


<br><br>


<div class="container blog-title">
  <h1>Profiling type-inference
    <a type="application/rss+xml" href="https://julialang.org/feed.xml">
      <i class="fa fa-rss-square rss-icon"></i>
    </a>
  </h1>
  <h3>
   <span style="font-weight: lighter;"> 28 January 2021 </span>
	|
	
	 <span style="font-weight: bold;"></span> 
  <!-- assumption that only one of the two is defined -->
   <span style="font-weight: bold;">Tim Holy and Nathan Daly </span> 
  </h3>
</div>



<a href="https://github.com/JuliaLang/www.julialang.org/blob/master/blog/2021/01/snoopi_deep.md" title="Edit this page on GitHub" class="edit-float">
</a>


<!-- Content appended here -->
<div class="container main"><p>This is the second in a short series on what package developers can do to reduce the latency of Julia packages. In the <a href="https://julialang.org/blog/2021/01/precompile_tutorial/">first post</a>, we introduced precompilation and some of its constraints. We also pointed out that precompilation is closely tied to <em>type inference</em>:</p>
<ul>
<li><p>precompilation allows you to cache the results of type inference, thus saving time when you start using methods defined in the package</p>
</li>
<li><p>caching becomes more effective when a higher proportion of calls are made with inferable argument types &#40;i.e., type-inference &quot;succeeds&quot;&#41;. Successful inference introduces links, in the form of <code>MethodInstance</code> backedges, that permit the entire call graph to be cached.</p>
</li>
</ul>
<p>As a consequence, anyone interested in precompilation needs to pay attention to type inference: how much time does it account for, where is it spending its time, and what can be done to improve caching? Julia itself provides the internal infrastructure needed to &quot;spy&quot; on inference, and the user-space utilities are in the <a href="https://github.com/timholy/SnoopCompile.jl">SnoopCompile</a> package. Julia 1.2 provided limited facilities for &quot;spying&quot; on inference, and this infrastructure corresponds to SnoopCompile&#39;s <code>@snoopi</code> macro. Julia 1.6 includes new changes that have permitted a far deeper look at what inference is doing. Appropriately enough, SnoopCompile calls this <code>@snoopi_deep</code>.</p>
<p>The rich data collected by <code>@snoopi_deep</code> are useful for several different purposes. In this post, we&#39;ll describe the basic tool and show how it can be used to profile inference. Later posts will show other ways to use the data to reduce the amount of type-inference or cache its results.</p>
<h2 id="collecting_the_data"><a href="#collecting_the_data" class="header-anchor">Collecting the data</a></h2>
<p>To see <code>@snoopi_deep</code> in action, we&#39;ll use the following demo:</p>
<pre><code class="julia hljs"><span class="hljs-keyword">module</span> SnoopDemo
    <span class="hljs-keyword">struct</span> MyType{T} x::T <span class="hljs-keyword">end</span>

    extract(y::MyType) = y.x

    <span class="hljs-keyword">function</span> domath(x)
        y = x + x
        <span class="hljs-keyword">return</span> y*x + <span class="hljs-number">2</span>*x + <span class="hljs-number">5</span>
    <span class="hljs-keyword">end</span>

    dostuff(y) = domath(extract(y))

    <span class="hljs-keyword">function</span> domath_with_mytype(x)
        y = MyType(x)
        <span class="hljs-keyword">return</span> dostuff(y)
    <span class="hljs-keyword">end</span>
<span class="hljs-keyword">end</span></code></pre>
<p>The main call, <code>domath_with_mytype</code>, stores the input in a <code>struct</code>, and then calls functions that extract the field value and perform arithmetic on the result. To profile inference on this call, we simply do the following:</p>
<pre><code class="julia hljs">julia&gt; <span class="hljs-keyword">using</span> SnoopCompile

julia&gt; tinf = <span class="hljs-meta">@snoopi_deep</span> SnoopDemo.domath_with_mytype(<span class="hljs-number">1</span>)
InferenceTimingNode: <span class="hljs-number">0.009382</span>/<span class="hljs-number">0.010515</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> Core.Compiler.Timings.ROOT() with <span class="hljs-number">1</span> direct children</code></pre>
<div class="note"><strong>Box 1</strong> Inference gets called only on the <em>first</em> invocation of a method with those specific types. You have to redefine the <code>SnoopDemo</code> module &#40;by re-executing the command we used to define it&#41; if you want to collect data with <code>@snoopi_deep</code> on the same code a second time.  This won&#39;t redefine any <code>Base</code> methods that <code>SnoopDemo</code> depends on, so you still may see differences between running this in a fresh session and subsequent uses of <code>@snoopi_deep</code>.</div>
<p>This may not look like much, but there&#39;s a wealth of information hidden inside <code>tinf</code>. While optional, before proceeding further it&#39;s recommended to check <code>tinf</code> for hints that <a href="https://julialang.org/blog/2020/08/invalidations/">invalidation</a> may have influenced the result:</p>
<pre><code class="julia hljs">julia&gt; staleinstances(tinf)
SnoopCompileCore.InferenceTiming[]</code></pre>
<p><code>staleinstances</code> extracts <code>MethodInstances</code> that have some &quot;stale&quot; generated code &#40;code that is no longer callable&#41;. In our case, it returns an empty list, meaning that it found no stale instances, which guarantees that no invalidation occurred. There&#39;s nothing &quot;funny&quot; going on behind the scenes that will influence our results.</p>
<div class="note"><strong>Box 2</strong> Unlike <code>@snoopr</code>, another macro exported by SnoopCompile, <code>staleinstances</code> does not distinguish between whether that stale code existed before you ran the <code>@snoopi_deep</code> block, or whether it got invalidated during the running of that block. For detailed analysis of invalidations, <code>@snoopr</code> is the recommended tool.</div>
<h2 id="inspecting_the_output"><a href="#inspecting_the_output" class="header-anchor">Inspecting the output</a></h2>
<p>In this post, we&#39;ll stick to the basics of inspecting the data collected by <code>@snoopi_deep</code>. First, notice that the output is an <code>InferenceTimingNode</code>: it&#39;s the root element of a tree of such nodes, all connected by caller-callee relationships. Indeed, this particular node is for <code>Core.Compiler.Timings.ROOT&#40;&#41;</code>, a &quot;dummy&quot; node that is the root of all such trees.</p>
<p>You may have noticed that this <code>ROOT</code> node prints with two numbers. It will be easier to understand their meaning if we first display the whole tree. We can do that with the <a href="https://github.com/JuliaCollections/AbstractTrees.jl">AbstractTrees</a> package:</p>
<pre><code class="julia hljs">julia&gt; <span class="hljs-keyword">using</span> AbstractTrees

julia&gt; print_tree(tinf)
InferenceTimingNode: <span class="hljs-number">0.009382</span>/<span class="hljs-number">0.010515</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> Core.Compiler.Timings.ROOT() with <span class="hljs-number">1</span> direct children
└─ InferenceTimingNode: <span class="hljs-number">0.000355</span>/<span class="hljs-number">0.001133</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> Main.SnoopDemo.domath_with_mytype(::<span class="hljs-built_in">Int64</span>) with <span class="hljs-number">3</span> direct children
   ├─ InferenceTimingNode: <span class="hljs-number">0.000122</span>/<span class="hljs-number">0.000254</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> MyType(::<span class="hljs-built_in">Int64</span>) with <span class="hljs-number">1</span> direct children
   │  └─ InferenceTimingNode: <span class="hljs-number">0.000132</span>/<span class="hljs-number">0.000132</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> MyType{<span class="hljs-built_in">Int64</span>}(::<span class="hljs-built_in">Int64</span>) with <span class="hljs-number">0</span> direct children
   ├─ InferenceTimingNode: <span class="hljs-number">0.000071</span>/<span class="hljs-number">0.000071</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> MyType(::<span class="hljs-built_in">Int64</span>) with <span class="hljs-number">0</span> direct children
   └─ InferenceTimingNode: <span class="hljs-number">0.000122</span>/<span class="hljs-number">0.000453</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> Main.SnoopDemo.dostuff(::MyType{<span class="hljs-built_in">Int64</span>}) with <span class="hljs-number">2</span> direct children
      ├─ InferenceTimingNode: <span class="hljs-number">0.000083</span>/<span class="hljs-number">0.000161</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> Main.SnoopDemo.extract(::MyType{<span class="hljs-built_in">Int64</span>}) with <span class="hljs-number">2</span> direct children
      │  ├─ InferenceTimingNode: <span class="hljs-number">0.000045</span>/<span class="hljs-number">0.000045</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> getproperty(::MyType{<span class="hljs-built_in">Int64</span>}, ::<span class="hljs-built_in">Symbol</span>) with <span class="hljs-number">0</span> direct children
      │  └─ InferenceTimingNode: <span class="hljs-number">0.000034</span>/<span class="hljs-number">0.000034</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> getproperty(::MyType{<span class="hljs-built_in">Int64</span>}, x::<span class="hljs-built_in">Symbol</span>) with <span class="hljs-number">0</span> direct children
      └─ InferenceTimingNode: <span class="hljs-number">0.000170</span>/<span class="hljs-number">0.000170</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> Main.SnoopDemo.domath(::<span class="hljs-built_in">Int64</span>) with <span class="hljs-number">0</span> direct children</code></pre>
<p>This tree structure reveals the caller-callee relationships, showing the specific types that were used for each <code>MethodInstance</code>. Indeed, as the calls to <code>getproperty</code> reveal, it goes beyond the types and even shows the results of <a href="https://en.wikipedia.org/wiki/Constant_folding">constant propagation</a>; the <code>getproperty&#40;::MyType&#123;Int64&#125;, x::Symbol&#41;</code> &#40;note <code>x::Symbol</code> instead of just plain <code>::Symbol</code>&#41; means that the call was <code>getproperty&#40;y, :x&#41;</code>, which corresponds to <code>y.x</code> in the definition of <code>extract</code>.</p>
<div class="note"><p><strong>Box 3</strong> Generally we speak of <a href="https://en.wikipedia.org/wiki/Call_graph">call graphs</a> rather than call trees. But because inference results are cached &#40;a.k.a., we only &quot;visit&quot; each node once&#41;, we obtain a tree as a depth-first-search of the full call graph.</p>
<p>Keep in mind that this can sometimes lead to surprising results when trying to improve inference times. You may delete a node in the graph, expecting to eliminate it and all of its children, only to find that the children are now sitting under a <em>different</em> parent node, the next function to be inferred that calls your child, and was previously relying on it being cached.</p></div>
<p>Each node in this tree is accompanied by a pair of numbers. The first number is the <em>exclusive</em> inference time &#40;in seconds&#41;, meaning the time spent inferring the particular MethodInstance, not including the time spent inferring its callees. The second number is the <em>inclusive</em> time, which is the exclusive time plus the time spent on the callees. Therefore, the inclusive time is always at least as large as the exclusive time.</p>
<p>The <code>ROOT</code> node is a bit different: its exclusive time measures the time spent on all operations <em>except</em> inference. In this case, we see that the entire call took approximately 10ms, of which 9.3ms was spent on activities besides inference. Almost all of that was code-generation, but it also includes the time needed to run the code. Just 0.76ms was needed to run type-inference on this entire series of calls. As users of <code>@snoopi_deep</code> will quickly discover, inference takes much more time on more complicated code.</p>
<p>You can extract the <code>MethodInstance</code> that was being inferred at each node with</p>
<pre><code class="julia hljs">julia&gt; Core.MethodInstance(tinf)
MethodInstance <span class="hljs-keyword">for</span> ROOT()

julia&gt; Core.MethodInstance(tinf.children[<span class="hljs-number">1</span>])
MethodInstance <span class="hljs-keyword">for</span> domath_with_mytype(::<span class="hljs-built_in">Int64</span>)</code></pre>
<h2 id="visualizing_the_output"><a href="#visualizing_the_output" class="header-anchor">Visualizing the output</a></h2>
<p>We can also display this tree as a flame graph, using either the <a href="https://github.com/timholy/ProfileView.jl">ProfileView</a> or <a href="https://github.com/JuliaPerf/PProf.jl">PProf</a> packages:</p>
<h3 id="profileviewjl"><a href="#profileviewjl" class="header-anchor">ProfileView.jl</a></h3>
<pre><code class="julia hljs">julia&gt; fg = flamegraph(tinf)
Node(FlameGraphs.NodeData(ROOT() at typeinfer.jl:<span class="hljs-number">75</span>, <span class="hljs-number">0x00</span>, <span class="hljs-number">0</span>:<span class="hljs-number">10080857</span>))

julia&gt; <span class="hljs-keyword">using</span> ProfileView

julia&gt; ProfileView.view(fg)</code></pre>
<p>You should see something like this:</p>
<p><img src="/assets/blog/2021-latency/flamegraph-flatten-demo.png" alt="flamegraph" /></p>
<p>Users are encouraged to read the ProfileView documentation to understand how to interpret this, but briefly:</p>
<ul>
<li><p>the horizontal axis is time &#40;wide boxes take longer than narrow ones&#41;, the vertical axis is call depth</p>
</li>
<li><p>hovering over a box displays the method that was inferred</p>
</li>
<li><p>left-clicking on a box causes the full MethodInstance to be printed in your REPL session</p>
</li>
<li><p>right-clicking on a box opens the corresponding method in your editor &#40;you must have <code>ENV&#91;&quot;EDITOR&quot;&#93;</code> configured appropriately for this to work&#41;</p>
</li>
<li><p>ctrl-click can be used to zoom in &#40;you can do rubber band selection or zoom in/zoom out&#41;</p>
</li>
<li><p>empty horizontal spaces correspond to activities other than type-inference; in this case, the relatively narrow flame followed by a lot of empty space indicates that all the type inference happened at the beginning and accounted for only a small fraction of the total time.</p>
</li>
</ul>
<p>You can explore this flamegraph and compare it to the output from <code>print_tree</code>.</p>
<p>In less trivial examples, these flame graphs may look more interesting:</p>
<p><img src="/assets/blog/2021-latency/flamegraph-complex.png" alt="flamegraph-complex" /></p>
<p>Here, the red boxes correspond to <code>MethodInstance</code>s which cannot be &quot;naturally&quot; precompiled. This occurs when the method is owned by one module but the argument types are from another unrelated module. We&#39;ll see how to deal with these in later installments.</p>
<p>You also see breaks in the flamegraph. During these periods, code generation and runtime create new objects and then call methods on those objects; if one of those calls requires a fresh entrance into inference, that triggers the creation of a new flame. Hence, the number of distinct flames &#40;which is just equal to <code>length&#40;tinf.children&#41;</code>&#41; gives you a rough indication of how frequently the chains of inference were broken. This can be caused by type instability, separate top-level calls from the REPL during <code>@snoopi_deep</code>, calls to <code>eval</code> in your code, or some other cause for Julia to start running type inference.</p>
<h3 id="pprofjl"><a href="#pprofjl" class="header-anchor">PProf.jl</a></h3>
<pre><code class="julia hljs">julia&gt; fg = flamegraph(tinf)
Node(FlameGraphs.NodeData(ROOT() at typeinfer.jl:<span class="hljs-number">75</span>, <span class="hljs-number">0x00</span>, <span class="hljs-number">0</span>:<span class="hljs-number">10080857</span>))

julia&gt; <span class="hljs-keyword">using</span> PProf

julia&gt; pprof(fg)
Serving web UI on http://localhost:<span class="hljs-number">57599</span></code></pre>
<p>For a detailed walkthrough of how to use PProf, see the <a href="https://github.com/JuliaPerf/PProf.jl">PProf.jl README</a> and, for a more complete guide, the <a href="https://github.com/google/pprof/blob/master/doc/README.md#web-interface">google/pprof web interface README</a>.</p>
<p>We have found the most useful views for inspecting an inference profile to be the <code>/flamegraph</code> and <code>/source</code> views. If you navigate to the Flamegraph view, via VIEW -&gt; Flame Graph, this is what you should see:</p>
<p><img src="/assets/blog/2021-latency/pprof-flamegraph-full-1.png" alt="PProf Flamegraph in full" /></p>
<p>Of course, as above, in this example inference was only a small part of the total time. You can zoom-in on nodes by clicking on them, and hovering will display their full text and time. The nicest way to expand just the inference time is to filter out the <em>non-inference time</em> by &quot;hiding&quot; the <code>ROOT&#40;&#41;</code> node. To do this, type <code>ROOT&#40;&#41;</code> in the <code>Search regexp</code> bar and click REFINE -&gt; Hide, or add <code>?h&#61;ROOT</code> to the URL. This works well if there are several top-level calls to inference, as discussed below. One benefit of hiding and filtering via the Search bar is that the percentages for all nodes will be recomputed as a percentage of the new total.</p>
<p>Typing values into the search bar &#40;without pressing enter&#41; will highlight them in the graph, as displayed in the following image, and pressing enter will filter the graph to <em>only</em> contain paths that match your search. These tools can be used to identify small functions that show up often, contributing large amounts of time when aggregated together.</p>
<p><img src="/assets/blog/2021-latency/pprof-flamepgraph-no-root-highlight.png" alt="PProf Flamegraph filtered and highlighted" /></p>
<p>Here&#39;s a screenshot of the Top view, again with <code>ROOT&#40;&#41;</code> hidden &#40;<code>/top?h&#61;ROOT&#40;&#41;</code>&#41;:</p>
<p><img src="/assets/blog/2021-latency/pprof-top-no-root.png" alt="PProf Top view" /></p>
<p>More details about using PProf are outside the scope of this post, but here are some things to keep in mind:</p>
<ul>
<li><p>Sibling frames in pprof are <em>not ordered by time</em>, they are ordered alphabetically. <code>ProfileView</code>, above, is a much better tool for understanding what occurred when during a computation.</p>
</li>
<li><p>PProf is excellent for interactively exploring &#40;potentially very large&#41; profiles. It provides good high-level summary of the biggest offenders, and includes many tools for understanding their details, including the <code>source</code> view, <code>top</code> view, and filtering.</p>
</li>
<li><p>You can export profiles to a file via the <code>out&#61;</code> parameter to <code>pprof&#40;&#41;</code>, which are entirely self-contained and can be shared with collaborators for them to view with PProf.</p>
</li>
</ul>
<h2 id="elementary_analysis_flatten_and_accumulate_by_source"><a href="#elementary_analysis_flatten_and_accumulate_by_source" class="header-anchor">Elementary analysis: <code>flatten</code> and <code>accumulate_by_source</code></a></h2>
<p>As our last step for this post, let&#39;s extract the data as a list:</p>
<pre><code class="julia hljs">julia&gt; flatten(tinf)
<span class="hljs-number">10</span>-element <span class="hljs-built_in">Vector</span>{SnoopCompileCore.InferenceTiming}:
 InferenceTiming: <span class="hljs-number">0.000034</span>/<span class="hljs-number">0.000034</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> getproperty(::Main.SnoopDemo.MyType{<span class="hljs-built_in">Int64</span>}, x::<span class="hljs-built_in">Symbol</span>)
 InferenceTiming: <span class="hljs-number">0.000045</span>/<span class="hljs-number">0.000045</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> getproperty(::Main.SnoopDemo.MyType{<span class="hljs-built_in">Int64</span>}, ::<span class="hljs-built_in">Symbol</span>)
 InferenceTiming: <span class="hljs-number">0.000071</span>/<span class="hljs-number">0.000071</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> Main.SnoopDemo.MyType(::<span class="hljs-built_in">Int64</span>)
 InferenceTiming: <span class="hljs-number">0.000083</span>/<span class="hljs-number">0.000161</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> Main.SnoopDemo.extract(::Main.SnoopDemo.MyType{<span class="hljs-built_in">Int64</span>})
 InferenceTiming: <span class="hljs-number">0.000122</span>/<span class="hljs-number">0.000453</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> Main.SnoopDemo.dostuff(::Main.SnoopDemo.MyType{<span class="hljs-built_in">Int64</span>})
 InferenceTiming: <span class="hljs-number">0.000122</span>/<span class="hljs-number">0.000254</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> Main.SnoopDemo.MyType(::<span class="hljs-built_in">Int64</span>)
 InferenceTiming: <span class="hljs-number">0.000132</span>/<span class="hljs-number">0.000132</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> Main.SnoopDemo.MyType{<span class="hljs-built_in">Int64</span>}(::<span class="hljs-built_in">Int64</span>)
 InferenceTiming: <span class="hljs-number">0.000170</span>/<span class="hljs-number">0.000170</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> Main.SnoopDemo.domath(::<span class="hljs-built_in">Int64</span>)
 InferenceTiming: <span class="hljs-number">0.000355</span>/<span class="hljs-number">0.001133</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> Main.SnoopDemo.domath_with_mytype(::<span class="hljs-built_in">Int64</span>)
 InferenceTiming: <span class="hljs-number">0.009382</span>/<span class="hljs-number">0.010515</span> on InferenceFrameInfo <span class="hljs-keyword">for</span> Core.Compiler.Timings.ROOT()</code></pre>
<p>By default, this orders the nodes by exclusive time, but <code>flatten&#40;tinf; sortby&#61;inclusive&#41;</code> allows you to sort by inclusive time. Finally, <code>flatten&#40;tinf; sortby&#61;nothing&#41;</code> returns the nodes in the order in which they were inferred.</p>
<p>Sometimes, you might infer the same method for many different specific argument types, and sometimes you might want to get a sense of the aggregate cost:</p>
<pre><code class="julia hljs">julia&gt; accumulate_by_source(flatten(tinf))
<span class="hljs-number">8</span>-element <span class="hljs-built_in">Vector</span>{<span class="hljs-built_in">Tuple</span>{<span class="hljs-built_in">Float64</span>, <span class="hljs-built_in">Union</span>{<span class="hljs-built_in">Method</span>, Core.MethodInstance}}}:
 (<span class="hljs-number">7.838100000000001e-5</span>, getproperty(x, f::<span class="hljs-built_in">Symbol</span>) <span class="hljs-keyword">in</span> Base at Base.jl:<span class="hljs-number">33</span>)
 (<span class="hljs-number">8.2955e-5</span>, extract(y::Main.SnoopDemo.MyType) <span class="hljs-keyword">in</span> Main.SnoopDemo at REPL[<span class="hljs-number">1</span>]:<span class="hljs-number">4</span>)
 (<span class="hljs-number">0.000121738</span>, dostuff(y) <span class="hljs-keyword">in</span> Main.SnoopDemo at REPL[<span class="hljs-number">1</span>]:<span class="hljs-number">11</span>)
 (<span class="hljs-number">0.000132328</span>, Main.SnoopDemo.MyType{T}(x) <span class="hljs-keyword">where</span> T <span class="hljs-keyword">in</span> Main.SnoopDemo at REPL[<span class="hljs-number">1</span>]:<span class="hljs-number">2</span>)
 (<span class="hljs-number">0.000170205</span>, domath(x) <span class="hljs-keyword">in</span> Main.SnoopDemo at REPL[<span class="hljs-number">1</span>]:<span class="hljs-number">6</span>)
 (<span class="hljs-number">0.000193107</span>, Main.SnoopDemo.MyType(x::T) <span class="hljs-keyword">where</span> T <span class="hljs-keyword">in</span> Main.SnoopDemo at REPL[<span class="hljs-number">1</span>]:<span class="hljs-number">2</span>)
 (<span class="hljs-number">0.000354527</span>, domath_with_mytype(x) <span class="hljs-keyword">in</span> Main.SnoopDemo at REPL[<span class="hljs-number">1</span>]:<span class="hljs-number">13</span>)
 (<span class="hljs-number">0.009381595</span>, ROOT() <span class="hljs-keyword">in</span> Core.Compiler.Timings at compiler/typeinfer.jl:<span class="hljs-number">75</span>)</code></pre>
<p>This shows the cost of each <code>Method</code>, summing across all specific <code>MethodInstance</code>s.</p>
<h2 id="summary"><a href="#summary" class="header-anchor">Summary</a></h2>
<p>The tools described here permit a new level of insight into where type inference is spending its time. Sometimes, this information alone is enough to show you how to change your code to reduce latency. However, most efforts at latency reduction will probably leverage additional tools that help identify the main opportunities for intervention. These tools will be described in future posts.</p>

</div><br><br>

<!-- CONTENT ENDS HERE -->
    
    
        <script src="/libs/highlight/highlight.min.js"></script>


    

    <!-- http://tutsplus.github.io/clipboard/ -->

<script>
(function(){

	// Get the elements.
	// - the 'pre' element.
	// - the 'div' with the 'paste-content' id.

	var pre = document.getElementsByTagName('pre');

	// Add a copy button in the 'pre' element.
	// which only has the className of 'language-' or ' hljs'(if enable highlight.js pre-render).

	for (var i = 0; i < pre.length; i++) {
		var tag_name = pre[i].children[0].className
            	var isLanguage = tag_name.startsWith('language-') || tag_name.endsWith(' hljs');
		if ( isLanguage ) {
			var button           = document.createElement('button');
					button.className = 'copy-button';
					button.textContent = 'Copy';

					pre[i].appendChild(button);
		}
	};

	// Run Clipboard

	var copyCode = new Clipboard('.copy-button', {
		target: function(trigger) {
			return trigger.previousElementSibling;
    }
	});

	// On success:
	// - Change the "Copy" text to "Copied".
	// - Swap it to "Copy" in 2s.
	// - Lead user to the "contenteditable" area with Velocity scroll.

	copyCode.on('success', function(event) {
		event.clearSelection();
		event.trigger.textContent = 'Copied';
		window.setTimeout(function() {
			event.trigger.textContent = 'Copy';
		}, 2000);

	});

	// On error (Safari):
	// - Change the  "Press Ctrl+C to copy"
	// - Swap it to "Copy" in 2s.

	copyCode.on('error', function(event) {
		event.trigger.textContent = 'Press "Ctrl + C" to copy';
		window.setTimeout(function() {
			event.trigger.textContent = 'Copy';
		}, 5000);
	});

})();
</script>


    <footer class="container-fluid footer-copy">
  <div class="container">
    <div class="row footrow">
      <ul>
        <li><a href="/project">About</a></li>
        <li><a href="/about/help">Get Help</a></li>
        <li><a href="/governance/">Governance</a></li>
        <li><a href="/research/#publications">Publications</a></li>
        <li><a href="/community/sponsors/">Sponsors</a></li>
      </ul>
      <ul>
        <li><a href="/downloads/">Downloads</a></li>
        <li><a href="/downloads/">All Releases</a></li>
        <li><a href="https://github.com/JuliaLang/julia">Source Code</a></li>
        <li><a href="/downloads/#current_stable_release">Current Stable Release</a></li>
        <li><a href="/downloads/#long_term_support_release">Longterm Support Release</a></li>
      </ul>
      <ul>
        <li><a href="https://docs.julialang.org/en/v1/">Documentation</a></li>
        <li><a href="https://juliaacademy.com">JuliaAcademy</a></li>
        <li><a href="https://www.youtube.com/user/JuliaLanguage">YouTube</a></li>
        <li><a href="/learning/getting-started/">Getting Started</a></li>
        <li><a href="https://docs.julialang.org/en/v1/manual/faq/">FAQ</a></li>
        <li><a href="/learning/books">Books</a></li>
      </ul>
      <ul>
        <li><a href="/community/">Community</a></li>
        <li><a href="/community/standards/">Code of Conduct</a></li>
        <li><a href="/community/stewards/">Stewards</a></li>
        <li><a href="/diversity/">Diversity</a></li>
        <li><a href="https://juliagenderinclusive.github.io">Julia Gender Inclusive</a></li>
        <li><a href="https://juliacon.org">JuliaCon</a></li>
        <li><a href="/community/#julia_user_and_developer_survey">User/Developer Survey</a></li>
        <li><a href="/shop/">Shop Merchandise</a></li>
      </ul>
      <ul>
        <li><a href="https://github.com/JuliaLang/julia/blob/master/CONTRIBUTING.md">Contributing</a></li>
        <li><a href="/contribute">Contributor's Guide</a></li>
        <li><a href="https://github.com/JuliaLang/julia/issues">Issue Tracker</a></li>
        <li><a href="https://github.com/JuliaLang/julia/security/policy">Report a Security Issue</a></li>
        <li><a href="https://github.com/search?q=is%3Aopen+is%3Aissue+language%3AJulia+label%3A%22help+wanted%22">Help Wanted Issues</a></li>
        <li><a href="https://github.com/search?q=is%3Aopen+is%3Aissue+language%3AJulia+label%3A%22good+first+issue%22">Good First Issue</a></li>
        <li><a href="https://docs.julialang.org/en/v1/devdocs/init/">Dev Docs</a></li>
      </ul>
    </div>
    <div id="footer-bottom" class="row">
      <div class="col-md-10 py-2">
        <p>Last modified: January 16, 2025. This site is powered by <a href="https://www.netlify.com">Netlify</a>, <a href="https://franklinjl.org">Franklin.jl</a>, and the <a href="https://julialang.org">Julia Programming Language</a>.</p>
        <p>We thank <a href="https://www.fastly.com">Fastly</a> for their generous infrastructure support.</p>
        <p>©2024 JuliaLang.org <a href="https://github.com/JuliaLang/www.julialang.org/graphs/contributors">contributors</a>. The content on this website is made available under the <a href="https://github.com/JuliaLang/www.julialang.org/blob/master/LICENSE.md">MIT license</a>.</p>
      </div>
      <div class="col-md-2 py-2">
        <span class="float-sm-right">
          <a class="github-button" href="https://github.com/sponsors/julialang" data-icon="octicon-heart" data-size="large" aria-label="Sponsor @julialang on GitHub">Sponsor</a>
        </span>
      </div>
    </div>
  </div>
</footer>

<script src="/libs/jquery/jquery.min.js"></script>
<script src="/libs/bootstrap/bootstrap.min.js"></script>
<!-- <script src="/libs/highlight/highlight.min.js"></script> -->
<!--  -->

    <script src="/libs/groups.js"></script>
    <script src="/libs/map.js"></script>
  </body>
</html>
